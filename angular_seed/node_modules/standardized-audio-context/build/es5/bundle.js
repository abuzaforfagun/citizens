(function (global, factory) {
    typeof exports === 'object' && typeof module !== 'undefined' ? factory(exports, require('babel-runtime/helpers/typeof'), require('babel-runtime/helpers/classCallCheck'), require('babel-runtime/helpers/createClass'), require('babel-runtime/helpers/possibleConstructorReturn'), require('babel-runtime/helpers/inherits'), require('babel-runtime/helpers/toConsumableArray'), require('babel-runtime/helpers/slicedToArray'), require('babel-runtime/regenerator'), require('tslib'), require('babel-runtime/helpers/defineProperty'), require('async-array-buffer')) :
    typeof define === 'function' && define.amd ? define(['exports', 'babel-runtime/helpers/typeof', 'babel-runtime/helpers/classCallCheck', 'babel-runtime/helpers/createClass', 'babel-runtime/helpers/possibleConstructorReturn', 'babel-runtime/helpers/inherits', 'babel-runtime/helpers/toConsumableArray', 'babel-runtime/helpers/slicedToArray', 'babel-runtime/regenerator', 'tslib', 'babel-runtime/helpers/defineProperty', 'async-array-buffer'], factory) :
    (factory((global.standardizedAudioContext = {}),global._typeof,global._classCallCheck,global._createClass,global._possibleConstructorReturn,global._inherits,global._toConsumableArray,global._slicedToArray,global._regeneratorRuntime,global.tslib_1,global._defineProperty,global.asyncArrayBuffer));
}(this, (function (exports,_typeof,_classCallCheck,_createClass,_possibleConstructorReturn,_inherits,_toConsumableArray,_slicedToArray,_regeneratorRuntime,tslib_1,_defineProperty,asyncArrayBuffer) { 'use strict';

    _typeof = _typeof && _typeof.hasOwnProperty('default') ? _typeof['default'] : _typeof;
    _classCallCheck = _classCallCheck && _classCallCheck.hasOwnProperty('default') ? _classCallCheck['default'] : _classCallCheck;
    _createClass = _createClass && _createClass.hasOwnProperty('default') ? _createClass['default'] : _createClass;
    _possibleConstructorReturn = _possibleConstructorReturn && _possibleConstructorReturn.hasOwnProperty('default') ? _possibleConstructorReturn['default'] : _possibleConstructorReturn;
    _inherits = _inherits && _inherits.hasOwnProperty('default') ? _inherits['default'] : _inherits;
    _toConsumableArray = _toConsumableArray && _toConsumableArray.hasOwnProperty('default') ? _toConsumableArray['default'] : _toConsumableArray;
    _slicedToArray = _slicedToArray && _slicedToArray.hasOwnProperty('default') ? _slicedToArray['default'] : _slicedToArray;
    _regeneratorRuntime = _regeneratorRuntime && _regeneratorRuntime.hasOwnProperty('default') ? _regeneratorRuntime['default'] : _regeneratorRuntime;
    _defineProperty = _defineProperty && _defineProperty.hasOwnProperty('default') ? _defineProperty['default'] : _defineProperty;

    /*!
     * modernizr v3.6.0
     * Build https://modernizr.com/download?-promises-typedarrays-webaudio-dontmin
     *
     * Copyright (c)
     *  Faruk Ates
     *  Paul Irish
     *  Alex Sexton
     *  Ryan Seddon
     *  Patrick Kettner
     *  Stu Cox
     *  Richard Herrera

     * MIT License
     */
    var browsernizr = (function (window) {
        var tests = [];
        /**
         *
         * ModernizrProto is the constructor for Modernizr
         *
         * @class
         * @access public
         */
        var ModernizrProto = {
            // The current version, dummy
            _version: '3.6.0',
            // Any settings that don't work as separate modules
            // can go in here as configuration.
            _config: {
                'classPrefix': '',
                'enableClasses': true,
                'enableJSClass': true,
                'usePrefixes': true
            },
            // Queue of tests
            _q: [],
            // Stub these for people who are listening
            on: function on(test, cb) {
                // I don't really think people should do this, but we can
                // safe guard it a bit.
                // -- NOTE:: this gets WAY overridden in src/addTest for actual async tests.
                // This is in case people listen to synchronous tests. I would leave it out,
                // but the code to *disallow* sync tests in the real version of this
                // function is actually larger than this.
                var self = this;
                setTimeout(function () {
                    cb(self[test]);
                }, 0);
            },
            addTest: function addTest(name, fn, options) {
                tests.push({ name: name, fn: fn, options: options });
            },
            addAsyncTest: function addAsyncTest(fn) {
                tests.push({ name: null, fn: fn });
            }
        };
        // Fake some of Object.create so we can force non test results to be non "own" properties.
        var Modernizr = function Modernizr() {};
        Modernizr.prototype = ModernizrProto;
        // Leak modernizr globally when you `require` it rather than force it here.
        // Overwrite name so constructor name is nicer :D
        Modernizr = new Modernizr();
        var classes = [];
        /**
         * is returns a boolean if the typeof an obj is exactly type.
         *
         * @access private
         * @function is
         * @param {*} obj - A thing we want to check the type of
         * @param {string} type - A string to compare the typeof against
         * @returns {boolean}
         */
        function is(obj, type) {
            return (typeof obj === 'undefined' ? 'undefined' : _typeof(obj)) === type;
        }
        /**
         * Run through all tests and detect their support in the current UA.
         *
         * @access private
         */
        function testRunner() {
            var featureNames;
            var feature;
            var aliasIdx;
            var result;
            var nameIdx;
            var featureName;
            var featureNameSplit;
            for (var featureIdx in tests) {
                if (tests.hasOwnProperty(featureIdx)) {
                    featureNames = [];
                    feature = tests[featureIdx];
                    // run the test, throw the return value into the Modernizr,
                    // then based on that boolean, define an appropriate className
                    // and push it into an array of classes we'll join later.
                    //
                    // If there is no name, it's an 'async' test that is run,
                    // but not directly added to the object. That should
                    // be done with a post-run addTest call.
                    if (feature.name) {
                        featureNames.push(feature.name.toLowerCase());
                        if (feature.options && feature.options.aliases && feature.options.aliases.length) {
                            // Add all the aliases into the names list
                            for (aliasIdx = 0; aliasIdx < feature.options.aliases.length; aliasIdx++) {
                                featureNames.push(feature.options.aliases[aliasIdx].toLowerCase());
                            }
                        }
                    }
                    // Run the test, or use the raw value if it's not a function
                    result = is(feature.fn, 'function') ? feature.fn() : feature.fn;
                    // Set each of the names on the Modernizr object
                    for (nameIdx = 0; nameIdx < featureNames.length; nameIdx++) {
                        featureName = featureNames[nameIdx];
                        // Support dot properties as sub tests. We don't do checking to make sure
                        // that the implied parent tests have been added. You must call them in
                        // order (either in the test, or make the parent test a dependency).
                        //
                        // Cap it to TWO to make the logic simple and because who needs that kind of subtesting
                        // hashtag famous last words
                        featureNameSplit = featureName.split('.');
                        if (featureNameSplit.length === 1) {
                            Modernizr[featureNameSplit[0]] = result;
                        } else {
                            // cast to a Boolean, if not one already
                            if (Modernizr[featureNameSplit[0]] && !(Modernizr[featureNameSplit[0]] instanceof Boolean)) {
                                Modernizr[featureNameSplit[0]] = new Boolean(Modernizr[featureNameSplit[0]]);
                            }
                            Modernizr[featureNameSplit[0]][featureNameSplit[1]] = result;
                        }
                        classes.push((result ? '' : 'no-') + featureNameSplit.join('-'));
                    }
                }
            }
        }
        /*!
        {
          "name": "ES6 Promises",
          "property": "promises",
          "caniuse": "promises",
          "polyfills": ["es6promises"],
          "authors": ["Krister Kari", "Jake Archibald"],
          "tags": ["es6"],
          "notes": [{
            "name": "The ES6 promises spec",
            "href": "https://github.com/domenic/promises-unwrapping"
          },{
            "name": "Chromium dashboard - ES6 Promises",
            "href": "https://www.chromestatus.com/features/5681726336532480"
          },{
            "name": "JavaScript Promises: There and back again - HTML5 Rocks",
            "href": "http://www.html5rocks.com/en/tutorials/es6/promises/"
          }]
        }
        !*/
        /* DOC
        Check if browser implements ECMAScript 6 Promises per specification.
        */
        Modernizr.addTest('promises', function () {
            return 'Promise' in window &&
            // Some of these methods are missing from
            // Firefox/Chrome experimental implementations
            'resolve' in window.Promise && 'reject' in window.Promise && 'all' in window.Promise && 'race' in window.Promise &&
            // Older version of the spec had a resolver object
            // as the arg rather than a function
            function () {
                var resolve;
                new window.Promise(function (r) {
                    resolve = r;
                });
                return typeof resolve === 'function';
            }();
        });
        /*!
        {
          "name": "Typed arrays",
          "property": "typedarrays",
          "caniuse": "typedarrays",
          "tags": ["js"],
          "authors": ["Stanley Stuart (@fivetanley)"],
          "notes": [{
            "name": "MDN documentation",
            "href": "https://developer.mozilla.org/en-US/docs/JavaScript_typed_arrays"
          },{
            "name": "Kronos spec",
            "href": "https://www.khronos.org/registry/typedarray/specs/latest/"
          }],
          "polyfills": ["joshuabell-polyfill"]
        }
        !*/
        /* DOC
        Detects support for native binary data manipulation via Typed Arrays in JavaScript.
        
        Does not check for DataView support; use `Modernizr.dataview` for that.
        */
        // Should fail in:
        // Internet Explorer <= 9
        // Firefox <= 3.6
        // Chrome <= 6.0
        // iOS Safari < 4.2
        // Safari < 5.1
        // Opera < 11.6
        // Opera Mini, <= 7.0
        // Android Browser < 4.0
        // Blackberry Browser < 10.0
        Modernizr.addTest('typedarrays', 'ArrayBuffer' in window);
        /*!
        {
          "name": "Web Audio API",
          "property": "webaudio",
          "caniuse": "audio-api",
          "polyfills": ["xaudiojs", "dynamicaudiojs", "audiolibjs"],
          "tags": ["audio", "media"],
          "builderAliases": ["audio_webaudio_api"],
          "authors": ["Addy Osmani"],
          "notes": [{
            "name": "W3 Specification",
            "href": "https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/specification.html"
          }]
        }
        !*/
        /* DOC
        Detects the older non standard webaudio API, (as opposed to the standards based AudioContext API)
        */
        Modernizr.addTest('webaudio', function () {
            var prefixed = 'webkitAudioContext' in window;
            var unprefixed = 'AudioContext' in window;
            if (Modernizr._config.usePrefixes) {
                return prefixed || unprefixed;
            }
            return unprefixed;
        });
        // Run each test
        testRunner();
        delete ModernizrProto.addTest;
        delete ModernizrProto.addAsyncTest;
        // Run the things that are supposed to run after the tests
        for (var i = 0; i < Modernizr._q.length; i++) {
            Modernizr._q[i]();
        }
        // Leak Modernizr namespace
        return Modernizr;
    })(window);

    var createInvalidStateError = function createInvalidStateError() {
        try {
            return new DOMException('', 'InvalidStateError');
        } catch (err) {
            var exception = new Error();
            exception.code = 11;
            exception.name = 'InvalidStateError';
            return exception;
        }
    };

    var AUDIO_NODE_STORE = new WeakMap();
    var AUDIO_GRAPHS = new WeakMap();
    var AUDIO_PARAM_STORE = new WeakMap();
    var CONTEXT_STORE = new WeakMap();
    var DETACHED_ARRAY_BUFFERS = new WeakSet();
    // This clunky name is borrowed from the spec. :-)
    var NODE_NAME_TO_PROCESSOR_DEFINITION_MAPS = new WeakMap();
    var NODE_TO_PROCESSOR_MAPS = new WeakMap();
    var TEST_RESULTS = new WeakMap();

    var getNativeContext = function getNativeContext(context) {
        var nativeContext = CONTEXT_STORE.get(context);
        if (nativeContext === undefined) {
            throw createInvalidStateError();
        }
        return nativeContext;
    };

    var DEFAULT_OPTIONS = {
        channelCount: 2,
        channelCountMode: 'max',
        channelInterpretation: 'speakers',
        fftSize: 2048,
        maxDecibels: -30,
        minDecibels: -100,
        smoothingTimeConstant: 0.8
    };
    var createAnalyserNodeConstructor = function createAnalyserNodeConstructor(createAnalyserNodeRenderer, createNativeAnalyserNode, isNativeOfflineAudioContext, noneAudioDestinationNodeConstructor) {
        return function (_noneAudioDestination) {
            _inherits(AnalyserNode, _noneAudioDestination);

            function AnalyserNode(context) {
                var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : DEFAULT_OPTIONS;

                _classCallCheck(this, AnalyserNode);

                var nativeContext = getNativeContext(context);
                var mergedOptions = Object.assign({}, DEFAULT_OPTIONS, options);
                var nativeAnalyserNode = createNativeAnalyserNode(nativeContext, mergedOptions);
                var analyserNodeRenderer = isNativeOfflineAudioContext(nativeContext) ? createAnalyserNodeRenderer() : null;

                var _this = _possibleConstructorReturn(this, (AnalyserNode.__proto__ || Object.getPrototypeOf(AnalyserNode)).call(this, context, nativeAnalyserNode, analyserNodeRenderer));

                _this._nativeAnalyserNode = nativeAnalyserNode;
                return _this;
            }

            _createClass(AnalyserNode, [{
                key: 'getByteFrequencyData',
                value: function getByteFrequencyData(array) {
                    this._nativeAnalyserNode.getByteFrequencyData(array);
                }
            }, {
                key: 'getByteTimeDomainData',
                value: function getByteTimeDomainData(array) {
                    this._nativeAnalyserNode.getByteTimeDomainData(array);
                }
            }, {
                key: 'getFloatFrequencyData',
                value: function getFloatFrequencyData(array) {
                    this._nativeAnalyserNode.getFloatFrequencyData(array);
                }
            }, {
                key: 'getFloatTimeDomainData',
                value: function getFloatTimeDomainData(array) {
                    this._nativeAnalyserNode.getFloatTimeDomainData(array);
                }
            }, {
                key: 'fftSize',
                get: function get() {
                    return this._nativeAnalyserNode.fftSize;
                },
                set: function set(value) {
                    this._nativeAnalyserNode.fftSize = value;
                }
            }, {
                key: 'frequencyBinCount',
                get: function get() {
                    return this._nativeAnalyserNode.frequencyBinCount;
                }
            }, {
                key: 'maxDecibels',
                get: function get() {
                    return this._nativeAnalyserNode.maxDecibels;
                },
                set: function set(value) {
                    this._nativeAnalyserNode.maxDecibels = value;
                }
            }, {
                key: 'minDecibels',
                get: function get() {
                    return this._nativeAnalyserNode.minDecibels;
                },
                set: function set(value) {
                    this._nativeAnalyserNode.minDecibels = value;
                }
            }, {
                key: 'smoothingTimeConstant',
                get: function get() {
                    return this._nativeAnalyserNode.smoothingTimeConstant;
                },
                set: function set(value) {
                    this._nativeAnalyserNode.smoothingTimeConstant = value;
                }
            }]);

            return AnalyserNode;
        }(noneAudioDestinationNodeConstructor);
    };

    var getNativeAudioNode = function getNativeAudioNode(audioNode) {
        var nativeAudioNode = AUDIO_NODE_STORE.get(audioNode);
        if (nativeAudioNode === undefined) {
            throw new Error('The associated nativeAudioNode is missing.');
        }
        return nativeAudioNode;
    };

    var isOwnedByContext = function isOwnedByContext(nativeAudioNode, nativeContext) {
        // @todo The type definition of TypeScript wrongly defines the context property of an AudioNode as an AudioContext.
        // @todo https://github.com/Microsoft/TypeScript/blob/master/lib/lib.dom.d.ts#L1415
        return nativeAudioNode.context === nativeContext;
    };

    function getAudioGraph(anyContext) {
        var audioGraph = AUDIO_GRAPHS.get(anyContext);
        if (audioGraph === undefined) {
            throw new Error('Missing the audio graph of the given context.');
        }
        return audioGraph;
    }

    var getAudioNodeConnections = function getAudioNodeConnections(anyAudioNode) {
        var audioGraph = getAudioGraph(anyAudioNode.context);
        var audioNodeConnections = audioGraph.nodes.get(anyAudioNode);
        if (audioNodeConnections === undefined) {
            throw new Error('Missing the connections of the given AudioNode in the audio graph.');
        }
        return audioNodeConnections;
    };

    var getAudioNodeRenderer = function getAudioNodeRenderer(anyAudioNode) {
        var audioNodeConnections = getAudioNodeConnections(anyAudioNode);
        if (audioNodeConnections.renderer === null) {
            throw new Error('Missing the renderer of the given AudioNode in the audio graph.');
        }
        return audioNodeConnections.renderer;
    };

    var renderInputsOfAudioNode = function renderInputsOfAudioNode(audioNode, nativeOfflineAudioContext, nativeAudioNode) {
        var audioNodeConnections = getAudioNodeConnections(audioNode);
        return Promise.all(audioNodeConnections.inputs.map(function (connections, input) {
            return Array.from(connections.values()).map(function (_ref) {
                var _ref2 = _slicedToArray(_ref, 2),
                    source = _ref2[0],
                    output = _ref2[1];

                return getAudioNodeRenderer(source).render(source, nativeOfflineAudioContext).then(function (node) {
                    return node.connect(nativeAudioNode, output, input);
                });
            });
        }).reduce(function (allRenderingPromises, renderingPromises) {
            return [].concat(_toConsumableArray(allRenderingPromises), _toConsumableArray(renderingPromises));
        }, []));
    };

    var _this = undefined;
    var createAnalyserNodeRendererFactory = function createAnalyserNodeRendererFactory(createNativeAnalyserNode) {
        return function () {
            var nativeAnalyserNode = null;
            return {
                render: function render(proxy, nativeOfflineAudioContext) {
                    return tslib_1.__awaiter(_this, void 0, void 0, /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {
                        var options;
                        return _regeneratorRuntime.wrap(function _callee$(_context) {
                            while (1) {
                                switch (_context.prev = _context.next) {
                                    case 0:
                                        if (!(nativeAnalyserNode !== null)) {
                                            _context.next = 2;
                                            break;
                                        }

                                        return _context.abrupt('return', nativeAnalyserNode);

                                    case 2:
                                        nativeAnalyserNode = getNativeAudioNode(proxy);
                                        /*
                                         * If the initially used nativeAnalyserNode was not constructed on the same OfflineAudioContext it needs to be created
                                         * again.
                                         */
                                        if (!isOwnedByContext(nativeAnalyserNode, nativeOfflineAudioContext)) {
                                            options = {
                                                channelCount: nativeAnalyserNode.channelCount,
                                                channelCountMode: nativeAnalyserNode.channelCountMode,
                                                channelInterpretation: nativeAnalyserNode.channelInterpretation,
                                                fftSize: nativeAnalyserNode.fftSize,
                                                maxDecibels: nativeAnalyserNode.maxDecibels,
                                                minDecibels: nativeAnalyserNode.minDecibels,
                                                smoothingTimeConstant: nativeAnalyserNode.smoothingTimeConstant
                                            };

                                            nativeAnalyserNode = createNativeAnalyserNode(nativeOfflineAudioContext, options);
                                        }
                                        _context.next = 6;
                                        return renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAnalyserNode);

                                    case 6:
                                        return _context.abrupt('return', nativeAnalyserNode);

                                    case 7:
                                    case 'end':
                                        return _context.stop();
                                }
                            }
                        }, _callee, this);
                    }));
                }
            };
        };
    };

    var ONGOING_TESTS = new Map();
    function cacheTestResult(tester, test) {
        var cachedTestResult = TEST_RESULTS.get(tester);
        if (cachedTestResult !== undefined) {
            return cachedTestResult;
        }
        var ongoingTest = ONGOING_TESTS.get(tester);
        if (ongoingTest !== undefined) {
            return ongoingTest;
        }
        var synchronousTestResult = test();
        if (synchronousTestResult instanceof Promise) {
            ONGOING_TESTS.set(tester, synchronousTestResult);
            return synchronousTestResult.then(function (finalTestResult) {
                ONGOING_TESTS.delete(tester);
                TEST_RESULTS.set(tester, finalTestResult);
                return finalTestResult;
            });
        }
        TEST_RESULTS.set(tester, synchronousTestResult);
        return synchronousTestResult;
    }

    var testAudioBufferCopyChannelMethodsSubarraySupport = function testAudioBufferCopyChannelMethodsSubarraySupport(nativeAudioBuffer) {
        var source = new Float32Array(2);
        try {
            /*
             * Only Firefox does not fully support the copyFromChannel() and copyToChannel() methods. Therefore testing one of those
             * methods is enough to know if the other one it supported as well.
             */
            nativeAudioBuffer.copyToChannel(source, 0, nativeAudioBuffer.length - 1);
        } catch (err) {
            return false;
        }
        return true;
    };

    var createIndexSizeError = function createIndexSizeError() {
        try {
            return new DOMException('', 'IndexSizeError');
        } catch (err) {
            var exception = new Error();
            exception.code = 1;
            exception.name = 'IndexSizeError';
            return exception;
        }
    };

    var wrapAudioBufferCopyChannelMethods = function wrapAudioBufferCopyChannelMethods(audioBuffer) {
        audioBuffer.copyFromChannel = function (destination, channelNumber) {
            var startInChannel = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;

            if (channelNumber >= audioBuffer.numberOfChannels || startInChannel >= audioBuffer.length) {
                throw createIndexSizeError();
            }
            var channelData = audioBuffer.getChannelData(channelNumber);
            var channelLength = channelData.length;
            var destinationLength = destination.length;
            for (var i = 0; i + startInChannel < channelLength && i < destinationLength; i += 1) {
                destination[i] = channelData[i + startInChannel];
            }
        };
        audioBuffer.copyToChannel = function (source, channelNumber) {
            var startInChannel = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;

            if (channelNumber >= audioBuffer.numberOfChannels || startInChannel >= audioBuffer.length) {
                throw createIndexSizeError();
            }
            var channelData = audioBuffer.getChannelData(channelNumber);
            var channelLength = channelData.length;
            var sourceLength = source.length;
            for (var i = 0; i + startInChannel < channelLength && i < sourceLength; i += 1) {
                channelData[i + startInChannel] = source[i];
            }
        };
    };

    var wrapAudioBufferCopyChannelMethodsSubarray = function wrapAudioBufferCopyChannelMethodsSubarray(audioBuffer) {
        audioBuffer.copyFromChannel = function (copyFromChannel) {
            return function (destination, channelNumber) {
                var startInChannel = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;

                if (startInChannel < audioBuffer.length && audioBuffer.length - startInChannel < destination.length) {
                    return copyFromChannel.call(audioBuffer, destination.subarray(0, audioBuffer.length - startInChannel), channelNumber, startInChannel);
                }
                return copyFromChannel.call(audioBuffer, destination, channelNumber, startInChannel);
            };
        }(audioBuffer.copyFromChannel);
        audioBuffer.copyToChannel = function (copyToChannel) {
            return function (source, channelNumber) {
                var startInChannel = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;

                if (startInChannel < audioBuffer.length && audioBuffer.length - startInChannel < source.length) {
                    return copyToChannel.call(audioBuffer, source.subarray(0, audioBuffer.length - startInChannel), channelNumber, startInChannel);
                }
                return copyToChannel.call(audioBuffer, source, channelNumber, startInChannel);
            };
        }(audioBuffer.copyToChannel);
    };

    var DEFAULT_OPTIONS$1 = {
        numberOfChannels: 1
    };
    var createAudioBufferConstructor = function createAudioBufferConstructor(nativeOfflineAudioContextConstructor) {
        var nativeOfflineAudioContext = null;
        return function () {
            function AudioBuffer(options) {
                _classCallCheck(this, AudioBuffer);

                if (nativeOfflineAudioContextConstructor === null) {
                    throw new Error(); // @todo
                }

                var _Object$assign = Object.assign({}, DEFAULT_OPTIONS$1, options),
                    length = _Object$assign.length,
                    numberOfChannels = _Object$assign.numberOfChannels,
                    sampleRate = _Object$assign.sampleRate;

                if (nativeOfflineAudioContext === null) {
                    nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
                }
                var audioBuffer = nativeOfflineAudioContext.createBuffer(numberOfChannels, length, sampleRate);
                // Bug #5: Safari does not support copyFromChannel() and copyToChannel().
                if (typeof audioBuffer.copyFromChannel !== 'function') {
                    wrapAudioBufferCopyChannelMethods(audioBuffer);
                    // Bug #42: Firefox does not yet fully support copyFromChannel() and copyToChannel().
                } else if (!cacheTestResult(testAudioBufferCopyChannelMethodsSubarraySupport, function () {
                    return testAudioBufferCopyChannelMethodsSubarraySupport(audioBuffer);
                })) {
                    wrapAudioBufferCopyChannelMethodsSubarray(audioBuffer);
                }
                /*
                 * This does violate all good pratices but it is necessary to allow this AudioBuffer to be used with native
                 * (Offline)AudioContexts.
                 */
                return audioBuffer;
            }
            // This method needs to be defined to convince TypeScript that the IAudioBuffer will be implemented.


            _createClass(AudioBuffer, [{
                key: 'getChannelData',
                value: function getChannelData(_) {
                    return new Float32Array(0);
                }
                // This method needs to be defined to convince TypeScript that the IAudioBuffer will be implemented.

            }, {
                key: 'copyFromChannel',
                value: function copyFromChannel(_1, _2) {
                } // tslint:disable-line:no-empty
                // This method needs to be defined to convince TypeScript that the IAudioBuffer will be implemented.

            }, {
                key: 'copyToChannel',
                value: function copyToChannel(_1, _2) {
                } // tslint:disable-line:no-empty

            }]);

            return AudioBuffer;
        }();
    };

    var DEFAULT_OPTIONS$2 = {
        buffer: null,
        channelCount: 2,
        channelCountMode: 'max',
        channelInterpretation: 'speakers',
        detune: 0,
        loop: false,
        loopEnd: 0,
        loopStart: 0,
        playbackRate: 1
    };
    var createAudioBufferSourceNodeConstructor = function createAudioBufferSourceNodeConstructor(createAudioBufferSourceNodeRenderer, createAudioParam, createInvalidStateError, createNativeAudioBufferSourceNode, isNativeOfflineAudioContext, noneAudioDestinationNodeConstructor) {
        return function (_noneAudioDestination) {
            _inherits(AudioBufferSourceNode, _noneAudioDestination);

            function AudioBufferSourceNode(context) {
                var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : DEFAULT_OPTIONS$2;

                _classCallCheck(this, AudioBufferSourceNode);

                var nativeContext = getNativeContext(context);
                var mergedOptions = Object.assign({}, DEFAULT_OPTIONS$2, options);
                var nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeContext, mergedOptions);
                var isOffline = isNativeOfflineAudioContext(nativeContext);
                var audioBufferSourceNodeRenderer = isOffline ? createAudioBufferSourceNodeRenderer() : null;

                var _this = _possibleConstructorReturn(this, (AudioBufferSourceNode.__proto__ || Object.getPrototypeOf(AudioBufferSourceNode)).call(this, context, nativeAudioBufferSourceNode, audioBufferSourceNodeRenderer));

                _this._audioBufferSourceNodeRenderer = audioBufferSourceNodeRenderer;
                _this._detune = createAudioParam(context, isOffline, nativeAudioBufferSourceNode.detune);
                _this._isBufferNullified = false;
                _this._isBufferSet = false;
                _this._nativeAudioBufferSourceNode = nativeAudioBufferSourceNode;
                // Bug #73: Edge, Firefox & Safari do not export the correct values for maxValue and minValue.
                _this._playbackRate = createAudioParam(context, isOffline, nativeAudioBufferSourceNode.playbackRate, 3.4028234663852886e38, -3.4028234663852886e38);
                return _this;
            }

            _createClass(AudioBufferSourceNode, [{
                key: 'start',
                value: function start() {
                    var when = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;
                    var offset = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
                    var duration = arguments[2];

                    this._nativeAudioBufferSourceNode.start(when, offset, duration);
                    if (this._audioBufferSourceNodeRenderer !== null) {
                        this._audioBufferSourceNodeRenderer.start = duration === undefined ? [when, offset] : [when, offset, duration];
                    }
                }
            }, {
                key: 'stop',
                value: function stop() {
                    var when = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;

                    this._nativeAudioBufferSourceNode.stop(when);
                    if (this._audioBufferSourceNodeRenderer !== null) {
                        this._audioBufferSourceNodeRenderer.stop = when;
                    }
                }
            }, {
                key: 'buffer',
                get: function get() {
                    if (this._isBufferNullified) {
                        return null;
                    }
                    return this._nativeAudioBufferSourceNode.buffer;
                },
                set: function set(value) {
                    // Bug #71: Edge does not allow to set the buffer to null.
                    try {
                        this._nativeAudioBufferSourceNode.buffer = value;
                    } catch (err) {
                        if (value !== null || err.code !== 17) {
                            throw err;
                        }
                        // @todo Create a new internal nativeAudioBufferSourceNode.
                        this._isBufferNullified = this._nativeAudioBufferSourceNode.buffer !== null;
                    }
                    // Bug #72: Only Chrome, Edge & Opera do not allow to reassign the buffer yet.
                    if (value !== null) {
                        if (this._isBufferSet) {
                            throw createInvalidStateError();
                        }
                        this._isBufferSet = true;
                    }
                }
            }, {
                key: 'onended',
                get: function get() {
                    return this._nativeAudioBufferSourceNode.onended;
                },
                set: function set(value) {
                    this._nativeAudioBufferSourceNode.onended = value;
                }
            }, {
                key: 'detune',
                get: function get() {
                    return this._detune;
                }
            }, {
                key: 'loop',
                get: function get() {
                    return this._nativeAudioBufferSourceNode.loop;
                },
                set: function set(value) {
                    this._nativeAudioBufferSourceNode.loop = value;
                }
            }, {
                key: 'loopEnd',
                get: function get() {
                    return this._nativeAudioBufferSourceNode.loopEnd;
                },
                set: function set(value) {
                    this._nativeAudioBufferSourceNode.loopEnd = value;
                }
            }, {
                key: 'loopStart',
                get: function get() {
                    return this._nativeAudioBufferSourceNode.loopStart;
                },
                set: function set(value) {
                    this._nativeAudioBufferSourceNode.loopStart = value;
                }
            }, {
                key: 'playbackRate',
                get: function get() {
                    return this._playbackRate;
                }
            }]);

            return AudioBufferSourceNode;
        }(noneAudioDestinationNodeConstructor);
    };

    var _this$1 = undefined;
    var createAudioBufferSourceNodeRendererFactory = function createAudioBufferSourceNodeRendererFactory(createNativeAudioBufferSourceNode) {
        return function () {
            var nativeAudioBufferSourceNode = null;
            var start = null;
            var stop = null;
            return {
                set start(value) {
                    start = value;
                },
                set stop(value) {
                    stop = value;
                },
                render: function render(proxy, nativeOfflineAudioContext) {
                    return tslib_1.__awaiter(_this$1, void 0, void 0, /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {
                        var options, _nativeAudioBufferSou;

                        return _regeneratorRuntime.wrap(function _callee$(_context) {
                            while (1) {
                                switch (_context.prev = _context.next) {
                                    case 0:
                                        if (!(nativeAudioBufferSourceNode !== null)) {
                                            _context.next = 2;
                                            break;
                                        }

                                        return _context.abrupt('return', nativeAudioBufferSourceNode);

                                    case 2:
                                        nativeAudioBufferSourceNode = getNativeAudioNode(proxy);
                                        /*
                                         * If the initially used nativeAudioBufferSourceNode was not constructed on the same OfflineAudioContext it needs to be
                                         * created again.
                                         */
                                        if (!isOwnedByContext(nativeAudioBufferSourceNode, nativeOfflineAudioContext)) {
                                            options = {
                                                buffer: nativeAudioBufferSourceNode.buffer,
                                                channelCount: nativeAudioBufferSourceNode.channelCount,
                                                channelCountMode: nativeAudioBufferSourceNode.channelCountMode,
                                                channelInterpretation: nativeAudioBufferSourceNode.channelInterpretation,
                                                detune: 0,
                                                loop: nativeAudioBufferSourceNode.loop,
                                                loopEnd: nativeAudioBufferSourceNode.loopEnd,
                                                loopStart: nativeAudioBufferSourceNode.loopStart,
                                                playbackRate: nativeAudioBufferSourceNode.playbackRate.value
                                            };

                                            nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeOfflineAudioContext, options);
                                            if (start !== null) {
                                                (_nativeAudioBufferSou = nativeAudioBufferSourceNode).start.apply(_nativeAudioBufferSou, _toConsumableArray(start));
                                            }
                                            if (stop !== null) {
                                                nativeAudioBufferSourceNode.stop(stop);
                                            }
                                        }
                                        _context.next = 6;
                                        return renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioBufferSourceNode);

                                    case 6:
                                        return _context.abrupt('return', nativeAudioBufferSourceNode);

                                    case 7:
                                    case 'end':
                                        return _context.stop();
                                }
                            }
                        }, _callee, this);
                    }));
                }
            };
        };
    };

    var isAudioBufferSourceNode = function isAudioBufferSourceNode(audioNode) {
        return audioNode.hasOwnProperty('playbackRate');
    };

    var isAudioWorkletNode = function isAudioWorkletNode(audioNode) {
        return audioNode.hasOwnProperty('port');
    };

    var isBiquadFilterNode = function isBiquadFilterNode(audioNode) {
        return audioNode.hasOwnProperty('frequency') && audioNode.hasOwnProperty('gain');
    };

    var isConstantSourceNode = function isConstantSourceNode(audioNode) {
        return audioNode.hasOwnProperty('offset') !== undefined;
    };

    var isGainNode = function isGainNode(audioNode) {
        return !audioNode.hasOwnProperty('frequency') && audioNode.hasOwnProperty('gain');
    };

    var isOscillatorNode = function isOscillatorNode(audioNode) {
        return audioNode.hasOwnProperty('detune') && audioNode.hasOwnProperty('frequency');
    };

    var disconnectAudioParamInputConnections = function disconnectAudioParamInputConnections(audioGraph, audioParam, disconnectAudioNodeInputConnections) {
        var audioParamConnections = audioGraph.params.get(audioParam);
        if (audioParamConnections !== undefined) {
            audioParamConnections.inputs.forEach(function (_ref) {
                var _ref2 = _slicedToArray(_ref, 1),
                    source = _ref2[0];

                /*
                 * @todo Disconnect the AudioParam.
                 * source.disconnect(audioParam);
                 */
                disconnectAudioNodeInputConnections(audioGraph, source);
            });
        }
    };

    var disconnectAudioNodeInputConnections = function disconnectAudioNodeInputConnections(audioGraph, audioNode) {
        var audioNodeConnections = audioGraph.nodes.get(audioNode);
        if (audioNodeConnections !== undefined) {
            var numberOfInputs = audioNodeConnections.inputs.length;
            for (var i = 0; i < numberOfInputs; i += 1) {
                var connections = audioNodeConnections.inputs[i];
                var _iteratorNormalCompletion = true;
                var _didIteratorError = false;
                var _iteratorError = undefined;

                try {
                    for (var _iterator = Array.from(connections)[Symbol.iterator](), _step; !(_iteratorNormalCompletion = (_step = _iterator.next()).done); _iteratorNormalCompletion = true) {
                        var _step$value = _slicedToArray(_step.value, 1),
                            source = _step$value[0];

                        // @todo Disconnect the exact connection with its output and input parameters.
                        source.disconnect(audioNode);
                        disconnectAudioNodeInputConnections(audioGraph, source);
                    }
                } catch (err) {
                    _didIteratorError = true;
                    _iteratorError = err;
                } finally {
                    try {
                        if (!_iteratorNormalCompletion && _iterator.return) {
                            _iterator.return();
                        }
                    } finally {
                        if (_didIteratorError) {
                            throw _iteratorError;
                        }
                    }
                }
            }
            if (isAudioBufferSourceNode(audioNode)) {
                // @todo disconnectAudioParamInputConnections(audioGraph, audioNode.detune, disconnectAudioNodeInputConnections);
                disconnectAudioParamInputConnections(audioGraph, audioNode.playbackRate, disconnectAudioNodeInputConnections);
            } else if (isAudioWorkletNode(audioNode)) {
                var _iteratorNormalCompletion2 = true;
                var _didIteratorError2 = false;
                var _iteratorError2 = undefined;

                try {
                    for (var _iterator2 = Array.from(audioNode.parameters.values())[Symbol.iterator](), _step2; !(_iteratorNormalCompletion2 = (_step2 = _iterator2.next()).done); _iteratorNormalCompletion2 = true) {
                        var audioParam = _step2.value;

                        disconnectAudioParamInputConnections(audioGraph, audioParam, disconnectAudioNodeInputConnections);
                    }
                } catch (err) {
                    _didIteratorError2 = true;
                    _iteratorError2 = err;
                } finally {
                    try {
                        if (!_iteratorNormalCompletion2 && _iterator2.return) {
                            _iterator2.return();
                        }
                    } finally {
                        if (_didIteratorError2) {
                            throw _iteratorError2;
                        }
                    }
                }
            } else if (isBiquadFilterNode(audioNode)) {
                disconnectAudioParamInputConnections(audioGraph, audioNode.Q, disconnectAudioNodeInputConnections);
                disconnectAudioParamInputConnections(audioGraph, audioNode.detune, disconnectAudioNodeInputConnections);
                disconnectAudioParamInputConnections(audioGraph, audioNode.frequency, disconnectAudioNodeInputConnections);
                disconnectAudioParamInputConnections(audioGraph, audioNode.gain, disconnectAudioNodeInputConnections);
            } else if (isConstantSourceNode(audioNode)) {
                disconnectAudioParamInputConnections(audioGraph, audioNode.offset, disconnectAudioNodeInputConnections);
            } else if (isGainNode(audioNode)) {
                disconnectAudioParamInputConnections(audioGraph, audioNode.gain, disconnectAudioNodeInputConnections);
            } else if (isOscillatorNode(audioNode)) {
                disconnectAudioParamInputConnections(audioGraph, audioNode.detune, disconnectAudioNodeInputConnections);
                disconnectAudioParamInputConnections(audioGraph, audioNode.frequency, disconnectAudioNodeInputConnections);
            }
        }
    };

    var deleteAudioGraph = function deleteAudioGraph(context, nativeContext) {
        var audioGraph = AUDIO_GRAPHS.get(context);
        if (audioGraph !== undefined) {
            disconnectAudioNodeInputConnections(audioGraph, context.destination);
        }
        AUDIO_GRAPHS.delete(context);
        AUDIO_GRAPHS.delete(nativeContext);
        CONTEXT_STORE.delete(context);
        NODE_NAME_TO_PROCESSOR_DEFINITION_MAPS.delete(nativeContext);
        NODE_TO_PROCESSOR_MAPS.delete(nativeContext);
    };

    var isValidLatencyHint = function isValidLatencyHint(latencyHint) {
        return latencyHint === undefined || typeof latencyHint === 'number' || typeof latencyHint === 'string' && (latencyHint === 'balanced' || latencyHint === 'interactive' || latencyHint === 'playback');
    };

    var createAudioContextConstructor = function createAudioContextConstructor(baseAudioContextConstructor, createInvalidStateError, mediaElementAudioSourceNodeConstructor, mediaStreamAudioSourceNodeConstructor, nativeAudioContextConstructor) {
        return function (_baseAudioContextCons) {
            _inherits(AudioContext, _baseAudioContextCons);

            function AudioContext() {
                var options = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};

                _classCallCheck(this, AudioContext);

                if (nativeAudioContextConstructor === null) {
                    throw new Error(); // @todo
                }
                var nativeAudioContext = new nativeAudioContextConstructor(options);
                // Bug #51 Only Chrome and Opera throw an error if the given latencyHint is invalid.
                if (!isValidLatencyHint(options.latencyHint)) {
                    throw new TypeError('The provided value \'' + options.latencyHint + '\' is not a valid enum value of type AudioContextLatencyCategory.');
                }

                var _this = _possibleConstructorReturn(this, (AudioContext.__proto__ || Object.getPrototypeOf(AudioContext)).call(this, nativeAudioContext, nativeAudioContext.destination.channelCount));

                _this._state = null;
                _this._nativeAudioContext = nativeAudioContext;
                /*
                 * Bug #34: Chrome and Opera pretend to be running right away, but fire an onstatechange event when the state actually changes
                 * to 'running'.
                 */
                if (nativeAudioContext.state === 'running') {
                    _this._state = 'suspended';
                    var revokeState = function revokeState() {
                        if (_this._state === 'suspended') {
                            _this._state = null;
                        }
                        if (nativeAudioContext.removeEventListener) {
                            nativeAudioContext.removeEventListener('statechange', revokeState);
                        }
                    };
                    nativeAudioContext.addEventListener('statechange', revokeState);
                }
                return _this;
            }

            _createClass(AudioContext, [{
                key: 'createMediaElementSource',
                value: function createMediaElementSource(mediaElement) {
                    return new mediaElementAudioSourceNodeConstructor(this, { mediaElement: mediaElement });
                }
            }, {
                key: 'createMediaStreamSource',
                value: function createMediaStreamSource(mediaStream) {
                    return new mediaStreamAudioSourceNodeConstructor(this, { mediaStream: mediaStream });
                }
            }, {
                key: 'close',
                value: function close() {
                    var _this2 = this;

                    // Bug #35: Firefox does not throw an error if the AudioContext was closed before.
                    if (this.state === 'closed') {
                        return this._nativeAudioContext.close().then(function () {
                            throw createInvalidStateError();
                        });
                    }
                    // Bug #34: If the state was set to suspended before it should be revoked now.
                    if (this._state === 'suspended') {
                        this._state = null;
                    }
                    return this._nativeAudioContext.close().then(function () {
                        return deleteAudioGraph(_this2, _this2._nativeAudioContext);
                    });
                }
            }, {
                key: 'resume',
                value: function resume() {
                    return this._nativeAudioContext.resume().catch(function (err) {
                        // Bug #55: Chrome, Edge and Opera do throw an InvalidAccessError instead of an InvalidStateError.
                        // Bug #56: Safari invokes the catch handler but without an error.
                        if (err === undefined || err.code === 15) {
                            throw createInvalidStateError();
                        }
                        throw err;
                    });
                }
            }, {
                key: 'suspend',
                value: function suspend() {
                    return this._nativeAudioContext.suspend().catch(function (err) {
                        // Bug #56: Safari invokes the catch handler but without an error.
                        if (err === undefined) {
                            throw createInvalidStateError();
                        }
                        throw err;
                    });
                }
            }, {
                key: 'state',
                get: function get() {
                    return this._state !== null ? this._state : this._nativeAudioContext.state;
                }
            }]);

            return AudioContext;
        }(baseAudioContextConstructor);
    };

    var createAudioDestinationNodeConstructor = function createAudioDestinationNodeConstructor(audioNodeConstructor, createAudioDestinationNodeRenderer, createIndexSizeError, createInvalidStateError, createNativeAudioDestinationNode, isNativeOfflineAudioContext) {
        return function (_audioNodeConstructor) {
            _inherits(AudioDestinationNode, _audioNodeConstructor);

            function AudioDestinationNode(context, channelCount) {
                _classCallCheck(this, AudioDestinationNode);

                var nativeContext = getNativeContext(context);
                var isOffline = isNativeOfflineAudioContext(nativeContext);
                var nativeAudioDestinationNode = createNativeAudioDestinationNode(nativeContext, channelCount, isOffline);
                var audioDestinationNodeRenderer = isOffline ? createAudioDestinationNodeRenderer() : null;
                var audioGraph = { nodes: new WeakMap(), params: new WeakMap() };
                AUDIO_GRAPHS.set(context, audioGraph);
                AUDIO_GRAPHS.set(nativeContext, audioGraph);

                var _this = _possibleConstructorReturn(this, (AudioDestinationNode.__proto__ || Object.getPrototypeOf(AudioDestinationNode)).call(this, context, nativeAudioDestinationNode, audioDestinationNodeRenderer));

                _this._isNodeOfNativeOfflineAudioContext = isOffline;
                _this._nativeAudioDestinationNode = nativeAudioDestinationNode;
                return _this;
            }

            _createClass(AudioDestinationNode, [{
                key: 'channelCount',
                get: function get() {
                    return this._nativeAudioDestinationNode.channelCount;
                },
                set: function set(value) {
                    // Bug #52: Chrome, Edge, Opera & Safari do not throw an exception at all.
                    // Bug #54: Firefox does throw an IndexSizeError.
                    if (this._isNodeOfNativeOfflineAudioContext) {
                        throw createInvalidStateError();
                    }
                    // Bug #47: The AudioDestinationNode in Edge and Safari do not initialize the maxChannelCount property correctly.
                    if (value > this._nativeAudioDestinationNode.maxChannelCount) {
                        throw createIndexSizeError();
                    }
                    this._nativeAudioDestinationNode.channelCount = value;
                }
            }, {
                key: 'channelCountMode',
                get: function get() {
                    return this._nativeAudioDestinationNode.channelCountMode;
                },
                set: function set(value) {
                    // Bug #53: No browser does throw an exception yet.
                    if (this._isNodeOfNativeOfflineAudioContext) {
                        throw createInvalidStateError();
                    }
                    this._nativeAudioDestinationNode.channelCountMode = value;
                }
            }, {
                key: 'maxChannelCount',
                get: function get() {
                    return this._nativeAudioDestinationNode.maxChannelCount;
                }
            }]);

            return AudioDestinationNode;
        }(audioNodeConstructor);
    };

    var _this$2 = undefined;
    var createAudioDestinationNodeRenderer = function createAudioDestinationNodeRenderer() {
        var nativeAudioDestinationNode = null;
        return {
            render: function render(proxy, nativeOfflineAudioContext) {
                return tslib_1.__awaiter(_this$2, void 0, void 0, /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {
                    return _regeneratorRuntime.wrap(function _callee$(_context) {
                        while (1) {
                            switch (_context.prev = _context.next) {
                                case 0:
                                    if (!(nativeAudioDestinationNode !== null)) {
                                        _context.next = 2;
                                        break;
                                    }

                                    return _context.abrupt("return", nativeAudioDestinationNode);

                                case 2:
                                    nativeAudioDestinationNode = nativeOfflineAudioContext.destination;
                                    _context.next = 5;
                                    return renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioDestinationNode);

                                case 5:
                                    return _context.abrupt("return", nativeAudioDestinationNode);

                                case 6:
                                case "end":
                                    return _context.stop();
                            }
                        }
                    }, _callee, this);
                }));
            }
        };
    };

    var EventTarget = function () {
        function EventTarget() {
            _classCallCheck(this, EventTarget);
        }

        _createClass(EventTarget, [{
            key: "addEventListener",
            value: function addEventListener(type, listener, // @todo EventListenerOrEventListenerObject | null = null,
            options) {
            }
        }, {
            key: "dispatchEvent",
            value: function dispatchEvent(evt) {
                return false;
            }
        }, {
            key: "removeEventListener",
            value: function removeEventListener(type, listener, // @todo EventListenerOrEventListenerObject | null = null,
            options) {
            }
        }]);

        return EventTarget;
    }();

    var isAudioNode = function isAudioNode(audioNodeOrAudioParam) {
        return audioNodeOrAudioParam.context !== undefined;
    };

    function getAudioParamConnections(anyContext, audioParam) {
        var audioGraph = getAudioGraph(anyContext);
        var audioParamConnections = audioGraph.params.get(audioParam);
        if (audioParamConnections === undefined) {
            throw new Error('Missing the connections of the given AudioParam in the audio graph.');
        }
        return audioParamConnections;
    }

    var getNativeAudioParam = function getNativeAudioParam(audioParam) {
        var nativeAudioParam = AUDIO_PARAM_STORE.get(audioParam);
        if (nativeAudioParam === undefined) {
            throw new Error('The associated nativeAudioParam is missing.');
        }
        return nativeAudioParam;
    };

    var testAudioNodeDisconnectMethodSupport = function testAudioNodeDisconnectMethodSupport(nativeAudioContext) {
        return new Promise(function (resolve) {
            var analyzer = nativeAudioContext.createScriptProcessor(256, 1, 1);
            var dummy = nativeAudioContext.createGain();
            // Safari does not play buffers which contain just one frame.
            var ones = nativeAudioContext.createBuffer(1, 2, 44100);
            var channelData = ones.getChannelData(0);
            channelData[0] = 1;
            channelData[1] = 1;
            var source = nativeAudioContext.createBufferSource();
            source.buffer = ones;
            source.loop = true;
            source.connect(analyzer);
            analyzer.connect(nativeAudioContext.destination);
            source.connect(dummy);
            source.disconnect(dummy);
            analyzer.onaudioprocess = function (event) {
                var chnnlDt = event.inputBuffer.getChannelData(0);
                if (Array.prototype.some.call(chnnlDt, function (sample) {
                    return sample === 1;
                })) {
                    resolve(true);
                } else {
                    resolve(false);
                }
                source.stop();
                analyzer.onaudioprocess = null;
                source.disconnect(analyzer);
                analyzer.disconnect(nativeAudioContext.destination);
            };
            source.start();
        });
    };

    var wrapAudioNodeDisconnectMethod = function wrapAudioNodeDisconnectMethod(nativeAudioNode) {
        var destinations = new Map();
        nativeAudioNode.connect = function (connect) {
            return function (destination) {
                var output = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
                var input = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;

                destinations.set(destination, { input: input, output: output });
                if (destination instanceof AudioNode) {
                    return connect.call(nativeAudioNode, destination, output, input);
                }
                return connect.call(nativeAudioNode, destination, output);
            };
        }(nativeAudioNode.connect);
        nativeAudioNode.disconnect = function (disconnect) {
            return function (outputOrDestination, _output, _input) {
                disconnect.apply(nativeAudioNode);
                if (outputOrDestination === undefined) {
                    destinations.clear();
                } else if (destinations.has(outputOrDestination)) {
                    destinations.delete(outputOrDestination);
                    destinations.forEach(function (_ref, dstntn) {
                        var input = _ref.input,
                            output = _ref.output;

                        nativeAudioNode.connect(dstntn, input, output);
                    });
                }
            };
        }(nativeAudioNode.disconnect);
    };

    var addAudioNode = function addAudioNode(context, audioNode, audioNoderRender, nativeAudioNode) {
        var audioGraphOfContext = getAudioGraph(context);
        var inputs = [];
        for (var i = 0; i < nativeAudioNode.numberOfInputs; i += 1) {
            inputs.push(new Set());
        }
        var audioNodeConnections = { inputs: inputs, outputs: new Set(), renderer: audioNoderRender };
        audioGraphOfContext.nodes.set(audioNode, audioNodeConnections);
        audioGraphOfContext.nodes.set(nativeAudioNode, audioNodeConnections);
    };
    var addConnectionToAudioNode = function addConnectionToAudioNode(source, destination, output, input) {
        var audioNodeConnectionsOfSource = getAudioNodeConnections(source);
        var audioNodeConnectionsOfDestination = getAudioNodeConnections(destination);
        audioNodeConnectionsOfSource.outputs.add([destination, output, input]);
        audioNodeConnectionsOfDestination.inputs[input].add([source, output]);
    };
    var addConnectionToAudioParam = function addConnectionToAudioParam(context, source, destination, output) {
        var audioNodeConnections = getAudioNodeConnections(source);
        var audioParamConnections = getAudioParamConnections(context, destination);
        audioNodeConnections.outputs.add([destination, output]);
        audioParamConnections.inputs.add([source, output]);
    };
    var removeAnyConnection = function removeAnyConnection(source) {
        var audioNodeConnectionsOfSource = getAudioNodeConnections(source);
        var _iteratorNormalCompletion = true;
        var _didIteratorError = false;
        var _iteratorError = undefined;

        try {
            for (var _iterator = Array.from(audioNodeConnectionsOfSource.outputs.values())[Symbol.iterator](), _step; !(_iteratorNormalCompletion = (_step = _iterator.next()).done); _iteratorNormalCompletion = true) {
                var _step$value = _slicedToArray(_step.value, 1),
                    destination = _step$value[0];

                if (isAudioNode(destination)) {
                    var audioNodeConnectionsOfDestination = getAudioNodeConnections(destination);
                    var _iteratorNormalCompletion2 = true;
                    var _didIteratorError2 = false;
                    var _iteratorError2 = undefined;

                    try {
                        for (var _iterator2 = audioNodeConnectionsOfDestination.inputs[Symbol.iterator](), _step2; !(_iteratorNormalCompletion2 = (_step2 = _iterator2.next()).done); _iteratorNormalCompletion2 = true) {
                            var connectionsToInput = _step2.value;
                            var _iteratorNormalCompletion3 = true;
                            var _didIteratorError3 = false;
                            var _iteratorError3 = undefined;

                            try {
                                for (var _iterator3 = Array.from(connectionsToInput.values())[Symbol.iterator](), _step3; !(_iteratorNormalCompletion3 = (_step3 = _iterator3.next()).done); _iteratorNormalCompletion3 = true) {
                                    var connection = _step3.value;

                                    if (connection[0] === source) {
                                        connectionsToInput.delete(connection);
                                    }
                                }
                            } catch (err) {
                                _didIteratorError3 = true;
                                _iteratorError3 = err;
                            } finally {
                                try {
                                    if (!_iteratorNormalCompletion3 && _iterator3.return) {
                                        _iterator3.return();
                                    }
                                } finally {
                                    if (_didIteratorError3) {
                                        throw _iteratorError3;
                                    }
                                }
                            }
                        }
                    } catch (err) {
                        _didIteratorError2 = true;
                        _iteratorError2 = err;
                    } finally {
                        try {
                            if (!_iteratorNormalCompletion2 && _iterator2.return) {
                                _iterator2.return();
                            }
                        } finally {
                            if (_didIteratorError2) {
                                throw _iteratorError2;
                            }
                        }
                    }
                }
            }
        } catch (err) {
            _didIteratorError = true;
            _iteratorError = err;
        } finally {
            try {
                if (!_iteratorNormalCompletion && _iterator.return) {
                    _iterator.return();
                }
            } finally {
                if (_didIteratorError) {
                    throw _iteratorError;
                }
            }
        }

        audioNodeConnectionsOfSource.outputs.clear();
    };
    var removeConnectionToAudioNode = function removeConnectionToAudioNode(source, destination) {
        var audioNodeConnectionsOfSource = getAudioNodeConnections(source);
        var audioNodeConnectionsOfDestination = getAudioNodeConnections(destination);
        var _iteratorNormalCompletion4 = true;
        var _didIteratorError4 = false;
        var _iteratorError4 = undefined;

        try {
            for (var _iterator4 = Array.from(audioNodeConnectionsOfSource.outputs.values())[Symbol.iterator](), _step4; !(_iteratorNormalCompletion4 = (_step4 = _iterator4.next()).done); _iteratorNormalCompletion4 = true) {
                var connection = _step4.value;

                if (connection[0] === destination) {
                    audioNodeConnectionsOfSource.outputs.delete(connection);
                }
            }
        } catch (err) {
            _didIteratorError4 = true;
            _iteratorError4 = err;
        } finally {
            try {
                if (!_iteratorNormalCompletion4 && _iterator4.return) {
                    _iterator4.return();
                }
            } finally {
                if (_didIteratorError4) {
                    throw _iteratorError4;
                }
            }
        }

        var _iteratorNormalCompletion5 = true;
        var _didIteratorError5 = false;
        var _iteratorError5 = undefined;

        try {
            for (var _iterator5 = audioNodeConnectionsOfDestination.inputs[Symbol.iterator](), _step5; !(_iteratorNormalCompletion5 = (_step5 = _iterator5.next()).done); _iteratorNormalCompletion5 = true) {
                var connectionsToInput = _step5.value;
                var _iteratorNormalCompletion6 = true;
                var _didIteratorError6 = false;
                var _iteratorError6 = undefined;

                try {
                    for (var _iterator6 = Array.from(connectionsToInput.values())[Symbol.iterator](), _step6; !(_iteratorNormalCompletion6 = (_step6 = _iterator6.next()).done); _iteratorNormalCompletion6 = true) {
                        var _connection = _step6.value;

                        if (_connection[0] === source) {
                            connectionsToInput.delete(_connection);
                        }
                    }
                } catch (err) {
                    _didIteratorError6 = true;
                    _iteratorError6 = err;
                } finally {
                    try {
                        if (!_iteratorNormalCompletion6 && _iterator6.return) {
                            _iterator6.return();
                        }
                    } finally {
                        if (_didIteratorError6) {
                            throw _iteratorError6;
                        }
                    }
                }
            }
        } catch (err) {
            _didIteratorError5 = true;
            _iteratorError5 = err;
        } finally {
            try {
                if (!_iteratorNormalCompletion5 && _iterator5.return) {
                    _iterator5.return();
                }
            } finally {
                if (_didIteratorError5) {
                    throw _iteratorError5;
                }
            }
        }
    };
    var createAudioNodeConstructor = function createAudioNodeConstructor(createInvalidAccessError, isNativeOfflineAudioContext) {
        return function (_EventTarget) {
            _inherits(AudioNode, _EventTarget);

            function AudioNode(context, nativeAudioNode, audioNodeRenderer) {
                _classCallCheck(this, AudioNode);

                var _this = _possibleConstructorReturn(this, (AudioNode.__proto__ || Object.getPrototypeOf(AudioNode)).call(this));

                _this._context = context;
                _this._nativeAudioNode = nativeAudioNode;
                var nativeContext = getNativeContext(context);
                // Bug #12: Firefox and Safari do not support to disconnect a specific destination.
                // @todo Make sure this is not used with an OfflineAudioContext.
                if (!isNativeOfflineAudioContext(nativeContext) && true !== cacheTestResult(testAudioNodeDisconnectMethodSupport, function () {
                    return testAudioNodeDisconnectMethodSupport(nativeContext);
                })) {
                    wrapAudioNodeDisconnectMethod(nativeAudioNode);
                }
                AUDIO_NODE_STORE.set(_this, nativeAudioNode);
                addAudioNode(context, _this, audioNodeRenderer, nativeAudioNode);
                return _this;
            }

            _createClass(AudioNode, [{
                key: 'addEventListener',
                value: function addEventListener(type, listener, // @todo EventListenerOrEventListenerObject | null = null,
                options) {
                    return this._nativeAudioNode.addEventListener(type, listener, options);
                }
            }, {
                key: 'connect',
                value: function connect(destination) {
                    var output = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
                    var input = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;

                    var nativeContext = getNativeContext(this._context);
                    if (isAudioNode(destination)) {
                        // Bug #41: Only Chrome, Firefox and Opera throw the correct exception by now.
                        if (this._context !== destination.context) {
                            throw createInvalidAccessError();
                        }
                        if (!isNativeOfflineAudioContext(nativeContext)) {
                            var nativeDestinationNode = getNativeAudioNode(destination);
                            if (nativeDestinationNode.inputs !== undefined) {
                                var inputs = nativeDestinationNode.inputs;
                                var nativeInputDestinationNode = inputs[input];
                                this._nativeAudioNode.connect(nativeInputDestinationNode, output, input);
                            } else {
                                this._nativeAudioNode.connect(nativeDestinationNode, output, input);
                            }
                        }
                        addConnectionToAudioNode(this, destination, output, input);
                        return destination;
                    }
                    var nativeAudioParam = getNativeAudioParam(destination);
                    try {
                        this._nativeAudioNode.connect(nativeAudioParam, output);
                        // @todo Calling connect() is only needed to throw possible errors when the nativeContext is an OfflineAudioContext.
                        if (isNativeOfflineAudioContext(nativeContext)) {
                            this._nativeAudioNode.disconnect(nativeAudioParam, output);
                        }
                    } catch (err) {
                        // Bug #58: Only Firefox does throw an InvalidStateError yet.
                        if (err.code === 12) {
                            throw createInvalidAccessError();
                        }
                        throw err;
                    }
                    addConnectionToAudioParam(this._context, this, destination, output);
                }
            }, {
                key: 'disconnect',
                value: function disconnect(destination) {
                    var nativeContext = getNativeContext(this._context);
                    if (!isNativeOfflineAudioContext(nativeContext)) {
                        if (destination === undefined) {
                            return this._nativeAudioNode.disconnect();
                        }
                        var nativeDestinationNode = getNativeAudioNode(destination);
                        if (nativeDestinationNode.inputs !== undefined) {
                            var _iteratorNormalCompletion7 = true;
                            var _didIteratorError7 = false;
                            var _iteratorError7 = undefined;

                            try {
                                for (var _iterator7 = nativeDestinationNode.inputs[Symbol.iterator](), _step7; !(_iteratorNormalCompletion7 = (_step7 = _iterator7.next()).done); _iteratorNormalCompletion7 = true) {
                                    var input = _step7.value;

                                    this._nativeAudioNode.disconnect(input);
                                }
                            } catch (err) {
                                _didIteratorError7 = true;
                                _iteratorError7 = err;
                            } finally {
                                try {
                                    if (!_iteratorNormalCompletion7 && _iterator7.return) {
                                        _iterator7.return();
                                    }
                                } finally {
                                    if (_didIteratorError7) {
                                        throw _iteratorError7;
                                    }
                                }
                            }
                        } else {
                            this._nativeAudioNode.disconnect(nativeDestinationNode);
                        }
                    }
                    if (destination === undefined) {
                        removeAnyConnection(this);
                    } else {
                        removeConnectionToAudioNode(this, destination);
                    }
                }
            }, {
                key: 'removeEventListener',
                value: function removeEventListener(type, listener, // @todo EventListenerOrEventListenerObject | null = null,
                options) {
                    return this._nativeAudioNode.removeEventListener(type, listener, options);
                }
            }, {
                key: 'channelInterpretation',
                get: function get() {
                    return this._nativeAudioNode.channelInterpretation;
                },
                set: function set(value) {
                    this._nativeAudioNode.channelInterpretation = value;
                }
            }, {
                key: 'context',
                get: function get() {
                    return this._context;
                }
            }, {
                key: 'numberOfInputs',
                get: function get() {
                    return this._nativeAudioNode.numberOfInputs;
                }
            }, {
                key: 'numberOfOutputs',
                get: function get() {
                    return this._nativeAudioNode.numberOfOutputs;
                }
            }]);

            return AudioNode;
        }(EventTarget);
    };

    var addAudioParam = function addAudioParam(context, audioParam, audioParamRenderer) {
        var audioGraphOfContext = getAudioGraph(context);
        audioGraphOfContext.params.set(audioParam, { inputs: new Set(), renderer: audioParamRenderer });
    };
    var createAudioParamFactory = function createAudioParamFactory(createAudioParamRenderer) {
        return function (context, isAudioParamOfOfflineAudioContext, nativeAudioParam) {
            var maxValue = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;
            var minValue = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : null;

            var audioParamRenderer = isAudioParamOfOfflineAudioContext ? createAudioParamRenderer() : null;
            var audioParam = {
                get defaultValue() {
                    return nativeAudioParam.defaultValue;
                },
                get maxValue() {
                    return maxValue === null ? nativeAudioParam.maxValue : maxValue;
                },
                get minValue() {
                    return minValue === null ? nativeAudioParam.minValue : minValue;
                },
                get value() {
                    return nativeAudioParam.value;
                },
                set value(value) {
                    nativeAudioParam.value = value;
                    if (audioParamRenderer !== null) {
                        audioParamRenderer.record({ startTime: context.currentTime, type: 'setValue', value: value });
                    }
                },
                cancelScheduledValues: function cancelScheduledValues(cancelTime) {
                    nativeAudioParam.cancelScheduledValues(cancelTime);
                    // @todo
                    return audioParam;
                },
                exponentialRampToValueAtTime: function exponentialRampToValueAtTime(value, endTime) {
                    nativeAudioParam.exponentialRampToValueAtTime(value, endTime);
                    if (audioParamRenderer !== null) {
                        audioParamRenderer.record({ endTime: endTime, type: 'exponentialRampToValue', value: value });
                    }
                    return audioParam;
                },
                linearRampToValueAtTime: function linearRampToValueAtTime(value, endTime) {
                    nativeAudioParam.linearRampToValueAtTime(value, endTime);
                    if (audioParamRenderer !== null) {
                        audioParamRenderer.record({ endTime: endTime, type: 'linearRampToValue', value: value });
                    }
                    return audioParam;
                },
                setTargetAtTime: function setTargetAtTime(target, startTime, timeConstant) {
                    nativeAudioParam.setTargetAtTime(target, startTime, timeConstant);
                    if (audioParamRenderer !== null) {
                        audioParamRenderer.record({ startTime: startTime, target: target, timeConstant: timeConstant, type: 'setTarget' });
                    }
                    return audioParam;
                },
                setValueAtTime: function setValueAtTime(value, startTime) {
                    nativeAudioParam.setValueAtTime(value, startTime);
                    if (audioParamRenderer !== null) {
                        audioParamRenderer.record({ startTime: startTime, type: 'setValue', value: value });
                    }
                    return audioParam;
                },
                setValueCurveAtTime: function setValueCurveAtTime(values, startTime, duration) {
                    // @todo TypeScript is expecting values to be an array of numbers.
                    nativeAudioParam.setValueCurveAtTime(values, startTime, duration);
                    if (audioParamRenderer !== null) {
                        audioParamRenderer.record({ duration: duration, startTime: startTime, type: 'setValueCurve', values: values });
                    }
                    return audioParam;
                }
            };
            AUDIO_PARAM_STORE.set(audioParam, nativeAudioParam);
            addAudioParam(context, audioParam, audioParamRenderer);
            return audioParam;
        };
    };

    var createAudioParamRenderer = function createAudioParamRenderer() {
        var automations = [];
        return {
            record: function record(automation) {
                automations.push(automation);
            },
            replay: function replay(audioParam) {
                var _iteratorNormalCompletion = true;
                var _didIteratorError = false;
                var _iteratorError = undefined;

                try {
                    for (var _iterator = automations[Symbol.iterator](), _step; !(_iteratorNormalCompletion = (_step = _iterator.next()).done); _iteratorNormalCompletion = true) {
                        var automation = _step.value;

                        if (automation.type === 'exponentialRampToValue') {
                            var endTime = automation.endTime,
                                value = automation.value;

                            audioParam.exponentialRampToValueAtTime(value, endTime);
                        } else if (automation.type === 'linearRampToValue') {
                            var _endTime = automation.endTime,
                                _value = automation.value;

                            audioParam.linearRampToValueAtTime(_value, _endTime);
                        } else if (automation.type === 'setTarget') {
                            var startTime = automation.startTime,
                                target = automation.target,
                                timeConstant = automation.timeConstant;

                            audioParam.setTargetAtTime(target, startTime, timeConstant);
                        } else if (automation.type === 'setValue') {
                            var _startTime = automation.startTime,
                                _value2 = automation.value;

                            audioParam.setValueAtTime(_value2, _startTime);
                        } else if (automation.type === 'setValueCurve') {
                            var duration = automation.duration,
                                _startTime2 = automation.startTime,
                                values = automation.values;
                            // @todo TypeScript is expecting values to be an array of numbers.

                            audioParam.setValueCurveAtTime(values, _startTime2, duration);
                        } else {
                            throw new Error("Can't apply an unkown automation.");
                        }
                    }
                } catch (err) {
                    _didIteratorError = true;
                    _iteratorError = err;
                } finally {
                    try {
                        if (!_iteratorNormalCompletion && _iterator.return) {
                            _iterator.return();
                        }
                    } finally {
                        if (_didIteratorError) {
                            throw _iteratorError;
                        }
                    }
                }
            }
        };
    };

    var ReadOnlyMap = function () {
        function ReadOnlyMap(parameters) {
            _classCallCheck(this, ReadOnlyMap);

            this._map = new Map(parameters);
        }

        _createClass(ReadOnlyMap, [{
            key: "entries",
            value: function entries() {
                return this._map.entries();
            }
        }, {
            key: "forEach",
            value: function forEach(callback) {
                var _this = this;

                var thisArg = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;

                return this._map.forEach(function (value, key) {
                    return callback.call(thisArg, value, key, _this);
                });
            }
        }, {
            key: "get",
            value: function get(name) {
                return this._map.get(name);
            }
        }, {
            key: "has",
            value: function has(name) {
                return this._map.has(name);
            }
        }, {
            key: "keys",
            value: function keys() {
                return this._map.keys();
            }
        }, {
            key: "values",
            value: function values() {
                return this._map.values();
            }
        }, {
            key: "size",
            get: function get() {
                return this._map.size;
            }
        }]);

        return ReadOnlyMap;
    }();

    var DEFAULT_OPTIONS$3 = {
        channelCount: 2,
        // Bug #61: The channelCountMode should be 'max' according to the spec but is set to 'explicit' to achieve consistent behavior.
        channelCountMode: 'explicit',
        channelInterpretation: 'speakers',
        numberOfInputs: 1,
        numberOfOutputs: 1,
        outputChannelCount: undefined,
        parameterData: {},
        processorOptions: null
    };
    var createChannelCount = function createChannelCount(length) {
        var channelCount = [];
        for (var i = 0; i < length; i += 1) {
            channelCount.push(1);
        }
        return channelCount;
    };
    var sanitizedOptions = function sanitizedOptions(options) {
        return Object.assign({}, options, { outputChannelCount: options.outputChannelCount !== undefined ? options.outputChannelCount : options.numberOfInputs === 1 && options.numberOfOutputs === 1 ?
            /*
             * Bug #61: This should be the computedNumberOfChannels, but unfortunately that is almost impossible to fake. That's why
             * the channelCountMode is required to be 'explicit' as long as there is not a native implementation in every browser. That
             * makes sure the computedNumberOfChannels is equivilant to the channelCount which makes it much easier to compute.
             */
            [options.channelCount] : createChannelCount(options.numberOfOutputs),
            // Bug #66: The default value of processorOptions should be null, but Chrome Canary doesn't like it.
            processorOptions: options.processorOptions === null ? {} : options.processorOptions });
    };
    var createAudioWorkletNodeConstructor = function createAudioWorkletNodeConstructor(createAudioParam, createAudioWorkletNodeRenderer, createNativeAudioWorkletNode, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor, noneAudioDestinationNodeConstructor) {
        return function (_noneAudioDestination) {
            _inherits(AudioWorkletNode, _noneAudioDestination);

            function AudioWorkletNode(context, name) {
                var options = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : DEFAULT_OPTIONS$3;

                _classCallCheck(this, AudioWorkletNode);

                var nativeContext = getNativeContext(context);
                var mergedOptions = sanitizedOptions(Object.assign({}, DEFAULT_OPTIONS$3, options));
                var nodeNameToProcessorDefinitionMap = NODE_NAME_TO_PROCESSOR_DEFINITION_MAPS.get(nativeContext);
                var processorDefinition = nodeNameToProcessorDefinitionMap === undefined ? undefined : nodeNameToProcessorDefinitionMap.get(name);
                var nativeAudioWorkletNode = createNativeAudioWorkletNode(nativeContext, nativeAudioWorkletNodeConstructor, name, processorDefinition, mergedOptions);
                var isOffline = isNativeOfflineAudioContext(nativeContext);
                var audioWorkletNodeRenderer = isOffline ? createAudioWorkletNodeRenderer(name, mergedOptions, processorDefinition) : null;

                var _this = _possibleConstructorReturn(this, (AudioWorkletNode.__proto__ || Object.getPrototypeOf(AudioWorkletNode)).call(this, context, nativeAudioWorkletNode, audioWorkletNodeRenderer));

                var parameters = [];
                nativeAudioWorkletNode.parameters.forEach(function (nativeAudioParam, nm) {
                    var audioParam = createAudioParam(context, isOffline, nativeAudioParam);
                    parameters.push([nm, audioParam]);
                });
                _this._nativeAudioWorkletNode = nativeAudioWorkletNode;
                // Bug #86 & #87: Every browser but Firefox needs to get an unused output which should not be exposed.
                _this._numberOfOutputs = options.numberOfOutputs === 0 ? 0 : _this._nativeAudioWorkletNode.numberOfOutputs;
                _this._parameters = new ReadOnlyMap(parameters);
                // Bug #86 & #87: Every browser but Firefox needs an output to be connected.
                if (options.numberOfOutputs === 0) {
                    _this.connect(context.destination);
                }
                return _this;
            }

            _createClass(AudioWorkletNode, [{
                key: 'numberOfOutputs',
                get: function get() {
                    return this._numberOfOutputs;
                }
            }, {
                key: 'onprocessorerror',
                get: function get() {
                    return this._nativeAudioWorkletNode.onprocessorerror;
                },
                set: function set(value) {
                    this._nativeAudioWorkletNode.onprocessorerror = value;
                }
            }, {
                key: 'parameters',
                get: function get() {
                    if (this._parameters === null) {
                        return this._nativeAudioWorkletNode.parameters;
                    }
                    return this._parameters;
                }
            }, {
                key: 'port',
                get: function get() {
                    return this._nativeAudioWorkletNode.port;
                }
            }]);

            return AudioWorkletNode;
        }(noneAudioDestinationNodeConstructor);
    };

    var renderInputsOfAudioParam = function renderInputsOfAudioParam(context, audioParam, nativeOfflineAudioContext, nativeAudioParam) {
        var audioParamConnections = getAudioParamConnections(context, audioParam);
        return Promise.all(Array.from(audioParamConnections.inputs).map(function (_ref) {
            var _ref2 = _slicedToArray(_ref, 2),
                source = _ref2[0],
                output = _ref2[1];

            var audioNodeRenderer = getAudioNodeRenderer(source);
            return audioNodeRenderer.render(source, nativeOfflineAudioContext).then(function (node) {
                return node.connect(nativeAudioParam, output);
            });
        }));
    };

    var connectAudioParam = function connectAudioParam(context, nativeOfflineAudioContext, audioParam) {
        var nativeAudioParam = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : getNativeAudioParam(audioParam);

        return renderInputsOfAudioParam(context, audioParam, nativeOfflineAudioContext, nativeAudioParam);
    };

    var createNestedArrays = function createNestedArrays(x, y) {
        var arrays = [];
        for (var i = 0; i < x; i += 1) {
            var array = [];
            var length = typeof y === 'number' ? y : y[i];
            for (var j = 0; j < length; j += 1) {
                array.push(new Float32Array(128));
            }
            arrays.push(array);
        }
        return arrays;
    };

    var getAudioWorkletProcessor = function getAudioWorkletProcessor(nativeOfflineAudioContext, proxy) {
        var nodeToProcessorMap = NODE_TO_PROCESSOR_MAPS.get(nativeOfflineAudioContext);
        if (nodeToProcessorMap === undefined) {
            throw new Error('Missing the processor map for the given OfflineAudioContext.');
        }
        var nativeAudioWorkletNode = getNativeAudioNode(proxy);
        var audioWorkletProcessorPromise = nodeToProcessorMap.get(nativeAudioWorkletNode);
        if (audioWorkletProcessorPromise === undefined) {
            throw new Error('Missing the promise for the given AudioWorkletNode.');
        }
        return audioWorkletProcessorPromise;
    };

    function getAudioParamRenderer(anyContext, audioParam) {
        var audioParamConnections = getAudioParamConnections(anyContext, audioParam);
        if (audioParamConnections.renderer === null) {
            throw new Error('Missing the renderer of the given AudioParam in the audio graph.');
        }
        return audioParamConnections.renderer;
    }

    var renderAutomation = function renderAutomation(context, nativeOfflineAudioContext, audioParam, nativeAudioParam) {
        var audioParamRenderer = getAudioParamRenderer(context, audioParam);
        audioParamRenderer.replay(nativeAudioParam);
        return renderInputsOfAudioParam(context, audioParam, nativeOfflineAudioContext, nativeAudioParam);
    };

    var _this$3 = undefined;
    var processBuffer = function processBuffer(proxy, renderedBuffer, nativeOfflineAudioContext, options, processorDefinition) {
        return tslib_1.__awaiter(_this$3, void 0, void 0, /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {
            var length, numberOfInputChannels, numberOfOutputChannels, processedBuffer, audioNodeConnections, audioWorkletProcessor, inputs, outputs, parameters, _loop, i, _ret;

            return _regeneratorRuntime.wrap(function _callee$(_context) {
                while (1) {
                    switch (_context.prev = _context.next) {
                        case 0:
                            length = renderedBuffer.length;
                            numberOfInputChannels = options.channelCount * options.numberOfInputs;
                            numberOfOutputChannels = options.outputChannelCount.reduce(function (sum, value) {
                                return sum + value;
                            }, 0);
                            processedBuffer = numberOfOutputChannels === 0 ? null : nativeOfflineAudioContext.createBuffer(numberOfOutputChannels, length, renderedBuffer.sampleRate);

                            if (!(processorDefinition === undefined)) {
                                _context.next = 6;
                                break;
                            }

                            throw new Error();

                        case 6:
                            audioNodeConnections = getAudioNodeConnections(proxy);
                            _context.next = 9;
                            return getAudioWorkletProcessor(nativeOfflineAudioContext, proxy);

                        case 9:
                            audioWorkletProcessor = _context.sent;
                            inputs = createNestedArrays(options.numberOfInputs, options.channelCount);
                            outputs = createNestedArrays(options.numberOfOutputs, options.outputChannelCount);
                            parameters = Array.from(proxy.parameters.keys()).reduce(function (prmtrs, name, index) {
                                return Object.assign({}, prmtrs, _defineProperty({}, name, renderedBuffer.getChannelData(numberOfInputChannels + index)));
                            }, {});

                            _loop = function _loop(i) {
                                for (var j = 0; j < options.numberOfInputs; j += 1) {
                                    for (var k = 0; k < options.channelCount; k += 1) {
                                        // Bug #5: Safari does not support copyFromChannel().
                                        var slicedRenderedBuffer = renderedBuffer.getChannelData(k).slice(i, i + 128);
                                        inputs[j][k].set(slicedRenderedBuffer);
                                    }
                                }
                                processorDefinition.parameterDescriptors.forEach(function (_ref, index) {
                                    var name = _ref.name;

                                    var slicedRenderedBuffer = renderedBuffer.getChannelData(numberOfInputChannels + index).slice(i, i + 128);
                                    parameters[name].set(slicedRenderedBuffer);
                                });
                                try {
                                    var potentiallyEmptyInputs = inputs.map(function (input, index) {
                                        if (audioNodeConnections.inputs[index].size === 0) {
                                            return [];
                                        }
                                        return input;
                                    });
                                    var activeSourceFlag = audioWorkletProcessor.process(potentiallyEmptyInputs, outputs, parameters);
                                    if (processedBuffer !== null) {
                                        for (var _j = 0, outputChannelSplitterNodeOutput = 0; _j < options.numberOfOutputs; _j += 1) {
                                            for (var _k = 0; _k < options.outputChannelCount[_j]; _k += 1) {
                                                // Bug #5: Safari does not support copyToChannel().
                                                processedBuffer.getChannelData(outputChannelSplitterNodeOutput + _k).set(outputs[_j][_k], i);
                                            }
                                            outputChannelSplitterNodeOutput += options.outputChannelCount[_j];
                                        }
                                    }
                                    if (!activeSourceFlag) {
                                        return 'break';
                                    }
                                } catch (err) {
                                    if (proxy.onprocessorerror !== null) {
                                        proxy.onprocessorerror.call(null, new ErrorEvent('processorerror'));
                                    }
                                    return 'break';
                                }
                            };

                            i = 0;

                        case 15:
                            if (!(i < length)) {
                                _context.next = 22;
                                break;
                            }

                            _ret = _loop(i);

                            if (!(_ret === 'break')) {
                                _context.next = 19;
                                break;
                            }

                            return _context.abrupt('break', 22);

                        case 19:
                            i += 128;
                            _context.next = 15;
                            break;

                        case 22:
                            return _context.abrupt('return', processedBuffer);

                        case 23:
                        case 'end':
                            return _context.stop();
                    }
                }
            }, _callee, this);
        }));
    };
    var createAudioWorkletNodeRendererFactory = function createAudioWorkletNodeRendererFactory(connectMultipleOutputs, createNativeAudioBufferSourceNode, createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeConstantSourceNode, createNativeGainNode, disconnectMultipleOutputs, nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor, renderNativeOfflineAudioContext) {
        return function (name, options, processorDefinition) {
            var nativeAudioNode = null;
            return {
                render: function render(proxy, nativeOfflineAudioContext) {
                    return tslib_1.__awaiter(_this$3, void 0, void 0, /*#__PURE__*/_regeneratorRuntime.mark(function _callee4() {
                        var _this2 = this;

                        var numberOfInputChannels, numberOfParameters, partialOfflineAudioContext, gainNodes, inputChannelSplitterNodes, i, constantSourceNodes, inputChannelMergerNode, _i, j, _iteratorNormalCompletion, _didIteratorError, _iteratorError, _iterator, _step, _step$value, index, constantSourceNode, _iteratorNormalCompletion2, _didIteratorError2, _iteratorError2, _iterator2, _step2, _step2$value, nm, audioParam, _iteratorNormalCompletion3, _didIteratorError3, _iteratorError3, _iterator3, _step3, _step3$value;

                        return _regeneratorRuntime.wrap(function _callee4$(_context4) {
                            while (1) {
                                switch (_context4.prev = _context4.next) {
                                    case 0:
                                        if (!(nativeAudioNode !== null)) {
                                            _context4.next = 2;
                                            break;
                                        }

                                        return _context4.abrupt('return', nativeAudioNode);

                                    case 2:
                                        nativeAudioNode = getNativeAudioNode(proxy);
                                        // Bug #61: Only Chrome Canary has an implementation of the AudioWorkletNode yet.

                                        if (!(nativeAudioWorkletNodeConstructor === null)) {
                                            _context4.next = 40;
                                            break;
                                        }

                                        if (!(processorDefinition === undefined)) {
                                            _context4.next = 6;
                                            break;
                                        }

                                        throw new Error('Missing the processor definition.');

                                    case 6:
                                        if (!(nativeOfflineAudioContextConstructor === null)) {
                                            _context4.next = 8;
                                            break;
                                        }

                                        throw new Error('Missing the native (Offline)AudioContext constructor.');

                                    case 8:
                                        // Bug #47: The AudioDestinationNode in Edge and Safari gets not initialized correctly.
                                        numberOfInputChannels = proxy.channelCount * proxy.numberOfInputs;
                                        numberOfParameters = processorDefinition.parameterDescriptors.length;
                                        partialOfflineAudioContext = new nativeOfflineAudioContextConstructor(numberOfInputChannels + numberOfParameters,
                                        // Ceil the length to the next full render quantum.
                                        // Bug #17: Safari does not yet expose the length.
                                        Math.ceil(proxy.context.length / 128) * 128, nativeOfflineAudioContext.sampleRate);
                                        gainNodes = [];
                                        inputChannelSplitterNodes = [];

                                        for (i = 0; i < options.numberOfInputs; i += 1) {
                                            gainNodes.push(createNativeGainNode(partialOfflineAudioContext, {
                                                channelCount: options.channelCount,
                                                channelCountMode: options.channelCountMode,
                                                channelInterpretation: options.channelInterpretation,
                                                gain: 1
                                            }));
                                            inputChannelSplitterNodes.push(createNativeChannelSplitterNode(partialOfflineAudioContext, {
                                                channelCount: options.channelCount,
                                                channelCountMode: 'explicit',
                                                channelInterpretation: 'discrete',
                                                numberOfOutputs: options.channelCount
                                            }));
                                        }
                                        _context4.next = 16;
                                        return Promise.all(Array.from(proxy.parameters.values()).map(function (audioParam) {
                                            return tslib_1.__awaiter(_this2, void 0, void 0, /*#__PURE__*/_regeneratorRuntime.mark(function _callee2() {
                                                var constantSourceNode;
                                                return _regeneratorRuntime.wrap(function _callee2$(_context2) {
                                                    while (1) {
                                                        switch (_context2.prev = _context2.next) {
                                                            case 0:
                                                                constantSourceNode = createNativeConstantSourceNode(partialOfflineAudioContext, {
                                                                    channelCount: 1,
                                                                    channelCountMode: 'explicit',
                                                                    channelInterpretation: 'discrete',
                                                                    offset: audioParam.value
                                                                });
                                                                _context2.next = 3;
                                                                return renderAutomation(proxy.context, partialOfflineAudioContext, audioParam, constantSourceNode.offset);

                                                            case 3:
                                                                return _context2.abrupt('return', constantSourceNode);

                                                            case 4:
                                                            case 'end':
                                                                return _context2.stop();
                                                        }
                                                    }
                                                }, _callee2, this);
                                            }));
                                        }));

                                    case 16:
                                        constantSourceNodes = _context4.sent;
                                        inputChannelMergerNode = createNativeChannelMergerNode(partialOfflineAudioContext, {
                                            numberOfInputs: Math.max(1, numberOfInputChannels + numberOfParameters)
                                        });

                                        for (_i = 0; _i < options.numberOfInputs; _i += 1) {
                                            gainNodes[_i].connect(inputChannelSplitterNodes[_i]);
                                            for (j = 0; j < options.channelCount; j += 1) {
                                                inputChannelSplitterNodes[_i].connect(inputChannelMergerNode, j, _i * options.channelCount + j);
                                            }
                                        }
                                        _iteratorNormalCompletion = true;
                                        _didIteratorError = false;
                                        _iteratorError = undefined;
                                        _context4.prev = 22;
                                        for (_iterator = Array.from(constantSourceNodes.entries())[Symbol.iterator](); !(_iteratorNormalCompletion = (_step = _iterator.next()).done); _iteratorNormalCompletion = true) {
                                            _step$value = _slicedToArray(_step.value, 2), index = _step$value[0], constantSourceNode = _step$value[1];

                                            constantSourceNode.connect(inputChannelMergerNode, 0, numberOfInputChannels + index);
                                            constantSourceNode.start(0);
                                        }
                                        _context4.next = 30;
                                        break;

                                    case 26:
                                        _context4.prev = 26;
                                        _context4.t0 = _context4['catch'](22);
                                        _didIteratorError = true;
                                        _iteratorError = _context4.t0;

                                    case 30:
                                        _context4.prev = 30;
                                        _context4.prev = 31;

                                        if (!_iteratorNormalCompletion && _iterator.return) {
                                            _iterator.return();
                                        }

                                    case 33:
                                        _context4.prev = 33;

                                        if (!_didIteratorError) {
                                            _context4.next = 36;
                                            break;
                                        }

                                        throw _iteratorError;

                                    case 36:
                                        return _context4.finish(33);

                                    case 37:
                                        return _context4.finish(30);

                                    case 38:
                                        inputChannelMergerNode.connect(partialOfflineAudioContext.destination);
                                        return _context4.abrupt('return', Promise.all(gainNodes.map(function (gainNode) {
                                            return renderInputsOfAudioNode(proxy, partialOfflineAudioContext, gainNode);
                                        })).then(function () {
                                            return renderNativeOfflineAudioContext(partialOfflineAudioContext);
                                        }).then(function (renderedBuffer) {
                                            return tslib_1.__awaiter(_this2, void 0, void 0, /*#__PURE__*/_regeneratorRuntime.mark(function _callee3() {
                                                var audioBufferSourceNode, numberOfOutputChannels, outputChannelSplitterNode, outputChannelMergerNodes, _i2, processedBuffer, _i3, outputChannelSplitterNodeOutput, outputChannelMergerNode, _j2, outputAudioNodes;

                                                return _regeneratorRuntime.wrap(function _callee3$(_context3) {
                                                    while (1) {
                                                        switch (_context3.prev = _context3.next) {
                                                            case 0:
                                                                audioBufferSourceNode = createNativeAudioBufferSourceNode(nativeOfflineAudioContext);
                                                                numberOfOutputChannels = options.outputChannelCount.reduce(function (sum, value) {
                                                                    return sum + value;
                                                                }, 0);
                                                                outputChannelSplitterNode = createNativeChannelSplitterNode(nativeOfflineAudioContext, {
                                                                    channelCount: Math.max(1, numberOfOutputChannels),
                                                                    channelCountMode: 'explicit',
                                                                    channelInterpretation: 'discrete',
                                                                    numberOfOutputs: Math.max(1, numberOfOutputChannels)
                                                                });
                                                                outputChannelMergerNodes = [];

                                                                for (_i2 = 0; _i2 < proxy.numberOfOutputs; _i2 += 1) {
                                                                    outputChannelMergerNodes.push(createNativeChannelMergerNode(nativeOfflineAudioContext, {
                                                                        numberOfInputs: options.outputChannelCount[_i2]
                                                                    }));
                                                                }
                                                                _context3.next = 7;
                                                                return processBuffer(proxy, renderedBuffer, nativeOfflineAudioContext, options, processorDefinition);

                                                            case 7:
                                                                processedBuffer = _context3.sent;

                                                                if (processedBuffer !== null) {
                                                                    audioBufferSourceNode.buffer = processedBuffer;
                                                                    audioBufferSourceNode.start(0);
                                                                }
                                                                audioBufferSourceNode.connect(outputChannelSplitterNode);
                                                                for (_i3 = 0, outputChannelSplitterNodeOutput = 0; _i3 < proxy.numberOfOutputs; _i3 += 1) {
                                                                    outputChannelMergerNode = outputChannelMergerNodes[_i3];

                                                                    for (_j2 = 0; _j2 < options.outputChannelCount[_i3]; _j2 += 1) {
                                                                        outputChannelSplitterNode.connect(outputChannelMergerNode, outputChannelSplitterNodeOutput + _j2, _j2);
                                                                    }
                                                                    outputChannelSplitterNodeOutput += options.outputChannelCount[_i3];
                                                                }
                                                                // Bug #87: Expose at least one output to make this node connectable.
                                                                outputAudioNodes = options.numberOfOutputs === 0 ? [outputChannelSplitterNode] : outputChannelMergerNodes;

                                                                audioBufferSourceNode.connect = function () {
                                                                    return connectMultipleOutputs(outputAudioNodes, arguments.length <= 0 ? undefined : arguments[0], arguments.length <= 1 ? undefined : arguments[1], arguments.length <= 2 ? undefined : arguments[2]);
                                                                };
                                                                audioBufferSourceNode.disconnect = function () {
                                                                    return disconnectMultipleOutputs(outputAudioNodes, arguments.length <= 0 ? undefined : arguments[0], arguments.length <= 1 ? undefined : arguments[1], arguments.length <= 2 ? undefined : arguments[2]);
                                                                };
                                                                nativeAudioNode = audioBufferSourceNode;
                                                                return _context3.abrupt('return', nativeAudioNode);

                                                            case 16:
                                                            case 'end':
                                                                return _context3.stop();
                                                        }
                                                    }
                                                }, _callee3, this);
                                            }));
                                        }));

                                    case 40:
                                        if (isOwnedByContext(nativeAudioNode, nativeOfflineAudioContext)) {
                                            _context4.next = 70;
                                            break;
                                        }

                                        nativeAudioNode = new nativeAudioWorkletNodeConstructor(nativeOfflineAudioContext, name);
                                        // @todo Using Array.from() is a lazy fix that should not be necessary forever.
                                        _iteratorNormalCompletion2 = true;
                                        _didIteratorError2 = false;
                                        _iteratorError2 = undefined;
                                        _context4.prev = 45;
                                        _iterator2 = Array.from(proxy.parameters.entries())[Symbol.iterator]();

                                    case 47:
                                        if (_iteratorNormalCompletion2 = (_step2 = _iterator2.next()).done) {
                                            _context4.next = 54;
                                            break;
                                        }

                                        _step2$value = _slicedToArray(_step2.value, 2), nm = _step2$value[0], audioParam = _step2$value[1];
                                        _context4.next = 51;
                                        return renderAutomation(proxy.context, nativeOfflineAudioContext, audioParam, nativeAudioNode.parameters.get(nm));

                                    case 51:
                                        _iteratorNormalCompletion2 = true;
                                        _context4.next = 47;
                                        break;

                                    case 54:
                                        _context4.next = 60;
                                        break;

                                    case 56:
                                        _context4.prev = 56;
                                        _context4.t1 = _context4['catch'](45);
                                        _didIteratorError2 = true;
                                        _iteratorError2 = _context4.t1;

                                    case 60:
                                        _context4.prev = 60;
                                        _context4.prev = 61;

                                        if (!_iteratorNormalCompletion2 && _iterator2.return) {
                                            _iterator2.return();
                                        }

                                    case 63:
                                        _context4.prev = 63;

                                        if (!_didIteratorError2) {
                                            _context4.next = 66;
                                            break;
                                        }

                                        throw _iteratorError2;

                                    case 66:
                                        return _context4.finish(63);

                                    case 67:
                                        return _context4.finish(60);

                                    case 68:
                                        _context4.next = 96;
                                        break;

                                    case 70:
                                        // @todo Using Array.from() is a lazy fix that should not be necessary forever.
                                        _iteratorNormalCompletion3 = true;
                                        _didIteratorError3 = false;
                                        _iteratorError3 = undefined;
                                        _context4.prev = 73;
                                        _iterator3 = Array.from(proxy.parameters.entries())[Symbol.iterator]();

                                    case 75:
                                        if (_iteratorNormalCompletion3 = (_step3 = _iterator3.next()).done) {
                                            _context4.next = 82;
                                            break;
                                        }

                                        _step3$value = _slicedToArray(_step3.value, 2), nm = _step3$value[0], audioParam = _step3$value[1];
                                        _context4.next = 79;
                                        return connectAudioParam(proxy.context, nativeOfflineAudioContext, audioParam, nativeAudioNode.parameters.get(nm));

                                    case 79:
                                        _iteratorNormalCompletion3 = true;
                                        _context4.next = 75;
                                        break;

                                    case 82:
                                        _context4.next = 88;
                                        break;

                                    case 84:
                                        _context4.prev = 84;
                                        _context4.t2 = _context4['catch'](73);
                                        _didIteratorError3 = true;
                                        _iteratorError3 = _context4.t2;

                                    case 88:
                                        _context4.prev = 88;
                                        _context4.prev = 89;

                                        if (!_iteratorNormalCompletion3 && _iterator3.return) {
                                            _iterator3.return();
                                        }

                                    case 91:
                                        _context4.prev = 91;

                                        if (!_didIteratorError3) {
                                            _context4.next = 94;
                                            break;
                                        }

                                        throw _iteratorError3;

                                    case 94:
                                        return _context4.finish(91);

                                    case 95:
                                        return _context4.finish(88);

                                    case 96:
                                        _context4.next = 98;
                                        return renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioNode);

                                    case 98:
                                        return _context4.abrupt('return', nativeAudioNode);

                                    case 99:
                                    case 'end':
                                        return _context4.stop();
                                }
                            }
                        }, _callee4, this, [[22, 26, 30, 38], [31,, 33, 37], [45, 56, 60, 68], [61,, 63, 67], [73, 84, 88, 96], [89,, 91, 95]]);
                    }));
                }
            };
        };
    };

    var createAbortError = function createAbortError() {
        try {
            return new DOMException('', 'AbortError');
        } catch (err) {
            var exception = new Error();
            exception.code = 20;
            exception.name = 'AbortError';
            return exception;
        }
    };

    var createNotSupportedError = function createNotSupportedError() {
        try {
            return new DOMException('', 'NotSupportedError');
        } catch (err) {
            var exception = new Error();
            exception.code = 9;
            exception.name = 'NotSupportedError';
            return exception;
        }
    };

    var handler = {
        construct: function construct() {
            return handler;
        }
    };
    var isConstructible = function isConstructible(constructible) {
        try {
            var proxy = new Proxy(constructible, handler);
            new proxy(); // tslint:disable-line:no-unused-expression
        } catch (err) {
            return false;
        }
        return true;
    };

    var verifyParameterDescriptors = function verifyParameterDescriptors(parameterDescriptors) {
        if (!Array.isArray(parameterDescriptors)) {
            throw new TypeError('The parameterDescriptors property of given value for processorCtor is not an array.');
        }
    };
    var verifyProcessorCtor = function verifyProcessorCtor(processorCtor) {
        if (!isConstructible(processorCtor)) {
            throw new TypeError('The given value for processorCtor should be a constructor.');
        }
        if (processorCtor.prototype === null || _typeof(processorCtor.prototype) !== 'object') {
            throw new TypeError('The given value for processorCtor should have a prototype.');
        }
        if (typeof processorCtor.prototype.process !== 'function') {
            throw new TypeError('The given value for processorCtor should have a callable process() function.');
        }
    };
    var ongoingRequests = new WeakMap();
    var resolvedRequests = new WeakMap();
    var addAudioWorkletModule = function addAudioWorkletModule(context, moduleURL) {
        var options = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : { credentials: 'omit' };

        var nativeContext = getNativeContext(context);
        // Bug #59: Only Chrome Canary does implement the audioWorklet property.
        // @todo Define the native interface as part of the native AudioContext.
        if (nativeContext.audioWorklet !== undefined) {
            return fetch(moduleURL).then(function (response) {
                if (response.ok) {
                    return response.text();
                }
                throw createAbortError();
            }).then(function (source) {
                /*
                 * Bug #86: Chrome Canary does not invoke the process() function if the corresponding AudioWorkletNode has no output.
                 *
                 * This is the unminified version of the code used below:
                 *
                 * ```js
                 * ((registerProcessor) => {${ source }})((name, processorCtor) => registerProcessor(name, class extends processorCtor {
                 *
                 *     constructor (options) {
                 *         const { hasNoOutput, ...otherParameterData } = options.parameterData;
                 *
                 *         if (hasNoOutput === 1) {
                 *             super({ ...options, numberOfOutputs: 0, outputChannelCount: [ ], parameterData: otherParameterData });
                 *
                 *             this._hasNoOutput = true;
                 *         } else {
                 *             super(options);
                 *
                 *             this._hasNoOutput = false;
                 *         }
                 *     }
                 *
                 *     process (inputs, outputs, parameters) {
                 *         return super.process(inputs, (this._hasNoOutput) ? [ ] : outputs, parameters);
                 *     }
                 *
                 * }))
                 * ```
                 */
                var wrappedSource = '(registerProcessor=>{' + source + '})((n,p)=>registerProcessor(n,class extends p{constructor(o){const{hasNoOutput,...q}=o.parameterData;if(hasNoOutput===1){super({...o,numberOfOutputs:0,outputChannelCount:[],parameterData:q});this._h=true}else{super(o);this._h=false}}process(i,o,p){return super.process(i,(this._h)?[]:o,p)}}))'; // tslint:disable-line:max-line-length
                var blob = new Blob([wrappedSource], { type: 'application/javascript; charset=utf-8' });
                var url = URL.createObjectURL(blob);
                return nativeContext.audioWorklet.addModule(url, options);
            });
        } else {
            var resolvedRequestsOfContext = resolvedRequests.get(context);
            if (resolvedRequestsOfContext !== undefined && resolvedRequestsOfContext.has(moduleURL)) {
                return Promise.resolve();
            }
            var ongoingRequestsOfContext = ongoingRequests.get(context);
            if (ongoingRequestsOfContext !== undefined) {
                var promiseOfOngoingRequest = ongoingRequestsOfContext.get(moduleURL);
                if (promiseOfOngoingRequest !== undefined) {
                    return promiseOfOngoingRequest;
                }
            }
            var promise = fetch(moduleURL).then(function (response) {
                if (response.ok) {
                    return response.text();
                }
                throw createAbortError();
            }).then(function (source) {
                var fn = new Function('AudioWorkletProcessor', 'currentFrame', 'currentTime', 'global', 'registerProcessor', 'sampleRate', 'self', 'window', source);
                var globalScope = Object.create(null, {
                    currentFrame: {
                        get: function get() {
                            return nativeContext.currentTime * nativeContext.sampleRate;
                        }
                    },
                    currentTime: {
                        get: function get() {
                            return nativeContext.currentTime;
                        }
                    },
                    sampleRate: {
                        get: function get() {
                            return nativeContext.sampleRate;
                        }
                    }
                });
                // @todo Evaluating the given source code is a possible security problem.
                fn(function AudioWorkletProcessor() {
                    _classCallCheck(this, AudioWorkletProcessor);
                }, globalScope.currentFrame, globalScope.currentTime, undefined, function (name, processorCtor) {
                    if (name.trim() === '') {
                        throw createNotSupportedError();
                    }
                    var nodeNameToProcessorDefinitionMap = NODE_NAME_TO_PROCESSOR_DEFINITION_MAPS.get(nativeContext);
                    if (nodeNameToProcessorDefinitionMap !== undefined) {
                        if (nodeNameToProcessorDefinitionMap.has(name)) {
                            throw createNotSupportedError();
                        }
                        verifyProcessorCtor(processorCtor);
                        verifyParameterDescriptors(processorCtor.parameterDescriptors);
                        nodeNameToProcessorDefinitionMap.set(name, processorCtor);
                    } else {
                        verifyProcessorCtor(processorCtor);
                        verifyParameterDescriptors(processorCtor.parameterDescriptors);
                        NODE_NAME_TO_PROCESSOR_DEFINITION_MAPS.set(nativeContext, new Map([[name, processorCtor]]));
                    }
                }, globalScope.sampleRate, undefined, undefined);
            }).catch(function (err) {
                if (err.name === 'SyntaxError') {
                    throw createAbortError();
                }
                throw err;
            });
            if (ongoingRequestsOfContext === undefined) {
                ongoingRequests.set(context, new Map([[moduleURL, promise]]));
            } else {
                ongoingRequestsOfContext.set(moduleURL, promise);
            }
            promise.then(function () {
                var rslvdRqstsFCntxt = resolvedRequests.get(context);
                if (rslvdRqstsFCntxt === undefined) {
                    resolvedRequests.set(context, new Set([moduleURL]));
                } else {
                    rslvdRqstsFCntxt.add(moduleURL);
                }
            }).catch(function () {}) // tslint:disable-line:no-empty
            // @todo Use finally when it becomes available in all supported browsers.
            .then(function () {
                var ngngRqstsFCntxt = ongoingRequests.get(context);
                if (ngngRqstsFCntxt !== undefined) {
                    ngngRqstsFCntxt.delete(moduleURL);
                }
            });
            return promise;
        }
    };

    var createDataCloneError = function createDataCloneError() {
        try {
            return new DOMException('', 'DataCloneError');
        } catch (err) {
            var exception = new Error();
            exception.code = 25;
            exception.name = 'DataCloneError';
            return exception;
        }
    };

    var createEncodingError = function createEncodingError() {
        try {
            return new DOMException('', 'EncodingError');
        } catch (err) {
            var exception = new Error();
            exception.code = 0;
            exception.name = 'EncodingError';
            return exception;
        }
    };

    var testPromiseSupport = function testPromiseSupport(nativeContext) {
        // This 12 numbers represent the 48 bytes of an empty WAVE file with a single sample.
        var uint32Array = new Uint32Array([1179011410, 40, 1163280727, 544501094, 16, 131073, 44100, 176400, 1048580, 1635017060, 4, 0]);
        try {
            // Bug #1: Safari requires a successCallback.
            var promise = nativeContext.decodeAudioData(uint32Array.buffer, function () {
                // Ignore the success callback.
            });
            if (promise === undefined) {
                return false;
            }
            promise.catch(function () {
                // Ignore rejected errors.
            });
            return true;
        } catch (err) {
            // Ignore thrown errors.
        }
        return false;
    };

    var isSupportingCopyChannelMethodsSubarray = function isSupportingCopyChannelMethodsSubarray(nativeAudioBuffer) {
        return cacheTestResult(testAudioBufferCopyChannelMethodsSubarraySupport, function () {
            return testAudioBufferCopyChannelMethodsSubarraySupport(nativeAudioBuffer);
        });
    };
    var isSupportingPromises = function isSupportingPromises(nativeContext) {
        return cacheTestResult(testPromiseSupport, function () {
            return testPromiseSupport(nativeContext);
        });
    };
    var decodeAudioData = function decodeAudioData(nativeContext, audioData) {
        // Bug #43: Only Chrome and Opera do throw a DataCloneError.
        if (DETACHED_ARRAY_BUFFERS.has(audioData)) {
            var err = createDataCloneError();
            return Promise.reject(err);
        }
        // The audioData parameter maybe of a type which can't be added to a WeakSet.
        try {
            DETACHED_ARRAY_BUFFERS.add(audioData);
        } catch (err) {}
        // Ignore errors.

        // Bug #21: Safari does not support promises yet.
        if (isSupportingPromises(nativeContext)) {
            var promise = nativeContext.decodeAudioData(audioData).catch(function (err) {
                // Bug #27: Edge is rejecting invalid arrayBuffers with a DOMException.
                if (err instanceof DOMException && err.name === 'NotSupportedError') {
                    throw new TypeError();
                }
                throw err;
            });
            setTimeout(function () {
                try {
                    asyncArrayBuffer.deallocate(audioData);
                } catch (err) {/* Ignore errors. */}
            });
            return promise;
        }
        // Bug #21: Safari does not return a Promise yet.
        return new Promise(function (resolve, reject) {
            var complete = function complete() {
                try {
                    asyncArrayBuffer.deallocate(audioData);
                } catch (err) {/* Ignore errors. */}
            };
            var fail = function fail(err) {
                reject(err);
                complete();
            };
            var succeed = function succeed(dBffrWrppr) {
                resolve(dBffrWrppr);
                complete();
            };
            // Bug #26: Safari throws a synchronous error.
            try {
                // Bug #1: Safari requires a successCallback.
                nativeContext.decodeAudioData(audioData, function (audioBuffer) {
                    // Bug #5: Safari does not support copyFromChannel() and copyToChannel().
                    if (typeof audioBuffer.copyFromChannel !== 'function') {
                        wrapAudioBufferCopyChannelMethods(audioBuffer);
                        // Bug #42: Firefox does not yet fully support copyFromChannel() and copyToChannel().
                    } else if (!isSupportingCopyChannelMethodsSubarray(audioBuffer)) {
                        wrapAudioBufferCopyChannelMethodsSubarray(audioBuffer);
                    }
                    succeed(audioBuffer);
                }, function (err) {
                    // Bug #4: Safari returns null instead of an error.
                    if (err === null) {
                        fail(createEncodingError());
                    } else {
                        fail(err);
                    }
                });
            } catch (err) {
                fail(err);
            }
        });
    };

    var createBaseAudioContextConstructor = function createBaseAudioContextConstructor(analyserNodeConstructor, audioBufferConstructor, audioBufferSourceNodeConstructor, biquadFilterNodeConstructor, channelMergerNodeConstructor, channelSplitterNodeConstructor, constantSourceNodeConstructor, gainNodeConstructor, iIRFilterNodeConstructor, minimalBaseAudioContextConstructor, oscillatorNodeConstructor) {
        return function (_minimalBaseAudioCont) {
            _inherits(BaseAudioContext, _minimalBaseAudioCont);

            function BaseAudioContext(nativeContext, numberOfChannels) {
                _classCallCheck(this, BaseAudioContext);

                var _this = _possibleConstructorReturn(this, (BaseAudioContext.__proto__ || Object.getPrototypeOf(BaseAudioContext)).call(this, nativeContext, numberOfChannels));

                _this._audioWorklet = {
                    addModule: function addModule(moduleURL, options) {
                        return addAudioWorkletModule(_this, moduleURL, options);
                    }
                };
                _this._nativeContext = nativeContext;
                return _this;
            }

            _createClass(BaseAudioContext, [{
                key: 'createAnalyser',
                value: function createAnalyser() {
                    return new analyserNodeConstructor(this);
                }
            }, {
                key: 'createBiquadFilter',
                value: function createBiquadFilter() {
                    return new biquadFilterNodeConstructor(this);
                }
            }, {
                key: 'createBuffer',
                value: function createBuffer(numberOfChannels, length, sampleRate) {
                    return new audioBufferConstructor({ length: length, numberOfChannels: numberOfChannels, sampleRate: sampleRate });
                }
            }, {
                key: 'createBufferSource',
                value: function createBufferSource() {
                    return new audioBufferSourceNodeConstructor(this);
                }
            }, {
                key: 'createChannelMerger',
                value: function createChannelMerger() {
                    var numberOfInputs = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 6;

                    return new channelMergerNodeConstructor(this, { numberOfInputs: numberOfInputs });
                }
            }, {
                key: 'createChannelSplitter',
                value: function createChannelSplitter() {
                    var numberOfOutputs = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 6;

                    return new channelSplitterNodeConstructor(this, { numberOfOutputs: numberOfOutputs });
                }
            }, {
                key: 'createConstantSource',
                value: function createConstantSource() {
                    return new constantSourceNodeConstructor(this);
                }
            }, {
                key: 'createGain',
                value: function createGain() {
                    return new gainNodeConstructor(this);
                }
            }, {
                key: 'createIIRFilter',
                value: function createIIRFilter(feedforward, feedback) {
                    return new iIRFilterNodeConstructor(this, { feedback: feedback, feedforward: feedforward });
                }
            }, {
                key: 'createOscillator',
                value: function createOscillator() {
                    return new oscillatorNodeConstructor(this);
                }
            }, {
                key: 'decodeAudioData',
                value: function decodeAudioData$$1(audioData, successCallback, errorCallback) {
                    return decodeAudioData(this._nativeContext, audioData).then(function (audioBuffer) {
                        if (typeof successCallback === 'function') {
                            successCallback(audioBuffer);
                        }
                        return audioBuffer;
                    }).catch(function (err) {
                        if (typeof errorCallback === 'function') {
                            errorCallback(err);
                        }
                        throw err;
                    });
                }
            }, {
                key: 'audioWorklet',
                get: function get() {
                    return this._audioWorklet;
                }
            }]);

            return BaseAudioContext;
        }(minimalBaseAudioContextConstructor);
    };

    var DEFAULT_OPTIONS$4 = {
        Q: 1,
        channelCount: 2,
        channelCountMode: 'max',
        channelInterpretation: 'speakers',
        detune: 0,
        frequency: 350,
        gain: 0,
        type: 'lowpass'
    };
    var createBiquadFilterNodeConstructor = function createBiquadFilterNodeConstructor(createAudioParam, createBiquadFilterNodeRenderer, createInvalidAccessError, createNativeBiquadFilterNode, isNativeOfflineAudioContext, noneAudioDestinationNodeConstructor) {
        return function (_noneAudioDestination) {
            _inherits(BiquadFilterNode, _noneAudioDestination);

            function BiquadFilterNode(context) {
                var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : DEFAULT_OPTIONS$4;

                _classCallCheck(this, BiquadFilterNode);

                var nativeContext = getNativeContext(context);
                var mergedOptions = Object.assign({}, DEFAULT_OPTIONS$4, options);
                var nativeBiquadFilterNode = createNativeBiquadFilterNode(nativeContext, mergedOptions);
                var isOffline = isNativeOfflineAudioContext(nativeContext);
                var biquadFilterNodeRenderer = isOffline ? createBiquadFilterNodeRenderer() : null;

                // Bug #80: Edge, Firefox & Safari do not export the correct values for maxValue and minValue.
                var _this = _possibleConstructorReturn(this, (BiquadFilterNode.__proto__ || Object.getPrototypeOf(BiquadFilterNode)).call(this, context, nativeBiquadFilterNode, biquadFilterNodeRenderer));

                _this._Q = createAudioParam(context, isOffline, nativeBiquadFilterNode.Q, 3.4028234663852886e38, -3.4028234663852886e38);
                // Bug #78: Edge, Firefox & Safari do not export the correct values for maxValue and minValue.
                _this._detune = createAudioParam(context, isOffline, nativeBiquadFilterNode.detune, 3.4028234663852886e38, -3.4028234663852886e38);
                // Bug #77: Chrome, Edge, Firefox, Opera & Safari do not export the correct values for maxValue and minValue.
                _this._frequency = createAudioParam(context, isOffline, nativeBiquadFilterNode.frequency, 3.4028234663852886e38, -3.4028234663852886e38);
                // Bug #79: Edge, Firefox & Safari do not export the correct values for maxValue and minValue.
                _this._gain = createAudioParam(context, isOffline, nativeBiquadFilterNode.gain, 3.4028234663852886e38, -3.4028234663852886e38);
                _this._nativeBiquadFilterNode = nativeBiquadFilterNode;
                return _this;
            }

            _createClass(BiquadFilterNode, [{
                key: 'getFrequencyResponse',
                value: function getFrequencyResponse(frequencyHz, magResponse, phaseResponse) {
                    this._nativeBiquadFilterNode.getFrequencyResponse(frequencyHz, magResponse, phaseResponse);
                    // Bug #68: Only Chrome does throw an error if the parameters differ in their length.
                    if (frequencyHz.length !== magResponse.length || magResponse.length !== phaseResponse.length) {
                        throw createInvalidAccessError();
                    }
                }
            }, {
                key: 'Q',
                get: function get() {
                    return this._Q;
                }
            }, {
                key: 'detune',
                get: function get() {
                    return this._detune;
                }
            }, {
                key: 'frequency',
                get: function get() {
                    return this._frequency;
                }
            }, {
                key: 'gain',
                get: function get() {
                    return this._gain;
                }
            }, {
                key: 'type',
                get: function get() {
                    return this._nativeBiquadFilterNode.type;
                },
                set: function set(value) {
                    this._nativeBiquadFilterNode.type = value;
                }
            }]);

            return BiquadFilterNode;
        }(noneAudioDestinationNodeConstructor);
    };

    var _this$4 = undefined;
    var createBiquadFilterNodeRendererFactory = function createBiquadFilterNodeRendererFactory(createNativeBiquadFilterNode) {
        return function () {
            var nativeBiquadFilterNode = null;
            return {
                render: function render(proxy, nativeOfflineAudioContext) {
                    return tslib_1.__awaiter(_this$4, void 0, void 0, /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {
                        var options;
                        return _regeneratorRuntime.wrap(function _callee$(_context) {
                            while (1) {
                                switch (_context.prev = _context.next) {
                                    case 0:
                                        if (!(nativeBiquadFilterNode !== null)) {
                                            _context.next = 2;
                                            break;
                                        }

                                        return _context.abrupt('return', nativeBiquadFilterNode);

                                    case 2:
                                        nativeBiquadFilterNode = getNativeAudioNode(proxy);
                                        /*
                                         * If the initially used nativeBiquadFilterNode was not constructed on the same OfflineAudioContext it needs to be created
                                         * again.
                                         */

                                        if (isOwnedByContext(nativeBiquadFilterNode, nativeOfflineAudioContext)) {
                                            _context.next = 16;
                                            break;
                                        }

                                        options = {
                                            Q: nativeBiquadFilterNode.Q.value,
                                            channelCount: nativeBiquadFilterNode.channelCount,
                                            channelCountMode: nativeBiquadFilterNode.channelCountMode,
                                            channelInterpretation: nativeBiquadFilterNode.channelInterpretation,
                                            detune: nativeBiquadFilterNode.detune.value,
                                            frequency: nativeBiquadFilterNode.frequency.value,
                                            gain: nativeBiquadFilterNode.gain.value,
                                            type: nativeBiquadFilterNode.type
                                        };

                                        nativeBiquadFilterNode = createNativeBiquadFilterNode(nativeOfflineAudioContext, options);
                                        _context.next = 8;
                                        return renderAutomation(proxy.context, nativeOfflineAudioContext, proxy.Q, nativeBiquadFilterNode.Q);

                                    case 8:
                                        _context.next = 10;
                                        return renderAutomation(proxy.context, nativeOfflineAudioContext, proxy.detune, nativeBiquadFilterNode.detune);

                                    case 10:
                                        _context.next = 12;
                                        return renderAutomation(proxy.context, nativeOfflineAudioContext, proxy.frequency, nativeBiquadFilterNode.frequency);

                                    case 12:
                                        _context.next = 14;
                                        return renderAutomation(proxy.context, nativeOfflineAudioContext, proxy.gain, nativeBiquadFilterNode.gain);

                                    case 14:
                                        _context.next = 24;
                                        break;

                                    case 16:
                                        _context.next = 18;
                                        return connectAudioParam(proxy.context, nativeOfflineAudioContext, proxy.Q);

                                    case 18:
                                        _context.next = 20;
                                        return connectAudioParam(proxy.context, nativeOfflineAudioContext, proxy.detune);

                                    case 20:
                                        _context.next = 22;
                                        return connectAudioParam(proxy.context, nativeOfflineAudioContext, proxy.frequency);

                                    case 22:
                                        _context.next = 24;
                                        return connectAudioParam(proxy.context, nativeOfflineAudioContext, proxy.gain);

                                    case 24:
                                        _context.next = 26;
                                        return renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeBiquadFilterNode);

                                    case 26:
                                        return _context.abrupt('return', nativeBiquadFilterNode);

                                    case 27:
                                    case 'end':
                                        return _context.stop();
                                }
                            }
                        }, _callee, this);
                    }));
                }
            };
        };
    };

    var DEFAULT_OPTIONS$5 = {
        channelCount: 1,
        channelCountMode: 'explicit',
        channelInterpretation: 'speakers',
        numberOfInputs: 6
    };
    var createChannelMergerNodeConstructor = function createChannelMergerNodeConstructor(createChannelMergerNodeRenderer, createNativeChannelMergerNode, isNativeOfflineAudioContext, noneAudioDestinationNodeConstructor) {
        return function (_noneAudioDestination) {
            _inherits(ChannelMergerNode, _noneAudioDestination);

            function ChannelMergerNode(context) {
                var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : DEFAULT_OPTIONS$5;

                _classCallCheck(this, ChannelMergerNode);

                var nativeContext = getNativeContext(context);
                var mergedOptions = Object.assign({}, DEFAULT_OPTIONS$5, options);
                var nativeChannelMergerNode = createNativeChannelMergerNode(nativeContext, mergedOptions);
                var channelMergerNodeRenderer = isNativeOfflineAudioContext(nativeContext) ? createChannelMergerNodeRenderer() : null;
                return _possibleConstructorReturn(this, (ChannelMergerNode.__proto__ || Object.getPrototypeOf(ChannelMergerNode)).call(this, context, nativeChannelMergerNode, channelMergerNodeRenderer));
            }

            return ChannelMergerNode;
        }(noneAudioDestinationNodeConstructor);
    };

    var _this$5 = undefined;
    var createChannelMergerNodeRendererFactory = function createChannelMergerNodeRendererFactory(createNativeChannelMergerNode) {
        return function () {
            var nativeAudioNode = null;
            return {
                render: function render(proxy, nativeOfflineAudioContext) {
                    return tslib_1.__awaiter(_this$5, void 0, void 0, /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {
                        var options;
                        return _regeneratorRuntime.wrap(function _callee$(_context) {
                            while (1) {
                                switch (_context.prev = _context.next) {
                                    case 0:
                                        if (!(nativeAudioNode !== null)) {
                                            _context.next = 2;
                                            break;
                                        }

                                        return _context.abrupt('return', nativeAudioNode);

                                    case 2:
                                        nativeAudioNode = getNativeAudioNode(proxy);
                                        // If the initially used nativeAudioNode was not constructed on the same OfflineAudioContext it needs to be created again.
                                        if (!isOwnedByContext(nativeAudioNode, nativeOfflineAudioContext)) {
                                            options = {
                                                channelCount: nativeAudioNode.channelCount,
                                                channelCountMode: nativeAudioNode.channelCountMode,
                                                channelInterpretation: nativeAudioNode.channelInterpretation,
                                                numberOfInputs: nativeAudioNode.numberOfInputs
                                            };

                                            nativeAudioNode = createNativeChannelMergerNode(nativeOfflineAudioContext, options);
                                        }
                                        _context.next = 6;
                                        return renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioNode);

                                    case 6:
                                        return _context.abrupt('return', nativeAudioNode);

                                    case 7:
                                    case 'end':
                                        return _context.stop();
                                }
                            }
                        }, _callee, this);
                    }));
                }
            };
        };
    };

    var DEFAULT_OPTIONS$6 = {
        channelCount: 6,
        channelCountMode: 'explicit',
        channelInterpretation: 'discrete',
        numberOfOutputs: 6
    };
    var sanitizedOptions$1 = function sanitizedOptions(options) {
        return Object.assign({}, options, { channelCount: options.numberOfOutputs });
    };
    var createChannelSplitterNodeConstructor = function createChannelSplitterNodeConstructor(createChannelSplitterNodeRenderer, createNativeChannelSplitterNode, isNativeOfflineAudioContext, noneAudioDestinationNodeConstructor) {
        return function (_noneAudioDestination) {
            _inherits(ChannelSplitterNode, _noneAudioDestination);

            function ChannelSplitterNode(context) {
                var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : DEFAULT_OPTIONS$6;

                _classCallCheck(this, ChannelSplitterNode);

                var nativeContext = getNativeContext(context);
                var mergedOptions = sanitizedOptions$1(Object.assign({}, DEFAULT_OPTIONS$6, options));
                var nativeChannelSplitterNode = createNativeChannelSplitterNode(nativeContext, mergedOptions);
                var channelSplitterNodeRenderer = isNativeOfflineAudioContext(nativeContext) ? createChannelSplitterNodeRenderer() : null;
                return _possibleConstructorReturn(this, (ChannelSplitterNode.__proto__ || Object.getPrototypeOf(ChannelSplitterNode)).call(this, context, nativeChannelSplitterNode, channelSplitterNodeRenderer));
            }

            return ChannelSplitterNode;
        }(noneAudioDestinationNodeConstructor);
    };

    var _this$6 = undefined;
    var createChannelSplitterNodeRendererFactory = function createChannelSplitterNodeRendererFactory(createNativeChannelSplitterNode) {
        return function () {
            var nativeAudioNode = null;
            return {
                render: function render(proxy, nativeOfflineAudioContext) {
                    return tslib_1.__awaiter(_this$6, void 0, void 0, /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {
                        var options;
                        return _regeneratorRuntime.wrap(function _callee$(_context) {
                            while (1) {
                                switch (_context.prev = _context.next) {
                                    case 0:
                                        if (!(nativeAudioNode !== null)) {
                                            _context.next = 2;
                                            break;
                                        }

                                        return _context.abrupt('return', nativeAudioNode);

                                    case 2:
                                        nativeAudioNode = getNativeAudioNode(proxy);
                                        // If the initially used nativeAudioNode was not constructed on the same OfflineAudioContext it needs to be created again.
                                        if (!isOwnedByContext(nativeAudioNode, nativeOfflineAudioContext)) {
                                            options = {
                                                channelCount: nativeAudioNode.channelCount,
                                                channelCountMode: nativeAudioNode.channelCountMode,
                                                channelInterpretation: nativeAudioNode.channelInterpretation,
                                                numberOfOutputs: nativeAudioNode.numberOfOutputs
                                            };

                                            nativeAudioNode = createNativeChannelSplitterNode(nativeOfflineAudioContext, options);
                                        }
                                        _context.next = 6;
                                        return renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioNode);

                                    case 6:
                                        return _context.abrupt('return', nativeAudioNode);

                                    case 7:
                                    case 'end':
                                        return _context.stop();
                                }
                            }
                        }, _callee, this);
                    }));
                }
            };
        };
    };

    var isNativeAudioNode = function isNativeAudioNode(nativeAudioNodeOrAudioParam) {
        return nativeAudioNodeOrAudioParam.context !== undefined;
    };

    var createConnectMultipleOutputs = function createConnectMultipleOutputs(createIndexSizeError) {
        return function (outputAudioNodes, destinationAudioNodeOrAudioParam) {
            var output = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
            var input = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;

            var outputAudioNode = outputAudioNodes[output];
            if (outputAudioNode === undefined) {
                throw createIndexSizeError();
            }
            if (isNativeAudioNode(destinationAudioNodeOrAudioParam)) {
                return outputAudioNode.connect(destinationAudioNodeOrAudioParam, 0, input);
            }
            return outputAudioNode.connect(destinationAudioNodeOrAudioParam, 0);
        };
    };

    var DEFAULT_OPTIONS$7 = {
        channelCount: 2,
        channelCountMode: 'max',
        channelInterpretation: 'speakers',
        offset: 1
    };
    var createConstantSourceNodeConstructor = function createConstantSourceNodeConstructor(createAudioParam, createConstantSourceNodeRendererFactory, createNativeConstantSourceNode, isNativeOfflineAudioContext, noneAudioDestinationNodeConstructor) {
        return function (_noneAudioDestination) {
            _inherits(ConstantSourceNode, _noneAudioDestination);

            function ConstantSourceNode(context) {
                var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : DEFAULT_OPTIONS$7;

                _classCallCheck(this, ConstantSourceNode);

                var nativeContext = getNativeContext(context);
                var mergedOptions = Object.assign({}, DEFAULT_OPTIONS$7, options);
                var nativeConstantSourceNode = createNativeConstantSourceNode(nativeContext, mergedOptions);
                var isOffline = isNativeOfflineAudioContext(nativeContext);
                var constantSourceNodeRenderer = isOffline ? createConstantSourceNodeRendererFactory() : null;

                var _this = _possibleConstructorReturn(this, (ConstantSourceNode.__proto__ || Object.getPrototypeOf(ConstantSourceNode)).call(this, context, nativeConstantSourceNode, constantSourceNodeRenderer));

                _this._constantSourceNodeRenderer = constantSourceNodeRenderer;
                _this._nativeConstantSourceNode = nativeConstantSourceNode;
                /*
                 * Bug #62 & #74: Edge & Safari do not support ConstantSourceNodes and do not export the correct values for maxValue and
                 * minValue for GainNodes.
                 * Bug #75: Firefox does not export the correct values for maxValue and minValue.
                 */
                _this._offset = createAudioParam(context, isOffline, nativeConstantSourceNode.offset, 3.4028234663852886e38, -3.4028234663852886e38);
                return _this;
            }

            _createClass(ConstantSourceNode, [{
                key: 'start',
                value: function start() {
                    var when = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;

                    this._nativeConstantSourceNode.start(when);
                    if (this._constantSourceNodeRenderer !== null) {
                        this._constantSourceNodeRenderer.start = when;
                    }
                }
            }, {
                key: 'stop',
                value: function stop() {
                    var when = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;

                    this._nativeConstantSourceNode.stop(when);
                    if (this._constantSourceNodeRenderer !== null) {
                        this._constantSourceNodeRenderer.stop = when;
                    }
                }
            }, {
                key: 'offset',
                get: function get() {
                    return this._offset;
                }
            }, {
                key: 'onended',
                get: function get() {
                    return this._nativeConstantSourceNode.onended;
                },
                set: function set(value) {
                    this._nativeConstantSourceNode.onended = value;
                }
            }]);

            return ConstantSourceNode;
        }(noneAudioDestinationNodeConstructor);
    };

    var _this$7 = undefined;
    var createConstantSourceNodeRendererFactory = function createConstantSourceNodeRendererFactory(createNativeConstantSourceNode) {
        return function () {
            var nativeConstantSourceNode = null;
            var start = null;
            var stop = null;
            return {
                set start(value) {
                    start = value;
                },
                set stop(value) {
                    stop = value;
                },
                render: function render(proxy, nativeOfflineAudioContext) {
                    return tslib_1.__awaiter(_this$7, void 0, void 0, /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {
                        var options;
                        return _regeneratorRuntime.wrap(function _callee$(_context) {
                            while (1) {
                                switch (_context.prev = _context.next) {
                                    case 0:
                                        if (!(nativeConstantSourceNode !== null)) {
                                            _context.next = 2;
                                            break;
                                        }

                                        return _context.abrupt('return', nativeConstantSourceNode);

                                    case 2:
                                        nativeConstantSourceNode = getNativeAudioNode(proxy);
                                        /*
                                         * If the initially used nativeConstantSourceNode was not constructed on the same OfflineAudioContext it needs to be
                                         * created again.
                                         */

                                        if (isOwnedByContext(nativeConstantSourceNode, nativeOfflineAudioContext)) {
                                            _context.next = 12;
                                            break;
                                        }

                                        options = {
                                            channelCount: nativeConstantSourceNode.channelCount,
                                            channelCountMode: nativeConstantSourceNode.channelCountMode,
                                            channelInterpretation: nativeConstantSourceNode.channelInterpretation,
                                            offset: nativeConstantSourceNode.offset.value
                                        };

                                        nativeConstantSourceNode = createNativeConstantSourceNode(nativeOfflineAudioContext, options);
                                        if (start !== null) {
                                            nativeConstantSourceNode.start(start);
                                        }
                                        if (stop !== null) {
                                            nativeConstantSourceNode.stop(stop);
                                        }
                                        _context.next = 10;
                                        return renderAutomation(proxy.context, nativeOfflineAudioContext, proxy.offset, nativeConstantSourceNode.offset);

                                    case 10:
                                        _context.next = 14;
                                        break;

                                    case 12:
                                        _context.next = 14;
                                        return connectAudioParam(proxy.context, nativeOfflineAudioContext, proxy.offset);

                                    case 14:
                                        _context.next = 16;
                                        return renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeConstantSourceNode);

                                    case 16:
                                        return _context.abrupt('return', nativeConstantSourceNode);

                                    case 17:
                                    case 'end':
                                        return _context.stop();
                                }
                            }
                        }, _callee, this);
                    }));
                }
            };
        };
    };

    var getOutputAudioNodeAtIndex = function getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, output) {
        var outputAudioNode = outputAudioNodes[output];
        if (outputAudioNode === undefined) {
            throw createIndexSizeError();
        }
        return outputAudioNode;
    };
    var createDisconnectMultipleOutputs = function createDisconnectMultipleOutputs(createIndexSizeError) {
        return function (outputAudioNodes) {
            var outputOrDestinationAudioNodeOrAudioParam = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : undefined;
            var output = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : undefined;
            var input = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;

            if (outputOrDestinationAudioNodeOrAudioParam === undefined) {
                return outputAudioNodes.forEach(function (outputAudioNode) {
                    return outputAudioNode.disconnect();
                });
            }
            if (typeof outputOrDestinationAudioNodeOrAudioParam === 'number') {
                return getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, outputOrDestinationAudioNodeOrAudioParam).disconnect();
            }
            if (isNativeAudioNode(outputOrDestinationAudioNodeOrAudioParam)) {
                if (output === undefined) {
                    return outputAudioNodes.forEach(function (outputAudioNode) {
                        return outputAudioNode.disconnect(outputOrDestinationAudioNodeOrAudioParam);
                    });
                }
                if (input === undefined) {
                    return getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, output).disconnect(outputOrDestinationAudioNodeOrAudioParam, 0);
                }
                return getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, output).disconnect(outputOrDestinationAudioNodeOrAudioParam, 0, input);
            }
            if (output === undefined) {
                return outputAudioNodes.forEach(function (outputAudioNode) {
                    return outputAudioNode.disconnect(outputOrDestinationAudioNodeOrAudioParam);
                });
            }
            return getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, output).disconnect(outputOrDestinationAudioNodeOrAudioParam, 0);
        };
    };

    var DEFAULT_OPTIONS$8 = {
        channelCount: 2,
        channelCountMode: 'max',
        channelInterpretation: 'speakers',
        gain: 1
    };
    var createGainNodeConstructor = function createGainNodeConstructor(createAudioParam, createGainNodeRenderer, createNativeGainNode, isNativeOfflineAudioContext, noneAudioDestinationNodeConstructor) {
        return function (_noneAudioDestination) {
            _inherits(GainNode, _noneAudioDestination);

            function GainNode(context) {
                var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : DEFAULT_OPTIONS$8;

                _classCallCheck(this, GainNode);

                var nativeContext = getNativeContext(context);
                var mergedOptions = Object.assign({}, DEFAULT_OPTIONS$8, options);
                var nativeGainNode = createNativeGainNode(nativeContext, mergedOptions);
                var isOffline = isNativeOfflineAudioContext(nativeContext);
                var gainNodeRenderer = isOffline ? createGainNodeRenderer() : null;

                // Bug #74: Edge, Firefox & Safari do not export the correct values for maxValue and minValue.
                var _this = _possibleConstructorReturn(this, (GainNode.__proto__ || Object.getPrototypeOf(GainNode)).call(this, context, nativeGainNode, gainNodeRenderer));

                _this._gain = createAudioParam(context, isOffline, nativeGainNode.gain, 3.4028234663852886e38, -3.4028234663852886e38);
                return _this;
            }

            _createClass(GainNode, [{
                key: 'gain',
                get: function get() {
                    return this._gain;
                }
            }]);

            return GainNode;
        }(noneAudioDestinationNodeConstructor);
    };

    var _this$8 = undefined;
    var createGainNodeRendererFactory = function createGainNodeRendererFactory(createNativeGainNode) {
        return function () {
            var nativeGainNode = null;
            return {
                render: function render(proxy, nativeOfflineAudioContext) {
                    return tslib_1.__awaiter(_this$8, void 0, void 0, /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {
                        var options;
                        return _regeneratorRuntime.wrap(function _callee$(_context) {
                            while (1) {
                                switch (_context.prev = _context.next) {
                                    case 0:
                                        if (!(nativeGainNode !== null)) {
                                            _context.next = 2;
                                            break;
                                        }

                                        return _context.abrupt('return', nativeGainNode);

                                    case 2:
                                        nativeGainNode = getNativeAudioNode(proxy);
                                        // If the initially used nativeGainNode was not constructed on the same OfflineAudioContext it needs to be created again.

                                        if (isOwnedByContext(nativeGainNode, nativeOfflineAudioContext)) {
                                            _context.next = 10;
                                            break;
                                        }

                                        options = {
                                            channelCount: nativeGainNode.channelCount,
                                            channelCountMode: nativeGainNode.channelCountMode,
                                            channelInterpretation: nativeGainNode.channelInterpretation,
                                            gain: nativeGainNode.gain.value
                                        };

                                        nativeGainNode = createNativeGainNode(nativeOfflineAudioContext, options);
                                        _context.next = 8;
                                        return renderAutomation(proxy.context, nativeOfflineAudioContext, proxy.gain, nativeGainNode.gain);

                                    case 8:
                                        _context.next = 12;
                                        break;

                                    case 10:
                                        _context.next = 12;
                                        return connectAudioParam(proxy.context, nativeOfflineAudioContext, proxy.gain);

                                    case 12:
                                        _context.next = 14;
                                        return renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeGainNode);

                                    case 14:
                                        return _context.abrupt('return', nativeGainNode);

                                    case 15:
                                    case 'end':
                                        return _context.stop();
                                }
                            }
                        }, _callee, this);
                    }));
                }
            };
        };
    };

    var createInvalidAccessError = function createInvalidAccessError() {
        try {
            return new DOMException('', 'InvalidAccessError');
        } catch (err) {
            var exception = new Error();
            exception.code = 15;
            exception.name = 'InvalidAccessError';
            return exception;
        }
    };

    var wrapIIRFilterNodeGetFrequencyResponseMethod = function wrapIIRFilterNodeGetFrequencyResponseMethod(nativeIIRFilterNode) {
        nativeIIRFilterNode.getFrequencyResponse = function (getFrequencyResponse) {
            return function (frequencyHz, magResponse, phaseResponse) {
                if (frequencyHz.length !== magResponse.length || magResponse.length !== phaseResponse.length) {
                    throw createInvalidAccessError();
                }
                return getFrequencyResponse.call(nativeIIRFilterNode, frequencyHz, magResponse, phaseResponse);
            };
        }(nativeIIRFilterNode.getFrequencyResponse);
    };

    // The DEFAULT_OPTIONS are only of type Partial<IIIRFilterOptions> because there are no default values for feedback and feedforward.
    var DEFAULT_OPTIONS$9 = {
        channelCount: 2,
        channelCountMode: 'max',
        channelInterpretation: 'speakers'
    };
    var createIIRFilterNodeConstructor = function createIIRFilterNodeConstructor(createNativeIIRFilterNode, createIIRFilterNodeRenderer, isNativeOfflineAudioContext, noneAudioDestinationNodeConstructor) {
        return function (_noneAudioDestination) {
            _inherits(IIRFilterNode, _noneAudioDestination);

            function IIRFilterNode(context, options) {
                _classCallCheck(this, IIRFilterNode);

                var nativeContext = getNativeContext(context);
                var mergedOptions = Object.assign({}, DEFAULT_OPTIONS$9, options);
                var nativeIIRFilterNode = createNativeIIRFilterNode(nativeContext, mergedOptions);
                var iirFilterNodeRenderer = isNativeOfflineAudioContext(nativeContext) ? createIIRFilterNodeRenderer(mergedOptions.feedback, mergedOptions.feedforward) : null;

                // Bug #23 & #24: FirefoxDeveloper does not throw an InvalidAccessError.
                // @todo Write a test which allows other browsers to remain unpatched.
                var _this = _possibleConstructorReturn(this, (IIRFilterNode.__proto__ || Object.getPrototypeOf(IIRFilterNode)).call(this, context, nativeIIRFilterNode, iirFilterNodeRenderer));

                wrapIIRFilterNodeGetFrequencyResponseMethod(nativeIIRFilterNode);
                _this._nativeIIRFilterNode = nativeIIRFilterNode;
                return _this;
            }

            _createClass(IIRFilterNode, [{
                key: 'getFrequencyResponse',
                value: function getFrequencyResponse(frequencyHz, magResponse, phaseResponse) {
                    return this._nativeIIRFilterNode.getFrequencyResponse(frequencyHz, magResponse, phaseResponse);
                }
            }]);

            return IIRFilterNode;
        }(noneAudioDestinationNodeConstructor);
    };

    // This implementation as shamelessly inspired by source code of
    // tslint:disable-next-line:max-line-length
    // {@link https://chromium.googlesource.com/chromium/src.git/+/master/third_party/WebKit/Source/platform/audio/IIRFilter.cpp|Chromium's IIRFilter}.
    var filterBuffer = function filterBuffer(feedback, feedbackLength, feedforward, feedforwardLength, minLength, xBuffer, yBuffer, bufferIndex, bufferLength, input, output) {
        var inputLength = input.length;
        var i = bufferIndex;
        for (var j = 0; j < inputLength; j += 1) {
            var y = feedforward[0] * input[j];
            for (var k = 1; k < minLength; k += 1) {
                var x = i - k & bufferLength - 1; // tslint:disable-line:no-bitwise
                y += feedforward[k] * xBuffer[x];
                y -= feedback[k] * yBuffer[x];
            }
            for (var _k = minLength; _k < feedforwardLength; _k += 1) {
                y += feedforward[_k] * xBuffer[i - _k & bufferLength - 1]; // tslint:disable-line:no-bitwise
            }
            for (var _k2 = minLength; _k2 < feedbackLength; _k2 += 1) {
                y -= feedback[_k2] * yBuffer[i - _k2 & bufferLength - 1]; // tslint:disable-line:no-bitwise
            }
            xBuffer[i] = input[j];
            yBuffer[i] = y;
            i = i + 1 & bufferLength - 1; // tslint:disable-line:no-bitwise
            output[j] = y;
        }
        return i;
    };

    var _this$9 = undefined;
    var filterFullBuffer = function filterFullBuffer(renderedBuffer, nativeOfflineAudioContext, feedback, feedforward) {
        var feedbackLength = feedback.length;
        var feedforwardLength = feedforward.length;
        var minLength = Math.min(feedbackLength, feedforwardLength);
        if (feedback[0] !== 1) {
            for (var i = 0; i < feedbackLength; i += 1) {
                feedforward[i] /= feedback[0];
            }
            for (var _i = 1; _i < feedforwardLength; _i += 1) {
                feedback[_i] /= feedback[0];
            }
        }
        var bufferLength = 32;
        var xBuffer = new Float32Array(bufferLength);
        var yBuffer = new Float32Array(bufferLength);
        var filteredBuffer = nativeOfflineAudioContext.createBuffer(renderedBuffer.numberOfChannels, renderedBuffer.length, renderedBuffer.sampleRate);
        var numberOfChannels = renderedBuffer.numberOfChannels;
        for (var _i2 = 0; _i2 < numberOfChannels; _i2 += 1) {
            var input = renderedBuffer.getChannelData(_i2);
            var output = filteredBuffer.getChannelData(_i2);
            // @todo Add a test which checks support for TypedArray.prototype.fill().
            xBuffer.fill(0);
            yBuffer.fill(0);
            filterBuffer(feedback, feedbackLength, feedforward, feedforwardLength, minLength, xBuffer, yBuffer, 0, bufferLength, input, output);
        }
        return filteredBuffer;
    };
    var createIIRFilterNodeRendererFactory = function createIIRFilterNodeRendererFactory(createNativeAudioBufferSourceNode, nativeOfflineAudioContextConstructor, renderNativeOfflineAudioContext) {
        return function (feedback, feedforward) {
            var nativeAudioNode = null;
            return {
                render: function render(proxy, nativeOfflineAudioContext) {
                    return tslib_1.__awaiter(_this$9, void 0, void 0, /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {
                        var partialOfflineAudioContext;
                        return _regeneratorRuntime.wrap(function _callee$(_context) {
                            while (1) {
                                switch (_context.prev = _context.next) {
                                    case 0:
                                        if (!(nativeAudioNode !== null)) {
                                            _context.next = 2;
                                            break;
                                        }

                                        return _context.abrupt('return', nativeAudioNode);

                                    case 2:
                                        if (!(nativeOfflineAudioContextConstructor === null)) {
                                            _context.next = 4;
                                            break;
                                        }

                                        throw new Error();

                                    case 4:
                                        nativeAudioNode = getNativeAudioNode(proxy);
                                        _context.prev = 5;

                                        if (!(nativeOfflineAudioContext.createIIRFilter === undefined)) {
                                            _context.next = 8;
                                            break;
                                        }

                                        throw new Error();

                                    case 8:
                                        /*
                                         * If the initially used nativeAudioNode was not constructed on the same OfflineAudioContext it needs to be created
                                         * again.
                                         */
                                        if (!isOwnedByContext(nativeAudioNode, nativeOfflineAudioContext)) {
                                            nativeAudioNode = nativeOfflineAudioContext.createIIRFilter(feedforward, feedback);
                                        }
                                        return _context.abrupt('return', renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioNode).then(function () {
                                            return nativeAudioNode;
                                        }));

                                    case 12:
                                        _context.prev = 12;
                                        _context.t0 = _context['catch'](5);
                                        partialOfflineAudioContext = new nativeOfflineAudioContextConstructor(
                                        // Bug #47: The AudioDestinationNode in Edge and Safari gets not initialized correctly.
                                        proxy.context.destination.channelCount,
                                        // Bug #17: Safari does not yet expose the length.
                                        proxy.context.length, nativeOfflineAudioContext.sampleRate);
                                        return _context.abrupt('return', renderInputsOfAudioNode(proxy, partialOfflineAudioContext, partialOfflineAudioContext.destination).then(function () {
                                            return renderNativeOfflineAudioContext(partialOfflineAudioContext);
                                        }).then(function (renderedBuffer) {
                                            var audioBufferSourceNode = createNativeAudioBufferSourceNode(nativeOfflineAudioContext);
                                            audioBufferSourceNode.buffer = filterFullBuffer(renderedBuffer, nativeOfflineAudioContext, feedback, feedforward);
                                            audioBufferSourceNode.start(0);
                                            nativeAudioNode = audioBufferSourceNode;
                                            return nativeAudioNode;
                                        }));

                                    case 16:
                                    case 'end':
                                        return _context.stop();
                                }
                            }
                        }, _callee, this, [[5, 12]]);
                    }));
                }
            };
        };
    };

    var createIsNativeOfflineAudioContext = function createIsNativeOfflineAudioContext(nativeOfflineAudioContextConstructor) {
        return function (nativeContext) {
            if (nativeOfflineAudioContextConstructor === null) {
                throw new Error('The native OfflineAudioContext constructor is missing.');
            }
            return nativeContext instanceof nativeOfflineAudioContextConstructor;
        };
    };

    var createIsSupportedPromise = function createIsSupportedPromise(browsernizr, testAudioContextCloseMethodSupport, testAudioContextDecodeAudioDataMethodTypeErrorSupport, testAudioContextOptionsSupport, testChannelMergerNodeSupport) {
        if (browsernizr.promises && browsernizr.typedarrays && browsernizr.webaudio && cacheTestResult(testAudioContextCloseMethodSupport, function () {
            return testAudioContextCloseMethodSupport();
        }) && cacheTestResult(testAudioContextOptionsSupport, function () {
            return testAudioContextOptionsSupport();
        })) {
            return Promise.all([cacheTestResult(testAudioContextDecodeAudioDataMethodTypeErrorSupport, function () {
                return testAudioContextDecodeAudioDataMethodTypeErrorSupport();
            }), cacheTestResult(testChannelMergerNodeSupport, function () {
                return testChannelMergerNodeSupport();
            })]).then(function (_ref) {
                var _ref2 = _slicedToArray(_ref, 2),
                    audioContextDecodeAudioDataMethodTypeErrorSupport = _ref2[0],
                    channelMergerNodeSupport = _ref2[1];

                return audioContextDecodeAudioDataMethodTypeErrorSupport && channelMergerNodeSupport;
            });
        }
        return Promise.resolve(false);
    };

    var DEFAULT_OPTIONS$10 = {
        channelCount: 2,
        channelCountMode: 'max',
        channelInterpretation: 'speakers'
    };
    var createMediaElementAudioSourceNodeConstructor = function createMediaElementAudioSourceNodeConstructor(noneAudioDestinationNodeConstructor) {
        return function (_noneAudioDestination) {
            _inherits(MediaElementAudioSourceNode, _noneAudioDestination);

            function MediaElementAudioSourceNode(context, options) {
                _classCallCheck(this, MediaElementAudioSourceNode);

                var nativeContext = getNativeContext(context);
                var mergedOptions = Object.assign({}, DEFAULT_OPTIONS$10, options);
                var nativeMediaElementAudioSourceNode = nativeContext.createMediaElementSource(mergedOptions.mediaElement);

                // Bug #63: Edge & Firefox do not expose the mediaElement yet.
                var _this = _possibleConstructorReturn(this, (MediaElementAudioSourceNode.__proto__ || Object.getPrototypeOf(MediaElementAudioSourceNode)).call(this, context, nativeMediaElementAudioSourceNode, null));

                _this._mediaElement = mergedOptions.mediaElement;
                _this._nativeMediaElementAudioSourceNode = nativeMediaElementAudioSourceNode;
                return _this;
            }

            _createClass(MediaElementAudioSourceNode, [{
                key: 'mediaElement',
                get: function get() {
                    return this._nativeMediaElementAudioSourceNode.mediaElement === undefined ? this._mediaElement : this._nativeMediaElementAudioSourceNode.mediaElement;
                }
            }]);

            return MediaElementAudioSourceNode;
        }(noneAudioDestinationNodeConstructor);
    };

    var DEFAULT_OPTIONS$11 = {
        channelCount: 2,
        channelCountMode: 'max',
        channelInterpretation: 'speakers'
    };
    var createMediaStreamAudioSourceNodeConstructor = function createMediaStreamAudioSourceNodeConstructor(noneAudioDestinationNodeConstructor) {
        return function (_noneAudioDestination) {
            _inherits(MediaStreamAudioSourceNode, _noneAudioDestination);

            function MediaStreamAudioSourceNode(context, options) {
                _classCallCheck(this, MediaStreamAudioSourceNode);

                var nativeContext = getNativeContext(context);
                var mergedOptions = Object.assign({}, DEFAULT_OPTIONS$11, options);
                var nativeMediaStreamAudioSourceNode = nativeContext.createMediaStreamSource(mergedOptions.mediaStream);

                // Bug #63: Edge & Firefox do not expose the mediaStream yet.
                var _this = _possibleConstructorReturn(this, (MediaStreamAudioSourceNode.__proto__ || Object.getPrototypeOf(MediaStreamAudioSourceNode)).call(this, context, nativeMediaStreamAudioSourceNode, null));

                _this._mediaStream = mergedOptions.mediaStream;
                _this._nativeMediaStreamAudioSourceNode = nativeMediaStreamAudioSourceNode;
                return _this;
            }

            _createClass(MediaStreamAudioSourceNode, [{
                key: 'mediaStream',
                get: function get() {
                    return this._nativeMediaStreamAudioSourceNode.mediaStream === undefined ? this._mediaStream : this._nativeMediaStreamAudioSourceNode.mediaStream;
                }
            }]);

            return MediaStreamAudioSourceNode;
        }(noneAudioDestinationNodeConstructor);
    };

    var createMinimalAudioContextConstructor = function createMinimalAudioContextConstructor(createInvalidStateError, minimalBaseAudioContextConstructor, nativeAudioContextConstructor) {
        return function (_minimalBaseAudioCont) {
            _inherits(MinimalAudioContext, _minimalBaseAudioCont);

            function MinimalAudioContext() {
                var options = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};

                _classCallCheck(this, MinimalAudioContext);

                if (nativeAudioContextConstructor === null) {
                    throw new Error(); // @todo
                }
                var nativeAudioContext = new nativeAudioContextConstructor(options);
                // Bug #51 Only Chrome and Opera throw an error if the given latencyHint is invalid.
                if (!isValidLatencyHint(options.latencyHint)) {
                    throw new TypeError('The provided value \'' + options.latencyHint + '\' is not a valid enum value of type AudioContextLatencyCategory.');
                }

                var _this = _possibleConstructorReturn(this, (MinimalAudioContext.__proto__ || Object.getPrototypeOf(MinimalAudioContext)).call(this, nativeAudioContext, nativeAudioContext.destination.channelCount));

                _this._state = null;
                _this._nativeAudioContext = nativeAudioContext;
                /*
                 * Bug #34: Chrome and Opera pretend to be running right away, but fire an onstatechange event when the state actually
                 * changes to 'running'.
                 */
                if (nativeAudioContext.state === 'running') {
                    _this._state = 'suspended';
                    var revokeState = function revokeState() {
                        if (_this._state === 'suspended') {
                            _this._state = null;
                        }
                        if (nativeAudioContext.removeEventListener) {
                            nativeAudioContext.removeEventListener('statechange', revokeState);
                        }
                    };
                    nativeAudioContext.addEventListener('statechange', revokeState);
                }
                return _this;
            }

            _createClass(MinimalAudioContext, [{
                key: 'close',
                value: function close() {
                    var _this2 = this;

                    // Bug #35: Firefox does not throw an error if the AudioContext was closed before.
                    if (this.state === 'closed') {
                        return this._nativeAudioContext.close().then(function () {
                            throw createInvalidStateError();
                        });
                    }
                    // Bug #34: If the state was set to suspended before it should be revoked now.
                    if (this._state === 'suspended') {
                        this._state = null;
                    }
                    return this._nativeAudioContext.close().then(function () {
                        return deleteAudioGraph(_this2, _this2._nativeAudioContext);
                    });
                }
            }, {
                key: 'resume',
                value: function resume() {
                    return this._nativeAudioContext.resume().catch(function (err) {
                        // Bug #55: Chrome, Edge and Opera do throw an InvalidAccessError instead of an InvalidStateError.
                        // Bug #56: Safari invokes the catch handler but without an error.
                        if (err === undefined || err.code === 15) {
                            throw createInvalidStateError();
                        }
                        throw err;
                    });
                }
            }, {
                key: 'suspend',
                value: function suspend() {
                    return this._nativeAudioContext.suspend().catch(function (err) {
                        // Bug #56: Safari invokes the catch handler but without an error.
                        if (err === undefined) {
                            throw createInvalidStateError();
                        }
                        throw err;
                    });
                }
            }, {
                key: 'state',
                get: function get() {
                    return this._state !== null ? this._state : this._nativeAudioContext.state;
                }
            }]);

            return MinimalAudioContext;
        }(minimalBaseAudioContextConstructor);
    };

    var createMinimalBaseAudioContextConstructor = function createMinimalBaseAudioContextConstructor(audioDestinationNodeConstructor) {
        return function (_EventTarget) {
            _inherits(MinimalBaseAudioContext, _EventTarget);

            function MinimalBaseAudioContext(nativeContext, numberOfChannels) {
                _classCallCheck(this, MinimalBaseAudioContext);

                var _this = _possibleConstructorReturn(this, (MinimalBaseAudioContext.__proto__ || Object.getPrototypeOf(MinimalBaseAudioContext)).call(this));

                CONTEXT_STORE.set(_this, nativeContext);
                _this._nativeContext = nativeContext;
                _this._destination = new audioDestinationNodeConstructor(_this, numberOfChannels);
                return _this;
            }

            _createClass(MinimalBaseAudioContext, [{
                key: 'currentTime',
                get: function get() {
                    return this._nativeContext.currentTime;
                }
            }, {
                key: 'destination',
                get: function get() {
                    return this._destination;
                }
            }, {
                key: 'onstatechange',
                get: function get() {
                    return this._nativeContext.onstatechange;
                },
                set: function set(value) {
                    this._nativeContext.onstatechange = value;
                }
            }, {
                key: 'sampleRate',
                get: function get() {
                    return this._nativeContext.sampleRate;
                }
            }, {
                key: 'state',
                get: function get() {
                    return this._nativeContext.state;
                }
            }]);

            return MinimalBaseAudioContext;
        }(EventTarget);
    };

    var DEFAULT_OPTIONS$12 = {
        numberOfChannels: 1
    };
    var isSupportingPromises$1 = function isSupportingPromises(nativeOfflineAudioContext) {
        return cacheTestResult(testPromiseSupport, function () {
            return testPromiseSupport(nativeOfflineAudioContext);
        });
    };
    var createMinimalOfflineAudioContextConstructor = function createMinimalOfflineAudioContextConstructor(createInvalidStateError, minimalBaseAudioContextConstructor, nativeOfflineAudioContextConstructor, _startRendering) {
        return function (_minimalBaseAudioCont) {
            _inherits(MinimalOfflineAudioContext, _minimalBaseAudioCont);

            function MinimalOfflineAudioContext(options) {
                _classCallCheck(this, MinimalOfflineAudioContext);

                if (nativeOfflineAudioContextConstructor === null) {
                    throw new Error(); // @todo
                }

                var _Object$assign = Object.assign({}, DEFAULT_OPTIONS$12, options),
                    length = _Object$assign.length,
                    numberOfChannels = _Object$assign.numberOfChannels,
                    sampleRate = _Object$assign.sampleRate;

                var nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(numberOfChannels, length, sampleRate);
                // #21 Safari does not support promises and therefore would fire the statechange event before the promise can be resolved.
                if (!isSupportingPromises$1(nativeOfflineAudioContext)) {
                    nativeOfflineAudioContext.addEventListener('statechange', function () {
                        var i = 0;
                        var delayStateChangeEvent = function delayStateChangeEvent(event) {
                            if (_this._state === 'running') {
                                if (i > 0) {
                                    nativeOfflineAudioContext.removeEventListener('statechange', delayStateChangeEvent);
                                    event.stopImmediatePropagation();
                                    _this._waitForThePromiseToSettle(event);
                                } else {
                                    i += 1;
                                }
                            }
                        };
                        return delayStateChangeEvent;
                    }());
                }

                var _this = _possibleConstructorReturn(this, (MinimalOfflineAudioContext.__proto__ || Object.getPrototypeOf(MinimalOfflineAudioContext)).call(this, nativeOfflineAudioContext, numberOfChannels));

                _this._length = length;
                _this._nativeOfflineAudioContext = nativeOfflineAudioContext;
                _this._state = null;
                return _this;
            }

            _createClass(MinimalOfflineAudioContext, [{
                key: 'startRendering',
                value: function startRendering() {
                    var _this2 = this;

                    /*
                     * Bug #9 & #59: It is theoretically possible that startRendering() will first render a partialOfflineAudioContext. Therefore
                     * the state of the nativeOfflineAudioContext might no transition to running immediately.
                     */
                    if (this._state === 'running') {
                        return Promise.reject(createInvalidStateError());
                    }
                    this._state = 'running';
                    return _startRendering(this.destination, this._nativeOfflineAudioContext).then(function (audioBuffer) {
                        // Bug #5: Safari does not support copyFromChannel() and copyToChannel().
                        if (typeof audioBuffer.copyFromChannel !== 'function') {
                            wrapAudioBufferCopyChannelMethods(audioBuffer);
                        }
                        _this2._state = null;
                        deleteAudioGraph(_this2, _this2._nativeOfflineAudioContext);
                        return audioBuffer;
                    })
                    // @todo This could be written more elegantly when Promise.finally() becomes avalaible.
                    .catch(function (err) {
                        _this2._state = null;
                        deleteAudioGraph(_this2, _this2._nativeOfflineAudioContext);
                        throw err;
                    });
                }
            }, {
                key: '_waitForThePromiseToSettle',
                value: function _waitForThePromiseToSettle(event) {
                    var _this3 = this;

                    if (this._state === null) {
                        this._nativeOfflineAudioContext.dispatchEvent(event);
                    } else {
                        setTimeout(function () {
                            return _this3._waitForThePromiseToSettle(event);
                        });
                    }
                }
            }, {
                key: 'length',
                get: function get() {
                    // Bug #17: Safari does not yet expose the length.
                    if (this._nativeOfflineAudioContext.length === undefined) {
                        return this._length;
                    }
                    return this._nativeOfflineAudioContext.length;
                }
            }, {
                key: 'state',
                get: function get() {
                    return this._state === null ? this._nativeOfflineAudioContext.state : this._state;
                }
            }]);

            return MinimalOfflineAudioContext;
        }(minimalBaseAudioContextConstructor);
    };

    // @todo Use the same strategy to assign all node specific options as well.
    var assignNativeAudioNodeOption = function assignNativeAudioNodeOption(nativeAudioNode, options, option) {
        var value = options[option];
        if (value !== undefined && value !== nativeAudioNode[option]) {
            nativeAudioNode[option] = value;
        }
    };
    var assignNativeAudioNodeOptions = function assignNativeAudioNodeOptions(nativeAudioNode) {
        var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};

        assignNativeAudioNodeOption(nativeAudioNode, options, 'channelCount');
        assignNativeAudioNodeOption(nativeAudioNode, options, 'channelCountMode');
        assignNativeAudioNodeOption(nativeAudioNode, options, 'channelInterpretation');
    };

    var testAnalyserNodeGetFloatTimeDomainDataMethodSupport = function testAnalyserNodeGetFloatTimeDomainDataMethodSupport(nativeAnalyserNode) {
        return typeof nativeAnalyserNode.getFloatTimeDomainData === 'function';
    };

    var wrapAnalyserNodeGetFloatTimeDomainDataMethod = function wrapAnalyserNodeGetFloatTimeDomainDataMethod(nativeAnalyserNode) {
        nativeAnalyserNode.getFloatTimeDomainData = function (array) {
            var byteTimeDomainData = new Uint8Array(array.length);
            nativeAnalyserNode.getByteTimeDomainData(byteTimeDomainData);
            var length = Math.max(byteTimeDomainData.length, nativeAnalyserNode.fftSize);
            for (var i = 0; i < length; i += 1) {
                array[i] = (byteTimeDomainData[i] - 128) * 0.0078125;
            }
            return array;
        };
    };

    var isSupportingAnalyserNodeGetFloatTimeDomainDataMethod = function isSupportingAnalyserNodeGetFloatTimeDomainDataMethod(nativeAnalyserNode) {
        return cacheTestResult(testAnalyserNodeGetFloatTimeDomainDataMethodSupport, function () {
            return testAnalyserNodeGetFloatTimeDomainDataMethodSupport(nativeAnalyserNode);
        });
    };
    var createNativeAnalyserNode = function createNativeAnalyserNode(nativeContext, options) {
        var nativeAnalyserNode = nativeContext.createAnalyser();
        assignNativeAudioNodeOptions(nativeAnalyserNode, options);
        if (options.fftSize !== nativeAnalyserNode.fftSize) {
            nativeAnalyserNode.fftSize = options.fftSize;
        }
        if (options.maxDecibels !== nativeAnalyserNode.maxDecibels) {
            nativeAnalyserNode.maxDecibels = options.maxDecibels;
        }
        if (options.minDecibels !== nativeAnalyserNode.minDecibels) {
            nativeAnalyserNode.minDecibels = options.minDecibels;
        }
        if (options.smoothingTimeConstant !== nativeAnalyserNode.smoothingTimeConstant) {
            nativeAnalyserNode.smoothingTimeConstant = options.smoothingTimeConstant;
        }
        // Bug #37: Only Edge and Safari create an AnalyserNode with the default properties.
        if (nativeAnalyserNode.channelCount === 1) {
            nativeAnalyserNode.channelCount = 2;
        }
        // Bug #36: Safari does not support getFloatTimeDomainData() yet.
        if (!isSupportingAnalyserNodeGetFloatTimeDomainDataMethod(nativeAnalyserNode)) {
            wrapAnalyserNodeGetFloatTimeDomainDataMethod(nativeAnalyserNode);
        }
        return nativeAnalyserNode;
    };

    var testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport = function testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport(nativeContext) {
        var audioBuffer = nativeContext.createBufferSource();
        audioBuffer.start();
        try {
            audioBuffer.start();
        } catch (err) {
            return true;
        }
        return false;
    };

    var testAudioScheduledSourceNodeStartMethodNegativeParametersSupport = function testAudioScheduledSourceNodeStartMethodNegativeParametersSupport(nativeContext) {
        var audioBuffer = nativeContext.createBufferSource();
        try {
            audioBuffer.start(-1);
        } catch (err) {
            return err instanceof RangeError;
        }
        return false;
    };

    var testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport = function testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport(nativeContext) {
        var audioBuffer = nativeContext.createBuffer(1, 1, 44100);
        var audioBufferSourceNode = nativeContext.createBufferSource();
        audioBufferSourceNode.buffer = audioBuffer;
        audioBufferSourceNode.start();
        audioBufferSourceNode.stop();
        try {
            audioBufferSourceNode.stop();
            return true;
        } catch (err) {
            return false;
        }
    };

    var testAudioScheduledSourceNodeStopMethodNegativeParametersSupport = function testAudioScheduledSourceNodeStopMethodNegativeParametersSupport(nativeContext) {
        var audioBuffer = nativeContext.createBufferSource();
        try {
            audioBuffer.stop(-1);
        } catch (err) {
            return err instanceof RangeError;
        }
        return false;
    };

    var wrapAudioBufferSourceNodeStartMethodConsecutiveCalls = function wrapAudioBufferSourceNodeStartMethodConsecutiveCalls(nativeAudioBufferSourceNode) {
        nativeAudioBufferSourceNode.start = function (start) {
            var isScheduled = false;
            return function () {
                var when = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;
                var offset = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
                var duration = arguments[2];

                if (isScheduled) {
                    throw createInvalidStateError();
                }
                start.call(nativeAudioBufferSourceNode, when, offset, duration);
                isScheduled = true;
            };
        }(nativeAudioBufferSourceNode.start);
    };

    var wrapAudioScheduledSourceNodeStartMethodNegativeParameters = function wrapAudioScheduledSourceNodeStartMethodNegativeParameters(nativeAudioScheduledSourceNode) {
        nativeAudioScheduledSourceNode.start = function (start) {
            return function () {
                var when = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;
                var offset = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
                var duration = arguments[2];

                if (typeof duration === 'number' && duration < 0 || offset < 0 || when < 0) {
                    throw new RangeError("The parameters can't be negative.");
                }
                start.call(nativeAudioScheduledSourceNode, when, offset, duration);
            };
        }(nativeAudioScheduledSourceNode.start);
    };

    var wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls = function wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls(nativeAudioScheduledSourceNode, nativeContext) {
        var gainNode = nativeContext.createGain();
        nativeAudioScheduledSourceNode.connect(gainNode);
        var disconnectGainNode = function (disconnect) {
            return function () {
                disconnect.call(nativeAudioScheduledSourceNode, gainNode);
                nativeAudioScheduledSourceNode.removeEventListener('ended', disconnectGainNode);
            };
        }(nativeAudioScheduledSourceNode.disconnect);
        nativeAudioScheduledSourceNode.addEventListener('ended', disconnectGainNode);
        nativeAudioScheduledSourceNode.connect = function (destination) {
            var output = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
            var input = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;

            if (destination instanceof AudioNode) {
                gainNode.connect.call(gainNode, destination, output, input);
                // Bug #11: Safari does not support chaining yet.
                return destination;
            }
            // @todo This return statement is necessary to satisfy TypeScript.
            return gainNode.connect.call(gainNode, destination, output);
        };
        nativeAudioScheduledSourceNode.disconnect = function () {
            gainNode.disconnect.apply(gainNode, arguments);
        };
        nativeAudioScheduledSourceNode.stop = function (stop) {
            var isStopped = false;
            return function () {
                var when = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;

                if (isStopped) {
                    try {
                        stop.call(nativeAudioScheduledSourceNode, when);
                    } catch (err) {
                        gainNode.gain.setValueAtTime(0, when);
                    }
                } else {
                    stop.call(nativeAudioScheduledSourceNode, when);
                    isStopped = true;
                }
            };
        }(nativeAudioScheduledSourceNode.stop);
    };

    var wrapAudioScheduledSourceNodeStopMethodNegativeParameters = function wrapAudioScheduledSourceNodeStopMethodNegativeParameters(nativeAudioScheduledSourceNode) {
        nativeAudioScheduledSourceNode.stop = function (stop) {
            return function () {
                var when = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;

                if (when < 0) {
                    throw new RangeError("The parameter can't be negative.");
                }
                stop.call(nativeAudioScheduledSourceNode, when);
            };
        }(nativeAudioScheduledSourceNode.stop);
    };

    var createNativeAudioBufferSourceNode = function createNativeAudioBufferSourceNode(nativeContext) {
        var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};

        var nativeAudioBufferSourceNode = nativeContext.createBufferSource();
        assignNativeAudioNodeOptions(nativeAudioBufferSourceNode, options);
        // Bug #71: Edge does not allow to set the buffer to null.
        if (options.buffer !== undefined && options.buffer !== null) {
            nativeAudioBufferSourceNode.buffer = options.buffer;
        }
        // @todo if (options.detune !== undefined) {
        // @todo    nativeAudioBufferSourceNode.detune.value = options.detune;
        // @todo }
        if (options.loop !== undefined) {
            nativeAudioBufferSourceNode.loop = options.loop;
        }
        if (options.loopEnd !== undefined) {
            nativeAudioBufferSourceNode.loopEnd = options.loopEnd;
        }
        if (options.loopStart !== undefined) {
            nativeAudioBufferSourceNode.loopStart = options.loopStart;
        }
        if (options.playbackRate !== undefined) {
            nativeAudioBufferSourceNode.playbackRate.value = options.playbackRate;
        }
        // Bug #69: Safari does allow calls to start() of an already scheduled AudioBufferSourceNode.
        if (!cacheTestResult(testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport, function () {
            return testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport(nativeContext);
        })) {
            wrapAudioBufferSourceNodeStartMethodConsecutiveCalls(nativeAudioBufferSourceNode);
        }
        // Bug #44: Only Chrome & Opera throw a RangeError yet.
        if (!cacheTestResult(testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, function () {
            return testAudioScheduledSourceNodeStartMethodNegativeParametersSupport(nativeContext);
        })) {
            wrapAudioScheduledSourceNodeStartMethodNegativeParameters(nativeAudioBufferSourceNode);
        }
        // Bug #19: Safari does not ignore calls to stop() of an already stopped AudioBufferSourceNode.
        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, function () {
            return testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport(nativeContext);
        })) {
            wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls(nativeAudioBufferSourceNode, nativeContext);
        }
        // Bug #44: No browser does throw a RangeError yet.
        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, function () {
            return testAudioScheduledSourceNodeStopMethodNegativeParametersSupport(nativeContext);
        })) {
            wrapAudioScheduledSourceNodeStopMethodNegativeParameters(nativeAudioBufferSourceNode);
        }
        return nativeAudioBufferSourceNode;
    };

    var createNativeAudioContextConstructor = function createNativeAudioContextConstructor(window) {
        if (window === null) {
            return null;
        }
        if (window.hasOwnProperty('AudioContext')) {
            return window.AudioContext;
        }
        return window.hasOwnProperty('webkitAudioContext') ? window.webkitAudioContext : null;
    };

    var createNativeAudioDestinationNode = function createNativeAudioDestinationNode(nativeContext, channelCount, isNodeOfNativeOfflineAudioContext) {
        var nativeAudioDestinationNode = nativeContext.destination;
        // @todo Which bug is that covering?
        if (nativeAudioDestinationNode.channelCount !== channelCount) {
            nativeAudioDestinationNode.channelCount = channelCount;
        }
        // Bug #83: Edge & Safari do not have the correct channelCountMode.
        if (isNodeOfNativeOfflineAudioContext && nativeAudioDestinationNode.channelCountMode !== 'explicit') {
            nativeAudioDestinationNode.channelCountMode = 'explicit';
        }
        // Bug #47: The AudioDestinationNode in Edge and Safari do not initialize the maxChannelCount property correctly.
        if (nativeAudioDestinationNode.maxChannelCount === 0) {
            Object.defineProperty(nativeAudioDestinationNode, 'maxChannelCount', {
                get: function get() {
                    return nativeAudioDestinationNode.channelCount;
                }
            });
        }
        return nativeAudioDestinationNode;
    };

    var createNativeAudioWorkletNodeConstructor = function createNativeAudioWorkletNodeConstructor(window) {
        if (window === null) {
            return null;
        }
        return window.hasOwnProperty('AudioWorkletNode') ? window.AudioWorkletNode : null;
    };

    var testClonabilityOfAudioWorkletNodeOptions = function testClonabilityOfAudioWorkletNodeOptions(audioWorkletNodeOptions) {
        var _ref = new MessageChannel(),
            port1 = _ref.port1;

        try {
            // This will throw an error if the audioWorkletNodeOptions are not clonable.
            port1.postMessage(audioWorkletNodeOptions);
        } finally {
            port1.close();
        }
    };

    var createNativeAudioWorkletNodeFactory = function createNativeAudioWorkletNodeFactory(createInvalidStateError, createNativeAudioWorkletNodeFaker, createNotSupportedError) {
        return function (nativeContext, nativeAudioWorkletNodeConstructor, name, processorDefinition, options) {
            if (nativeAudioWorkletNodeConstructor !== null) {
                try {
                    // Bug #86: Chrome Canary does not invoke the process() function if the corresponding AudioWorkletNode has no output.
                    var nativeAudioWorkletNode = options.numberOfInputs !== 0 && options.numberOfOutputs === 0 ? new nativeAudioWorkletNodeConstructor(nativeContext, name, Object.assign({}, options, { numberOfOutputs: 1, outputChannelCount: [1], parameterData: Object.assign({}, options.parameterData, { hasNoOutput: 1 }) })) : new nativeAudioWorkletNodeConstructor(nativeContext, name, options);
                    /*
                     * Bug #61: Overwriting the property accessors is necessary as long as some browsers have no native implementation to
                     * achieve a consistent behavior.
                     */
                    Object.defineProperties(nativeAudioWorkletNode, {
                        channelCount: {
                            get: function get() {
                                return options.channelCount;
                            },
                            set: function set() {
                                throw createInvalidStateError();
                            }
                        },
                        channelCountMode: {
                            get: function get() {
                                return 'explicit';
                            },
                            set: function set() {
                                throw createInvalidStateError();
                            }
                        }
                    });
                    return nativeAudioWorkletNode;
                } catch (err) {
                    // Bug #60: Chrome Canary throws an InvalidStateError instead of a NotSupportedError.
                    if (err.code === 11 && nativeContext.state !== 'closed') {
                        throw createNotSupportedError();
                    }
                    throw err;
                }
            }
            // Bug #61: Only Chrome Canary has an implementation of the AudioWorkletNode yet.
            if (processorDefinition === undefined) {
                throw createNotSupportedError();
            }
            testClonabilityOfAudioWorkletNodeOptions(options);
            return createNativeAudioWorkletNodeFaker(nativeContext, processorDefinition, options);
        };
    };

    var cloneAudioWorkletNodeOptions = function cloneAudioWorkletNodeOptions(audioWorkletNodeOptions) {
        return new Promise(function (resolve, reject) {
            var _ref = new MessageChannel(),
                port1 = _ref.port1,
                port2 = _ref.port2;

            port1.onmessage = function (_ref2) {
                var data = _ref2.data;

                port1.close();
                port2.close();
                resolve(data);
            };
            port1.onmessageerror = function (_ref3) {
                var data = _ref3.data;

                port1.close();
                port2.close();
                reject(data);
            };
            // This will throw an error if the audioWorkletNodeOptions are not clonable.
            port2.postMessage(audioWorkletNodeOptions);
        });
    };

    var _this$10 = undefined;
    var createAudioWorkletProcessorPromise = function createAudioWorkletProcessorPromise(processorDefinition, audioWorkletNodeOptions) {
        return tslib_1.__awaiter(_this$10, void 0, void 0, /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {
            var clonedAudioWorkletNodeOptions;
            return _regeneratorRuntime.wrap(function _callee$(_context) {
                while (1) {
                    switch (_context.prev = _context.next) {
                        case 0:
                            _context.next = 2;
                            return cloneAudioWorkletNodeOptions(audioWorkletNodeOptions);

                        case 2:
                            clonedAudioWorkletNodeOptions = _context.sent;
                            return _context.abrupt('return', new processorDefinition(clonedAudioWorkletNodeOptions));

                        case 4:
                        case 'end':
                            return _context.stop();
                    }
                }
            }, _callee, this);
        }));
    };
    var createAudioWorkletProcessor = function createAudioWorkletProcessor(nativeContext, nativeAudioWorkletNode, processorDefinition, audioWorkletNodeOptions) {
        var nodeToProcessorMap = NODE_TO_PROCESSOR_MAPS.get(nativeContext);
        if (nodeToProcessorMap === undefined) {
            nodeToProcessorMap = new WeakMap();
            NODE_TO_PROCESSOR_MAPS.set(nativeContext, nodeToProcessorMap);
        }
        var audioWorkletProcessorPromise = createAudioWorkletProcessorPromise(processorDefinition, audioWorkletNodeOptions);
        nodeToProcessorMap.set(nativeAudioWorkletNode, audioWorkletProcessorPromise);
        return audioWorkletProcessorPromise;
    };

    var createNativeAudioWorkletNodeFakerFactory = function createNativeAudioWorkletNodeFakerFactory(connectMultipleOutputs, createIndexSizeError, createInvalidStateError, createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeConstantSourceNode, createNativeGainNode, createNotSupportedError, disconnectMultipleOutputs) {
        return function (nativeAudioContext, processorDefinition, options) {
            if (options.numberOfInputs === 0 && options.numberOfOutputs === 0) {
                throw createNotSupportedError();
            }
            if (options.outputChannelCount !== undefined) {
                if (options.outputChannelCount.length !== options.numberOfOutputs) {
                    throw createIndexSizeError();
                }
                // @todo Check if any of the channelCount values is greater than the implementation's maximum number of channels.
                if (options.outputChannelCount.some(function (channelCount) {
                    return channelCount < 1;
                })) {
                    throw createNotSupportedError();
                }
            }
            // Bug #61: This is not part of the standard but required for the faker to work.
            if (options.channelCountMode !== 'explicit') {
                throw createNotSupportedError();
            }
            var numberOfInputChannels = options.channelCount * options.numberOfInputs;
            var numberOfOutputChannels = options.outputChannelCount.reduce(function (sum, value) {
                return sum + value;
            }, 0);
            var numberOfParameters = processorDefinition.parameterDescriptors.length;
            // Bug #61: This is not part of the standard but required for the faker to work.
            if (numberOfInputChannels + numberOfParameters > 6 || numberOfOutputChannels > 6) {
                throw createNotSupportedError();
            }
            var messageChannel = new MessageChannel();
            var gainNodes = [];
            var inputChannelSplitterNodes = [];
            for (var i = 0; i < options.numberOfInputs; i += 1) {
                gainNodes.push(createNativeGainNode(nativeAudioContext, {
                    channelCount: options.channelCount,
                    channelCountMode: options.channelCountMode,
                    channelInterpretation: options.channelInterpretation,
                    gain: 1
                }));
                inputChannelSplitterNodes.push(createNativeChannelSplitterNode(nativeAudioContext, {
                    channelCount: options.channelCount,
                    channelCountMode: 'explicit',
                    channelInterpretation: 'discrete',
                    numberOfOutputs: options.channelCount
                }));
            }
            var constantSourceNodes = [];
            var _iteratorNormalCompletion = true;
            var _didIteratorError = false;
            var _iteratorError = undefined;

            try {
                var _loop2 = function _loop2() {
                    var _step$value = _step.value,
                        defaultValue = _step$value.defaultValue,
                        maxValue = _step$value.maxValue,
                        minValue = _step$value.minValue;

                    var constantSourceNode = createNativeConstantSourceNode(nativeAudioContext, {
                        channelCount: 1,
                        channelCountMode: 'explicit',
                        channelInterpretation: 'discrete',
                        offset: defaultValue === undefined ? 0 : defaultValue
                    });
                    Object.defineProperties(constantSourceNode.offset, {
                        defaultValue: {
                            get: function get() {
                                return defaultValue === undefined ? 0 : defaultValue;
                            }
                        },
                        maxValue: {
                            get: function get() {
                                return maxValue === undefined ? 3.4028234663852886e38 : maxValue;
                            }
                        },
                        minValue: {
                            get: function get() {
                                return minValue === undefined ? -3.4028234663852886e38 : minValue;
                            }
                        }
                    });
                    constantSourceNodes.push(constantSourceNode);
                };

                for (var _iterator = processorDefinition.parameterDescriptors[Symbol.iterator](), _step; !(_iteratorNormalCompletion = (_step = _iterator.next()).done); _iteratorNormalCompletion = true) {
                    _loop2();
                }
            } catch (err) {
                _didIteratorError = true;
                _iteratorError = err;
            } finally {
                try {
                    if (!_iteratorNormalCompletion && _iterator.return) {
                        _iterator.return();
                    }
                } finally {
                    if (_didIteratorError) {
                        throw _iteratorError;
                    }
                }
            }

            var inputChannelMergerNode = createNativeChannelMergerNode(nativeAudioContext, {
                numberOfInputs: Math.max(1, numberOfInputChannels + numberOfParameters)
            });
            var bufferSize = 512;
            var scriptProcessorNode = nativeAudioContext.createScriptProcessor(bufferSize, numberOfInputChannels + numberOfParameters,
            // Bug #87: Only Firefox will fire an AudioProcessingEvent if there is no connected output.
            Math.max(1, numberOfOutputChannels));
            var outputChannelSplitterNode = createNativeChannelSplitterNode(nativeAudioContext, {
                channelCount: Math.max(1, numberOfOutputChannels),
                channelCountMode: 'explicit',
                channelInterpretation: 'discrete',
                numberOfOutputs: Math.max(1, numberOfOutputChannels)
            });
            var outputChannelMergerNodes = [];
            for (var _i = 0; _i < options.numberOfOutputs; _i += 1) {
                outputChannelMergerNodes.push(createNativeChannelMergerNode(nativeAudioContext, {
                    numberOfInputs: options.outputChannelCount[_i]
                }));
            }
            for (var _i2 = 0; _i2 < options.numberOfInputs; _i2 += 1) {
                gainNodes[_i2].connect(inputChannelSplitterNodes[_i2]);
                for (var j = 0; j < options.channelCount; j += 1) {
                    inputChannelSplitterNodes[_i2].connect(inputChannelMergerNode, j, _i2 * options.channelCount + j);
                }
            }
            var parameterMap = new ReadOnlyMap(processorDefinition.parameterDescriptors.map(function (_ref, index) {
                var name = _ref.name;

                var constantSourceNode = constantSourceNodes[index];
                constantSourceNode.connect(inputChannelMergerNode, 0, numberOfInputChannels + index);
                constantSourceNode.start(0);
                return [name, constantSourceNode.offset];
            }));
            inputChannelMergerNode.connect(scriptProcessorNode);
            if (options.numberOfOutputs > 0) {
                scriptProcessorNode.connect(outputChannelSplitterNode);
            }
            for (var _i3 = 0, outputChannelSplitterNodeOutput = 0; _i3 < options.numberOfOutputs; _i3 += 1) {
                var outputChannelMergerNode = outputChannelMergerNodes[_i3];
                for (var _j = 0; _j < options.outputChannelCount[_i3]; _j += 1) {
                    outputChannelSplitterNode.connect(outputChannelMergerNode, outputChannelSplitterNodeOutput + _j, _j);
                }
                outputChannelSplitterNodeOutput += options.outputChannelCount[_i3];
            }
            var onprocessorerror = null;
            // Bug #87: Expose at least one output to make this node connectable.
            var outputAudioNodes = options.numberOfOutputs === 0 ? [scriptProcessorNode] : outputChannelMergerNodes;
            var faker = {
                get bufferSize() {
                    return bufferSize;
                },
                get channelCount() {
                    return options.channelCount;
                },
                set channelCount(_) {
                    // Bug #61: This is not part of the standard but required for the faker to work.
                    throw createInvalidStateError();
                },
                get channelCountMode() {
                    return options.channelCountMode;
                },
                set channelCountMode(_) {
                    // Bug #61: This is not part of the standard but required for the faker to work.
                    throw createInvalidStateError();
                },
                get channelInterpretation() {
                    return gainNodes[0].channelInterpretation;
                },
                set channelInterpretation(value) {
                    var _iteratorNormalCompletion2 = true;
                    var _didIteratorError2 = false;
                    var _iteratorError2 = undefined;

                    try {
                        for (var _iterator2 = gainNodes[Symbol.iterator](), _step2; !(_iteratorNormalCompletion2 = (_step2 = _iterator2.next()).done); _iteratorNormalCompletion2 = true) {
                            var gainNode = _step2.value;

                            gainNode.channelInterpretation = value;
                        }
                    } catch (err) {
                        _didIteratorError2 = true;
                        _iteratorError2 = err;
                    } finally {
                        try {
                            if (!_iteratorNormalCompletion2 && _iterator2.return) {
                                _iterator2.return();
                            }
                        } finally {
                            if (_didIteratorError2) {
                                throw _iteratorError2;
                            }
                        }
                    }
                },
                get context() {
                    return gainNodes[0].context;
                },
                get inputs() {
                    return gainNodes;
                },
                get numberOfInputs() {
                    return options.numberOfInputs;
                },
                get numberOfOutputs() {
                    return options.numberOfOutputs;
                },
                get onprocessorerror() {
                    return onprocessorerror;
                },
                set onprocessorerror(value) {
                    if (value === null || typeof value === 'function') {
                        onprocessorerror = value;
                    } else {
                        onprocessorerror = null;
                    }
                },
                get parameters() {
                    return parameterMap;
                },
                get port() {
                    return messageChannel.port2;
                },
                addEventListener: function addEventListener() {
                    return gainNodes[0].addEventListener(arguments.length <= 0 ? undefined : arguments[0], arguments.length <= 1 ? undefined : arguments[1], arguments.length <= 2 ? undefined : arguments[2]);
                },
                connect: function connect() {
                    return connectMultipleOutputs(outputAudioNodes, arguments.length <= 0 ? undefined : arguments[0], arguments.length <= 1 ? undefined : arguments[1], arguments.length <= 2 ? undefined : arguments[2]);
                },
                disconnect: function disconnect() {
                    return disconnectMultipleOutputs(outputAudioNodes, arguments.length <= 0 ? undefined : arguments[0], arguments.length <= 1 ? undefined : arguments[1], arguments.length <= 2 ? undefined : arguments[2]);
                },
                dispatchEvent: function dispatchEvent() {
                    return gainNodes[0].dispatchEvent(arguments.length <= 0 ? undefined : arguments[0]);
                },
                removeEventListener: function removeEventListener() {
                    return gainNodes[0].removeEventListener(arguments.length <= 0 ? undefined : arguments[0], arguments.length <= 1 ? undefined : arguments[1], arguments.length <= 2 ? undefined : arguments[2]);
                }
            };
            processorDefinition.prototype.port = messageChannel.port1;
            var audioWorkletProcessor = null;
            var audioWorkletProcessorPromise = createAudioWorkletProcessor(nativeAudioContext, faker, processorDefinition, options);
            audioWorkletProcessorPromise.then(function (dWrkltPrcssr) {
                return audioWorkletProcessor = dWrkltPrcssr;
            });
            var inputs = createNestedArrays(options.numberOfInputs, options.channelCount);
            var outputs = createNestedArrays(options.numberOfOutputs, options.outputChannelCount);
            var parameters = processorDefinition.parameterDescriptors.reduce(function (prmtrs, _ref2) {
                var name = _ref2.name;
                return Object.assign({}, prmtrs, _defineProperty({}, name, new Float32Array(128)));
            }, {});
            var isActive = true;
            scriptProcessorNode.onaudioprocess = function (_ref3) {
                var inputBuffer = _ref3.inputBuffer,
                    outputBuffer = _ref3.outputBuffer;

                if (audioWorkletProcessor !== null) {
                    var _loop = function _loop(_i4) {
                        for (var _j2 = 0; _j2 < options.numberOfInputs; _j2 += 1) {
                            for (var k = 0; k < options.channelCount; k += 1) {
                                // Bug #5: Safari does not support copyFromChannel().
                                var slicedInputBuffer = inputBuffer.getChannelData(k).slice(_i4, _i4 + 128);
                                inputs[_j2][k].set(slicedInputBuffer);
                            }
                        }
                        processorDefinition.parameterDescriptors.forEach(function (_ref4, index) {
                            var name = _ref4.name;

                            var slicedInputBuffer = inputBuffer.getChannelData(numberOfInputChannels + index).slice(_i4, _i4 + 128);
                            parameters[name].set(slicedInputBuffer);
                        });
                        try {
                            var audioNodeConnections = getAudioNodeConnections(faker);
                            var potentiallyEmptyInputs = inputs.map(function (input, index) {
                                if (audioNodeConnections.inputs[index].size === 0) {
                                    return [];
                                }
                                return input;
                            });
                            var activeSourceFlag = audioWorkletProcessor.process(potentiallyEmptyInputs, outputs, parameters);
                            isActive = activeSourceFlag;
                            for (var _j3 = 0, _outputChannelSplitterNodeOutput = 0; _j3 < options.numberOfOutputs; _j3 += 1) {
                                for (var _k = 0; _k < options.outputChannelCount[_j3]; _k += 1) {
                                    // Bug #5: Safari does not support copyFromChannel().
                                    outputBuffer.getChannelData(_outputChannelSplitterNodeOutput + _k).set(outputs[_j3][_k], _i4);
                                }
                                _outputChannelSplitterNodeOutput += options.outputChannelCount[_j3];
                            }
                        } catch (err) {
                            isActive = false;
                            if (onprocessorerror !== null) {
                                onprocessorerror.call(null, new ErrorEvent('processorerror'));
                            }
                        }
                        if (!isActive) {
                            scriptProcessorNode.onaudioprocess = null;
                            return 'break';
                        }
                    };

                    for (var _i4 = 0; _i4 < bufferSize; _i4 += 128) {
                        var _ret = _loop(_i4);

                        if (_ret === 'break') break;
                    }
                }
            };
            return faker;
        };
    };

    var createNativeBiquadFilterNode = function createNativeBiquadFilterNode(nativeContext, options) {
        var nativeBiquadFilterNode = nativeContext.createBiquadFilter();
        assignNativeAudioNodeOptions(nativeBiquadFilterNode, options);
        if (options.Q !== nativeBiquadFilterNode.Q.value) {
            nativeBiquadFilterNode.Q.value = options.Q;
        }
        if (options.detune !== nativeBiquadFilterNode.detune.value) {
            nativeBiquadFilterNode.detune.value = options.detune;
        }
        if (options.frequency !== nativeBiquadFilterNode.frequency.value) {
            nativeBiquadFilterNode.frequency.value = options.frequency;
        }
        if (options.gain !== nativeBiquadFilterNode.gain.value) {
            nativeBiquadFilterNode.gain.value = options.gain;
        }
        if (options.type !== nativeBiquadFilterNode.type) {
            nativeBiquadFilterNode.type = options.type;
        }
        return nativeBiquadFilterNode;
    };

    var wrapChannelMergerNode = function wrapChannelMergerNode(nativeContext, channelMergerNode) {
        var audioBufferSourceNode = nativeContext.createBufferSource();
        channelMergerNode.channelCount = 1;
        channelMergerNode.channelCountMode = 'explicit';
        // Bug #20: Safari requires a connection of any kind to treat the input signal correctly.
        var length = channelMergerNode.numberOfInputs;
        for (var i = 0; i < length; i += 1) {
            audioBufferSourceNode.connect(channelMergerNode, 0, i);
        }
        Object.defineProperty(channelMergerNode, 'channelCount', {
            get: function get() {
                return 1;
            },
            set: function set() {
                throw createInvalidStateError();
            }
        });
        Object.defineProperty(channelMergerNode, 'channelCountMode', {
            get: function get() {
                return 'explicit';
            },
            set: function set() {
                throw createInvalidStateError();
            }
        });
    };

    var createNativeChannelMergerNode = function createNativeChannelMergerNode(nativeContext) {
        var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};

        var nativeChannelMergerNode = nativeContext.createChannelMerger(options.numberOfInputs === undefined ? 6 : options.numberOfInputs);
        assignNativeAudioNodeOptions(nativeChannelMergerNode, options);
        // Bug #15: Safari does not return the default properties.
        if (nativeChannelMergerNode.channelCount !== 1 && nativeChannelMergerNode.channelCountMode !== 'explicit') {
            wrapChannelMergerNode(nativeContext, nativeChannelMergerNode);
        }
        // Bug #16: Firefox does not throw an error when setting a different channelCount or channelCountMode.
        try {
            nativeChannelMergerNode.channelCount = options.numberOfInputs === undefined ? 6 : options.numberOfInputs;
            wrapChannelMergerNode(nativeContext, nativeChannelMergerNode);
        } catch (err) {} // tslint:disable-line:no-empty
        return nativeChannelMergerNode;
    };

    var wrapChannelSplitterNode = function wrapChannelSplitterNode(channelSplitterNode) {
        channelSplitterNode.channelCountMode = 'explicit';
        channelSplitterNode.channelInterpretation = 'discrete';
        var channelCount = channelSplitterNode.numberOfOutputs;
        Object.defineProperty(channelSplitterNode, 'channelCount', {
            get: function get() {
                return channelCount;
            },
            set: function set() {
                throw createInvalidStateError();
            }
        });
        Object.defineProperty(channelSplitterNode, 'channelCountMode', {
            get: function get() {
                return 'explicit';
            },
            set: function set() {
                throw createInvalidStateError();
            }
        });
        // Bug #31: Only Chrome & Opera have the correct channelInterpretation.
        Object.defineProperty(channelSplitterNode, 'channelInterpretation', {
            get: function get() {
                return 'discrete';
            },
            set: function set() {
                throw createInvalidStateError();
            }
        });
    };

    var createNativeChannelSplitterNode = function createNativeChannelSplitterNode(nativeContext, options) {
        var nativeChannelSplitterNode = nativeContext.createChannelSplitter(options.numberOfOutputs);
        assignNativeAudioNodeOptions(nativeChannelSplitterNode, options);
        // Bug #29 - #32: Only Chrome & Opera partially support the spec yet.
        wrapChannelSplitterNode(nativeChannelSplitterNode);
        return nativeChannelSplitterNode;
    };

    var testConstantSourceNodeAccurateSchedulingSupport = function testConstantSourceNodeAccurateSchedulingSupport(nativeContext) {
      // @todo TypeScript doesn't know yet about createConstantSource().
      var constantSourceNode = nativeContext.createConstantSource();
      /*
       * @todo This is using bug #67 to detect bug #70. That works because both bugs are unique to the implementation of Firefox right
       * now, but it could probably be done in a better way.
       */
      return constantSourceNode.channelCount !== 1;
    };

    var wrapConstantSourceNodeAccurateScheduling = function wrapConstantSourceNodeAccurateScheduling(constantSourceNode, nativeContext) {
        var gainNode = nativeContext.createGain();
        constantSourceNode.connect(gainNode);
        var disconnectGainNode = function (disconnect) {
            return function () {
                disconnect.call(constantSourceNode, gainNode);
                constantSourceNode.removeEventListener('ended', disconnectGainNode);
            };
        }(constantSourceNode.disconnect);
        constantSourceNode.addEventListener('ended', disconnectGainNode);
        constantSourceNode.connect = function (destination) {
            var output = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
            var input = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;

            if (destination instanceof AudioNode) {
                // Bug #11: Safari does not support chaining yet, but that wrapper should not be used in Safari.
                return gainNode.connect.call(gainNode, destination, output, input);
            }
            // @todo This return statement is necessary to satisfy TypeScript.
            return gainNode.connect.call(gainNode, destination, output);
        };
        constantSourceNode.disconnect = function () {
            gainNode.disconnect.apply(gainNode, arguments);
        };
        var startTime = 0;
        var stopTime = null;
        var scheduleEnvelope = function scheduleEnvelope() {
            gainNode.gain.cancelScheduledValues(0);
            gainNode.gain.setValueAtTime(0, 0);
            if (stopTime === null || startTime < stopTime) {
                gainNode.gain.setValueAtTime(1, startTime);
            }
            if (stopTime !== null && startTime < stopTime) {
                gainNode.gain.setValueAtTime(0, stopTime);
            }
        };
        constantSourceNode.start = function (start) {
            return function () {
                var when = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;

                start.call(constantSourceNode, when);
                startTime = when;
                scheduleEnvelope();
            };
        }(constantSourceNode.start);
        constantSourceNode.stop = function (stop) {
            return function () {
                var when = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;

                stop.call(constantSourceNode, when);
                stopTime = when;
                scheduleEnvelope();
            };
        }(constantSourceNode.stop);
    };

    var createNativeConstantSourceNodeFactory = function createNativeConstantSourceNodeFactory(createNativeConstantSourceNodeFaker) {
        return function (nativeContext, options) {
            // Bug #62: Edge & Safari do not support ConstantSourceNodes.
            // @todo TypeScript doesn't know yet about createConstantSource().
            if (nativeContext.createConstantSource === undefined) {
                return createNativeConstantSourceNodeFaker(nativeContext, options);
            }
            var nativeConstantSourceNode = nativeContext.createConstantSource();
            assignNativeAudioNodeOptions(nativeConstantSourceNode, options);
            if (options.offset !== nativeConstantSourceNode.offset.value) {
                nativeConstantSourceNode.offset.value = options.offset;
            }
            // Bug #44: Only Chrome & Opera throw a RangeError yet.
            if (!cacheTestResult(testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, function () {
                return testAudioScheduledSourceNodeStartMethodNegativeParametersSupport(nativeContext);
            })) {
                wrapAudioScheduledSourceNodeStartMethodNegativeParameters(nativeConstantSourceNode);
            }
            // Bug #44: No browser does throw a RangeError yet.
            if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, function () {
                return testAudioScheduledSourceNodeStopMethodNegativeParametersSupport(nativeContext);
            })) {
                wrapAudioScheduledSourceNodeStopMethodNegativeParameters(nativeConstantSourceNode);
            }
            // Bug #70: Firefox does not schedule ConstantSourceNodes accurately.
            if (!cacheTestResult(testConstantSourceNodeAccurateSchedulingSupport, function () {
                return testConstantSourceNodeAccurateSchedulingSupport(nativeContext);
            })) {
                wrapConstantSourceNodeAccurateScheduling(nativeConstantSourceNode, nativeContext);
            }
            return nativeConstantSourceNode;
        };
    };

    var createNativeConstantSourceNodeFakerFactory = function createNativeConstantSourceNodeFakerFactory(createNativeAudioBufferSourceNode, createNativeGainNode) {
        return function (nativeAudioContext, _a) {
            var offset = _a.offset,
                audioNodeOptions = tslib_1.__rest(_a, ["offset"]);
            // @todo Safari does not play/loop 1 sample buffers. This should be covered by an expectation test.
            var audioBufferSourceNode = createNativeAudioBufferSourceNode(nativeAudioContext);
            /*
             * @todo Edge will throw a NotSupportedError when calling createBuffer() on a closed context. That's why the audioBuffer is created
             * after the audioBufferSourceNode in this case. If the context is closed createNativeAudioBufferSourceNode() will throw the
             * expected error and createBuffer() never gets called.
             */
            var audioBuffer = nativeAudioContext.createBuffer(1, 2, nativeAudioContext.sampleRate);
            var gainNode = createNativeGainNode(nativeAudioContext, Object.assign({}, audioNodeOptions, { gain: offset }));
            // Bug #5: Safari does not support copyFromChannel() and copyToChannel().
            var channelData = audioBuffer.getChannelData(0);
            channelData[0] = 1;
            channelData[1] = 1;
            audioBufferSourceNode.buffer = audioBuffer;
            audioBufferSourceNode.loop = true;
            audioBufferSourceNode.connect(gainNode);
            return {
                get bufferSize() {
                    return undefined;
                },
                get channelCount() {
                    return gainNode.channelCount;
                },
                set channelCount(value) {
                    gainNode.channelCount = value;
                },
                get channelCountMode() {
                    return gainNode.channelCountMode;
                },
                set channelCountMode(value) {
                    gainNode.channelCountMode = value;
                },
                get channelInterpretation() {
                    return gainNode.channelInterpretation;
                },
                set channelInterpretation(value) {
                    gainNode.channelInterpretation = value;
                },
                get context() {
                    return gainNode.context;
                },
                get inputs() {
                    return undefined;
                },
                get numberOfInputs() {
                    return audioBufferSourceNode.numberOfInputs;
                },
                get numberOfOutputs() {
                    return gainNode.numberOfOutputs;
                },
                get offset() {
                    return gainNode.gain;
                },
                get onended() {
                    return audioBufferSourceNode.onended;
                },
                set onended(value) {
                    audioBufferSourceNode.onended = value;
                },
                addEventListener: function addEventListener() {
                    return audioBufferSourceNode.addEventListener(arguments.length <= 0 ? undefined : arguments[0], arguments.length <= 1 ? undefined : arguments[1], arguments.length <= 2 ? undefined : arguments[2]);
                },
                connect: function connect() {
                    if ((arguments.length <= 2 ? undefined : arguments[2]) === undefined) {
                        return gainNode.connect.call(gainNode, arguments.length <= 0 ? undefined : arguments[0], arguments.length <= 1 ? undefined : arguments[1]);
                    }
                    return gainNode.connect.call(gainNode, arguments.length <= 0 ? undefined : arguments[0], arguments.length <= 1 ? undefined : arguments[1], arguments.length <= 2 ? undefined : arguments[2]);
                },
                disconnect: function disconnect() {
                    return gainNode.disconnect.call(gainNode, arguments.length <= 0 ? undefined : arguments[0], arguments.length <= 1 ? undefined : arguments[1], arguments.length <= 2 ? undefined : arguments[2]);
                },
                dispatchEvent: function dispatchEvent() {
                    return audioBufferSourceNode.dispatchEvent(arguments.length <= 0 ? undefined : arguments[0]);
                },
                removeEventListener: function removeEventListener() {
                    return audioBufferSourceNode.removeEventListener(arguments.length <= 0 ? undefined : arguments[0], arguments.length <= 1 ? undefined : arguments[1], arguments.length <= 2 ? undefined : arguments[2]);
                },
                start: function start() {
                    var when = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;

                    audioBufferSourceNode.start.call(audioBufferSourceNode, when);
                },
                stop: function stop() {
                    var when = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;

                    audioBufferSourceNode.stop.call(audioBufferSourceNode, when);
                }
            };
        };
    };

    var createNativeGainNode = function createNativeGainNode(nativeContext, options) {
        var nativeGainNode = nativeContext.createGain();
        assignNativeAudioNodeOptions(nativeGainNode, options);
        if (options.gain !== nativeGainNode.gain.value) {
            nativeGainNode.gain.value = options.gain;
        }
        return nativeGainNode;
    };

    var createNativeIIRFilterNodeFactory = function createNativeIIRFilterNodeFactory(createNativeIIRFilterNodeFaker) {
        return function (nativeContext, options) {
            // Bug #9: Safari does not support IIRFilterNodes.
            if (nativeContext.createIIRFilter === undefined) {
                return createNativeIIRFilterNodeFaker(nativeContext, options);
            }
            var nativeIIRFilterNode = nativeContext.createIIRFilter(options.feedforward, options.feedback);
            assignNativeAudioNodeOptions(nativeIIRFilterNode, options);
            return nativeIIRFilterNode;
        };
    };

    function divide(a, b) {
        var denominator = b[0] * b[0] + b[1] * b[1];
        return [(a[0] * b[0] + a[1] * b[1]) / denominator, (a[1] * b[0] - a[0] * b[1]) / denominator];
    }
    function multiply(a, b) {
        return [a[0] * b[0] - a[1] * b[1], a[0] * b[1] + a[1] * b[0]];
    }
    function evaluatePolynomial(coefficient, z) {
        var result = [0, 0];
        for (var i = coefficient.length - 1; i >= 0; i -= 1) {
            result = multiply(result, z);
            result[0] += coefficient[i];
        }
        return result;
    }
    var createNativeIIRFilterNodeFakerFactory = function createNativeIIRFilterNodeFakerFactory(createInvalidAccessError, createInvalidStateError, createNotSupportedError) {
        return function (nativeAudioContext, _ref) {
            var channelCount = _ref.channelCount,
                channelCountMode = _ref.channelCountMode,
                channelInterpretation = _ref.channelInterpretation,
                feedback = _ref.feedback,
                feedforward = _ref.feedforward;

            var bufferSize = 256;
            var feedbackLength = feedback.length;
            var feedforwardLength = feedforward.length;
            var minLength = Math.min(feedbackLength, feedforwardLength);
            if (feedback.length === 0 || feedback.length > 20) {
                throw createNotSupportedError();
            }
            if (feedback[0] === 0) {
                throw createInvalidStateError();
            }
            if (feedforward.length === 0 || feedforward.length > 20) {
                throw createNotSupportedError();
            }
            if (feedforward[0] === 0) {
                throw createInvalidStateError();
            }
            if (feedback[0] !== 1) {
                for (var i = 0; i < feedforwardLength; i += 1) {
                    feedforward[i] /= feedback[0];
                }
                for (var _i = 1; _i < feedbackLength; _i += 1) {
                    feedback[_i] /= feedback[0];
                }
            }
            var scriptProcessorNode = nativeAudioContext.createScriptProcessor(bufferSize, channelCount, channelCount);
            scriptProcessorNode.channelCount = channelCount;
            scriptProcessorNode.channelCountMode = channelCountMode;
            scriptProcessorNode.channelInterpretation = channelInterpretation;
            var bufferLength = 32;
            var bufferIndexes = [];
            var xBuffers = [];
            var yBuffers = [];
            for (var _i2 = 0; _i2 < channelCount; _i2 += 1) {
                bufferIndexes.push(0);
                var xBuffer = new Float32Array(bufferLength);
                var yBuffer = new Float32Array(bufferLength);
                // @todo Add a test which checks support for TypedArray.prototype.fill().
                xBuffer.fill(0);
                yBuffer.fill(0);
                xBuffers.push(xBuffer);
                yBuffers.push(yBuffer);
            }
            scriptProcessorNode.onaudioprocess = function (event) {
                var inputBuffer = event.inputBuffer;
                var outputBuffer = event.outputBuffer;
                var numberOfChannels = inputBuffer.numberOfChannels;
                for (var _i3 = 0; _i3 < numberOfChannels; _i3 += 1) {
                    var input = inputBuffer.getChannelData(_i3);
                    var output = outputBuffer.getChannelData(_i3);
                    bufferIndexes[_i3] = filterBuffer(feedback, feedbackLength, feedforward, feedforwardLength, minLength, xBuffers[_i3], yBuffers[_i3], bufferIndexes[_i3], bufferLength, input, output);
                }
            };
            var nyquist = nativeAudioContext.sampleRate / 2;
            return {
                get bufferSize() {
                    return bufferSize;
                },
                get channelCount() {
                    return scriptProcessorNode.channelCount;
                },
                set channelCount(value) {
                    scriptProcessorNode.channelCount = value;
                },
                get channelCountMode() {
                    return scriptProcessorNode.channelCountMode;
                },
                set channelCountMode(value) {
                    scriptProcessorNode.channelCountMode = value;
                },
                get channelInterpretation() {
                    return scriptProcessorNode.channelInterpretation;
                },
                set channelInterpretation(value) {
                    scriptProcessorNode.channelInterpretation = value;
                },
                get context() {
                    return scriptProcessorNode.context;
                },
                get inputs() {
                    return [scriptProcessorNode];
                },
                get numberOfInputs() {
                    return scriptProcessorNode.numberOfInputs;
                },
                get numberOfOutputs() {
                    return scriptProcessorNode.numberOfOutputs;
                },
                addEventListener: function addEventListener() {
                    // @todo Dissallow adding an audioprocess listener.
                    return scriptProcessorNode.addEventListener(arguments.length <= 0 ? undefined : arguments[0], arguments.length <= 1 ? undefined : arguments[1], arguments.length <= 2 ? undefined : arguments[2]);
                },
                connect: function connect() {
                    if ((arguments.length <= 2 ? undefined : arguments[2]) === undefined) {
                        return scriptProcessorNode.connect.call(scriptProcessorNode, arguments.length <= 0 ? undefined : arguments[0], arguments.length <= 1 ? undefined : arguments[1]);
                    }
                    return scriptProcessorNode.connect.call(scriptProcessorNode, arguments.length <= 0 ? undefined : arguments[0], arguments.length <= 1 ? undefined : arguments[1], arguments.length <= 2 ? undefined : arguments[2]);
                },
                disconnect: function disconnect() {
                    return scriptProcessorNode.disconnect.call(scriptProcessorNode, arguments.length <= 0 ? undefined : arguments[0], arguments.length <= 1 ? undefined : arguments[1], arguments.length <= 2 ? undefined : arguments[2]);
                },
                dispatchEvent: function dispatchEvent() {
                    return scriptProcessorNode.dispatchEvent(arguments.length <= 0 ? undefined : arguments[0]);
                },
                getFrequencyResponse: function getFrequencyResponse(frequencyHz, magResponse, phaseResponse) {
                    if (frequencyHz.length !== magResponse.length || magResponse.length !== phaseResponse.length) {
                        throw createInvalidAccessError();
                    }
                    var length = frequencyHz.length;
                    for (var _i4 = 0; _i4 < length; _i4 += 1) {
                        var omega = -Math.PI * (frequencyHz[_i4] / nyquist);
                        var z = [Math.cos(omega), Math.sin(omega)];
                        var numerator = evaluatePolynomial(feedforward, z);
                        var denominator = evaluatePolynomial(feedback, z);
                        var response = divide(numerator, denominator);
                        magResponse[_i4] = Math.sqrt(response[0] * response[0] + response[1] * response[1]);
                        phaseResponse[_i4] = Math.atan2(response[1], response[0]);
                    }
                },
                removeEventListener: function removeEventListener() {
                    return scriptProcessorNode.removeEventListener(arguments.length <= 0 ? undefined : arguments[0], arguments.length <= 1 ? undefined : arguments[1], arguments.length <= 2 ? undefined : arguments[2]);
                }
            };
        };
    };

    var createNativeOfflineAudioContextConstructor = function createNativeOfflineAudioContextConstructor(window) {
        if (window === null) {
            return null;
        }
        if (window.hasOwnProperty('OfflineAudioContext')) {
            return window.OfflineAudioContext;
        }
        return window.hasOwnProperty('webkitOfflineAudioContext') ? window.webkitOfflineAudioContext : null;
    };

    var createNativeOscillatorNode = function createNativeOscillatorNode(nativeContext, options) {
        var nativeOscillatorNode = nativeContext.createOscillator();
        assignNativeAudioNodeOptions(nativeOscillatorNode, options);
        if (options.detune !== nativeOscillatorNode.detune.value) {
            nativeOscillatorNode.detune.value = options.detune;
        }
        if (options.frequency !== nativeOscillatorNode.frequency.value) {
            nativeOscillatorNode.frequency.value = options.frequency;
        }
        // @todo periodicWave
        if (options.type !== nativeOscillatorNode.type) {
            nativeOscillatorNode.type = options.type;
        }
        // Bug #44: Only Chrome & Opera throw a RangeError yet.
        if (!cacheTestResult(testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, function () {
            return testAudioScheduledSourceNodeStartMethodNegativeParametersSupport(nativeContext);
        })) {
            wrapAudioScheduledSourceNodeStartMethodNegativeParameters(nativeOscillatorNode);
        }
        // Bug #19: Safari does not ignore calls to stop() of an already stopped AudioBufferSourceNode.
        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, function () {
            return testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport(nativeContext);
        })) {
            wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls(nativeOscillatorNode, nativeContext);
        }
        // Bug #44: No browser does throw a RangeError yet.
        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, function () {
            return testAudioScheduledSourceNodeStopMethodNegativeParametersSupport(nativeContext);
        })) {
            wrapAudioScheduledSourceNodeStopMethodNegativeParameters(nativeOscillatorNode);
        }
        return nativeOscillatorNode;
    };

    var createNoneAudioDestinationNodeConstructor = function createNoneAudioDestinationNodeConstructor(audioNodeConstructor, createInvalidStateError) {
        return function (_audioNodeConstructor) {
            _inherits(NoneAudioDestinationNode, _audioNodeConstructor);

            function NoneAudioDestinationNode(context, nativeAudioNode, audioNodeRenderer) {
                _classCallCheck(this, NoneAudioDestinationNode);

                // Bug #50 Safari does not throw an error when the context is already closed.
                if (context.state === 'closed') {
                    throw createInvalidStateError();
                }

                var _this = _possibleConstructorReturn(this, (NoneAudioDestinationNode.__proto__ || Object.getPrototypeOf(NoneAudioDestinationNode)).call(this, context, nativeAudioNode, audioNodeRenderer));

                _this._nativeAudioNode = nativeAudioNode;
                return _this;
            }

            _createClass(NoneAudioDestinationNode, [{
                key: 'channelCount',
                get: function get() {
                    return this._nativeAudioNode.channelCount;
                },
                set: function set(value) {
                    this._nativeAudioNode.channelCount = value;
                }
            }, {
                key: 'channelCountMode',
                get: function get() {
                    return this._nativeAudioNode.channelCountMode;
                },
                set: function set(value) {
                    this._nativeAudioNode.channelCountMode = value;
                }
            }]);

            return NoneAudioDestinationNode;
        }(audioNodeConstructor);
    };

    var DEFAULT_OPTIONS$13 = {
        numberOfChannels: 1
    };
    var isSupportingPromises$2 = function isSupportingPromises(nativeOfflineAudioContext) {
        return cacheTestResult(testPromiseSupport, function () {
            return testPromiseSupport(nativeOfflineAudioContext);
        });
    };
    var createOfflineAudioContextConstructor = function createOfflineAudioContextConstructor(baseAudioContextConstructor, createInvalidStateError, nativeOfflineAudioContextConstructor, _startRendering) {
        return function (_baseAudioContextCons) {
            _inherits(OfflineAudioContext, _baseAudioContextCons);

            function OfflineAudioContext(a, b, c) {
                _classCallCheck(this, OfflineAudioContext);

                if (nativeOfflineAudioContextConstructor === null) {
                    throw new Error(); // @todo
                }
                var options = void 0;
                if (typeof a === 'number' && b !== undefined && c !== undefined) {
                    options = { length: b, numberOfChannels: a, sampleRate: c };
                } else if ((typeof a === 'undefined' ? 'undefined' : _typeof(a)) === 'object') {
                    options = a;
                } else {
                    throw new Error('The given parameters are not valid.');
                }

                var _Object$assign = Object.assign({}, DEFAULT_OPTIONS$13, options),
                    length = _Object$assign.length,
                    numberOfChannels = _Object$assign.numberOfChannels,
                    sampleRate = _Object$assign.sampleRate;

                var nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(numberOfChannels, length, sampleRate);
                // #21 Safari does not support promises and therefore would fire the statechange event before the promise can be resolved.
                if (!isSupportingPromises$2(nativeOfflineAudioContext)) {
                    nativeOfflineAudioContext.addEventListener('statechange', function () {
                        var i = 0;
                        var delayStateChangeEvent = function delayStateChangeEvent(event) {
                            if (_this._state === 'running') {
                                if (i > 0) {
                                    nativeOfflineAudioContext.removeEventListener('statechange', delayStateChangeEvent);
                                    event.stopImmediatePropagation();
                                    _this._waitForThePromiseToSettle(event);
                                } else {
                                    i += 1;
                                }
                            }
                        };
                        return delayStateChangeEvent;
                    }());
                }

                var _this = _possibleConstructorReturn(this, (OfflineAudioContext.__proto__ || Object.getPrototypeOf(OfflineAudioContext)).call(this, nativeOfflineAudioContext, numberOfChannels));

                _this._length = length;
                _this._nativeOfflineAudioContext = nativeOfflineAudioContext;
                _this._state = null;
                return _this;
            }

            _createClass(OfflineAudioContext, [{
                key: 'startRendering',
                value: function startRendering() {
                    var _this2 = this;

                    /*
                     * Bug #9 & #59: It is theoretically possible that startRendering() will first render a partialOfflineAudioContext. Therefore
                     * the state of the nativeOfflineAudioContext might no transition to running immediately.
                     */
                    if (this._state === 'running') {
                        return Promise.reject(createInvalidStateError());
                    }
                    this._state = 'running';
                    return _startRendering(this.destination, this._nativeOfflineAudioContext).then(function (audioBuffer) {
                        // Bug #5: Safari does not support copyFromChannel() and copyToChannel().
                        if (typeof audioBuffer.copyFromChannel !== 'function') {
                            wrapAudioBufferCopyChannelMethods(audioBuffer);
                        }
                        _this2._state = null;
                        deleteAudioGraph(_this2, _this2._nativeOfflineAudioContext);
                        return audioBuffer;
                    })
                    // @todo This could be written more elegantly when Promise.finally() becomes avalaible.
                    .catch(function (err) {
                        _this2._state = null;
                        deleteAudioGraph(_this2, _this2._nativeOfflineAudioContext);
                        throw err;
                    });
                }
            }, {
                key: '_waitForThePromiseToSettle',
                value: function _waitForThePromiseToSettle(event) {
                    var _this3 = this;

                    if (this._state === null) {
                        this._nativeOfflineAudioContext.dispatchEvent(event);
                    } else {
                        setTimeout(function () {
                            return _this3._waitForThePromiseToSettle(event);
                        });
                    }
                }
            }, {
                key: 'length',
                get: function get() {
                    // Bug #17: Safari does not yet expose the length.
                    if (this._nativeOfflineAudioContext.length === undefined) {
                        return this._length;
                    }
                    return this._nativeOfflineAudioContext.length;
                }
            }, {
                key: 'state',
                get: function get() {
                    return this._state === null ? this._nativeOfflineAudioContext.state : this._state;
                }
            }]);

            return OfflineAudioContext;
        }(baseAudioContextConstructor);
    };

    // The DEFAULT_OPTIONS are only of type Partial<IOscillatorOptions> because there is no default value for periodicWave.
    var DEFAULT_OPTIONS$14 = {
        channelCount: 2,
        channelCountMode: 'max',
        channelInterpretation: 'speakers',
        detune: 0,
        frequency: 440,
        type: 'sine'
    };
    var createOscillatorNodeConstructor = function createOscillatorNodeConstructor(createAudioParam, createInvalidStateError, createNativeOscillatorNode, createOscillatorNodeRenderer, isNativeOfflineAudioContext, noneAudioDestinationNodeConstructor) {
        return function (_noneAudioDestination) {
            _inherits(OscillatorNode, _noneAudioDestination);

            function OscillatorNode(context) {
                var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : DEFAULT_OPTIONS$14;

                _classCallCheck(this, OscillatorNode);

                var nativeContext = getNativeContext(context);
                var mergedOptions = Object.assign({}, DEFAULT_OPTIONS$14, options);
                var nativeOscillatorNode = createNativeOscillatorNode(nativeContext, mergedOptions);
                var isOffline = isNativeOfflineAudioContext(nativeContext);
                var oscillatorNodeRenderer = isOffline ? createOscillatorNodeRenderer() : null;
                var nyquist = context.sampleRate / 2;

                // Bug #81: Edge, Firefox & Safari do not export the correct values for maxValue and minValue.
                var _this = _possibleConstructorReturn(this, (OscillatorNode.__proto__ || Object.getPrototypeOf(OscillatorNode)).call(this, context, nativeOscillatorNode, oscillatorNodeRenderer));

                _this._detune = createAudioParam(context, isOffline, nativeOscillatorNode.detune, 3.4028234663852886e38, -3.4028234663852886e38);
                // Bug #76: Edge & Safari do not export the correct values for maxValue and minValue.
                _this._frequency = createAudioParam(context, isOffline, nativeOscillatorNode.frequency, nyquist, -nyquist);
                _this._nativeOscillatorNode = nativeOscillatorNode;
                _this._oscillatorNodeRenderer = oscillatorNodeRenderer;
                return _this;
            }

            _createClass(OscillatorNode, [{
                key: 'setPeriodicWave',
                value: function setPeriodicWave(periodicWave) {
                    this._nativeOscillatorNode.setPeriodicWave(periodicWave);
                }
            }, {
                key: 'start',
                value: function start() {
                    var when = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;

                    this._nativeOscillatorNode.start(when);
                    if (this._oscillatorNodeRenderer !== null) {
                        this._oscillatorNodeRenderer.start = when;
                    }
                }
            }, {
                key: 'stop',
                value: function stop() {
                    var when = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;

                    this._nativeOscillatorNode.stop(when);
                    if (this._oscillatorNodeRenderer !== null) {
                        this._oscillatorNodeRenderer.stop = when;
                    }
                }
            }, {
                key: 'detune',
                get: function get() {
                    return this._detune;
                }
            }, {
                key: 'frequency',
                get: function get() {
                    return this._frequency;
                }
            }, {
                key: 'onended',
                get: function get() {
                    return this._nativeOscillatorNode.onended;
                },
                set: function set(value) {
                    this._nativeOscillatorNode.onended = value;
                }
            }, {
                key: 'type',
                get: function get() {
                    return this._nativeOscillatorNode.type;
                },
                set: function set(value) {
                    this._nativeOscillatorNode.type = value;
                    // Bug #57: Edge will not throw an error when assigning the type to 'custom'. But it still will change the value.
                    if (value === 'custom') {
                        throw createInvalidStateError();
                    }
                }
            }]);

            return OscillatorNode;
        }(noneAudioDestinationNodeConstructor);
    };

    var _this$11 = undefined;
    var createOscillatorNodeRendererFactory = function createOscillatorNodeRendererFactory(createNativeOscillatorNode) {
        return function () {
            var nativeOscillatorNode = null;
            var start = null;
            var stop = null;
            return {
                set start(value) {
                    start = value;
                },
                set stop(value) {
                    stop = value;
                },
                render: function render(proxy, nativeOfflineAudioContext) {
                    return tslib_1.__awaiter(_this$11, void 0, void 0, /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {
                        var options;
                        return _regeneratorRuntime.wrap(function _callee$(_context) {
                            while (1) {
                                switch (_context.prev = _context.next) {
                                    case 0:
                                        if (!(nativeOscillatorNode !== null)) {
                                            _context.next = 2;
                                            break;
                                        }

                                        return _context.abrupt('return', nativeOscillatorNode);

                                    case 2:
                                        nativeOscillatorNode = getNativeAudioNode(proxy);
                                        /*
                                         * If the initially used nativeOscillatorNode was not constructed on the same OfflineAudioContext it needs to be created
                                         * again.
                                         */

                                        if (isOwnedByContext(nativeOscillatorNode, nativeOfflineAudioContext)) {
                                            _context.next = 14;
                                            break;
                                        }

                                        options = {
                                            channelCount: nativeOscillatorNode.channelCount,
                                            channelCountMode: nativeOscillatorNode.channelCountMode,
                                            channelInterpretation: nativeOscillatorNode.channelInterpretation,
                                            detune: nativeOscillatorNode.detune.value,
                                            frequency: nativeOscillatorNode.frequency.value,
                                            // @todo periodicWave is not exposed by the native node.
                                            type: nativeOscillatorNode.type
                                        };

                                        nativeOscillatorNode = createNativeOscillatorNode(nativeOfflineAudioContext, options);
                                        if (start !== null) {
                                            nativeOscillatorNode.start(start);
                                        }
                                        if (stop !== null) {
                                            nativeOscillatorNode.stop(stop);
                                        }
                                        _context.next = 10;
                                        return renderAutomation(proxy.context, nativeOfflineAudioContext, proxy.detune, nativeOscillatorNode.detune);

                                    case 10:
                                        _context.next = 12;
                                        return renderAutomation(proxy.context, nativeOfflineAudioContext, proxy.frequency, nativeOscillatorNode.frequency);

                                    case 12:
                                        _context.next = 18;
                                        break;

                                    case 14:
                                        _context.next = 16;
                                        return connectAudioParam(proxy.context, nativeOfflineAudioContext, proxy.detune);

                                    case 16:
                                        _context.next = 18;
                                        return connectAudioParam(proxy.context, nativeOfflineAudioContext, proxy.frequency);

                                    case 18:
                                        _context.next = 20;
                                        return renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeOscillatorNode);

                                    case 20:
                                        return _context.abrupt('return', nativeOscillatorNode);

                                    case 21:
                                    case 'end':
                                        return _context.stop();
                                }
                            }
                        }, _callee, this);
                    }));
                }
            };
        };
    };

    var isSupportingPromises$3 = function isSupportingPromises(nativeOfflineAudioContext) {
        return cacheTestResult(testPromiseSupport, function () {
            return testPromiseSupport(nativeOfflineAudioContext);
        });
    };
    var createRenderNativeOfflineAudioContext = function createRenderNativeOfflineAudioContext(createNativeGainNode) {
        return function (nativeOfflineAudioContext) {
            // Bug #21: Safari does not support promises yet.
            if (isSupportingPromises$3(nativeOfflineAudioContext)) {
                return nativeOfflineAudioContext.startRendering();
            }
            return new Promise(function (resolve) {
                // Bug #48: Safari does not render an OfflineAudioContext without any connected node.
                var gainNode = createNativeGainNode(nativeOfflineAudioContext, {
                    channelCount: 1,
                    channelCountMode: 'explicit',
                    channelInterpretation: 'discrete',
                    gain: 0
                });
                nativeOfflineAudioContext.oncomplete = function (event) {
                    gainNode.disconnect();
                    resolve(event.renderedBuffer);
                };
                gainNode.connect(nativeOfflineAudioContext.destination);
                nativeOfflineAudioContext.startRendering();
            });
        };
    };

    var createStartRendering = function createStartRendering(renderNativeOfflineAudioContext) {
        return function (destination, nativeOfflineAudioContext) {
            return getAudioNodeRenderer(destination).render(destination, nativeOfflineAudioContext).then(function () {
                return renderNativeOfflineAudioContext(nativeOfflineAudioContext);
            });
        };
    };

    var createTestAudioContextCloseMethodSupport = function createTestAudioContextCloseMethodSupport(nativeAudioContextConstructor) {
        return function () {
            if (nativeAudioContextConstructor === null) {
                return false;
            }
            // Try to check the prototype before constructing the AudioContext.
            if (nativeAudioContextConstructor.prototype !== undefined && nativeAudioContextConstructor.prototype.close !== undefined) {
                return true;
            }
            var audioContext = new nativeAudioContextConstructor();
            var isAudioContextClosable = audioContext.close !== undefined;
            try {
                audioContext.close();
            } catch (err) {
                // Ignore errors.
            }
            return isAudioContextClosable;
        };
    };

    /**
     * Edge up to version 14, Firefox up to version 52, Safari up to version 9 and maybe other browsers
     * did not refuse to decode invalid parameters with a TypeError.
     */
    var createTestAudioContextDecodeAudioDataMethodTypeErrorSupport = function createTestAudioContextDecodeAudioDataMethodTypeErrorSupport(nativeOfflineAudioContextConstructor) {
        return function () {
            if (nativeOfflineAudioContextConstructor === null) {
                return Promise.resolve(false);
            }
            var offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
            // Bug #21: Safari does not support promises yet.
            return new Promise(function (resolve) {
                offlineAudioContext
                // Bug #1: Safari requires a successCallback.
                .decodeAudioData(null, function () {
                    // Ignore the success callback.
                }, function (err) {
                    offlineAudioContext.startRendering();
                    resolve(err instanceof TypeError);
                }).catch(function () {
                    // Ignore errors.
                });
            });
        };
    };

    var createTestAudioContextOptionsSupport = function createTestAudioContextOptionsSupport(nativeAudioContextConstructor) {
        return function () {
            if (nativeAudioContextConstructor === null) {
                return false;
            }
            var audioContext = void 0;
            try {
                audioContext = new nativeAudioContextConstructor({ latencyHint: 'balanced' });
            } catch (err) {
                return false;
            }
            audioContext.close();
            return true;
        };
    };

    /**
     * Firefox up to version 44 had a bug which resulted in a misbehaving ChannelMergerNode. If one of
     * its channels would be unconnected the remaining channels were somehow upmixed to spread the
     * signal across all available channels.
     */
    var createTestChannelMergerNodeSupport = function createTestChannelMergerNodeSupport(nativeAudioContextConstructor) {
        return function () {
            if (nativeAudioContextConstructor === null) {
                return Promise.resolve(false);
            }
            var audioContext = new nativeAudioContextConstructor();
            var audioBufferSourceNode = audioContext.createBufferSource();
            var audioBuffer = audioContext.createBuffer(2, 2, audioContext.sampleRate);
            var channelMergerNode = audioContext.createChannelMerger(2);
            var scriptProcessorNode = audioContext.createScriptProcessor(256);
            return new Promise(function (resolve) {
                var startTime = void 0;
                // @todo Safari does not play/loop 1 sample buffers. This should be patched.
                audioBuffer.getChannelData(0)[0] = 1;
                audioBuffer.getChannelData(0)[1] = 1;
                audioBuffer.getChannelData(1)[0] = 1;
                audioBuffer.getChannelData(1)[1] = 1;
                audioBufferSourceNode.buffer = audioBuffer;
                audioBufferSourceNode.loop = true;
                scriptProcessorNode.onaudioprocess = function (event) {
                    var channelData = event.inputBuffer.getChannelData(1);
                    var length = channelData.length;
                    for (var i = 0; i < length; i += 1) {
                        if (channelData[i] !== 0) {
                            resolve(false);
                            return;
                        }
                    }
                    if (startTime + 1 / audioContext.sampleRate < event.playbackTime) {
                        resolve(true);
                    }
                };
                audioBufferSourceNode.connect(channelMergerNode, 0, 0);
                channelMergerNode.connect(scriptProcessorNode);
                scriptProcessorNode.connect(audioContext.destination);
                startTime = audioContext.currentTime;
                audioBufferSourceNode.start(startTime);
            }).then(function (result) {
                audioBufferSourceNode.stop();
                audioBufferSourceNode.disconnect();
                channelMergerNode.disconnect();
                scriptProcessorNode.disconnect();
                audioContext.close();
                return result;
            });
        };
    };

    var createWindow = function createWindow() {
      return typeof window === 'undefined' ? null : window;
    };

    var window$1 = createWindow();
    var nativeOfflineAudioContextConstructor = createNativeOfflineAudioContextConstructor(window$1);
    var isNativeOfflineAudioContext = createIsNativeOfflineAudioContext(nativeOfflineAudioContextConstructor);
    var audioNodeConstructor = createAudioNodeConstructor(createInvalidAccessError, isNativeOfflineAudioContext);
    var noneAudioDestinationNodeConstructor = createNoneAudioDestinationNodeConstructor(audioNodeConstructor, createInvalidStateError);
    var createAnalyserNodeRenderer = createAnalyserNodeRendererFactory(createNativeAnalyserNode);
    var analyserNodeConstructor = createAnalyserNodeConstructor(createAnalyserNodeRenderer, createNativeAnalyserNode, isNativeOfflineAudioContext, noneAudioDestinationNodeConstructor);
    var audioBufferConstructor = createAudioBufferConstructor(nativeOfflineAudioContextConstructor);
    var createAudioBufferSourceNodeRenderer = createAudioBufferSourceNodeRendererFactory(createNativeAudioBufferSourceNode);
    var createAudioParam = createAudioParamFactory(createAudioParamRenderer);
    var audioBufferSourceNodeConstructor = createAudioBufferSourceNodeConstructor(createAudioBufferSourceNodeRenderer, createAudioParam, createInvalidStateError, createNativeAudioBufferSourceNode, isNativeOfflineAudioContext, noneAudioDestinationNodeConstructor);
    var audioDestinationNodeConstructor = createAudioDestinationNodeConstructor(audioNodeConstructor, createAudioDestinationNodeRenderer, createIndexSizeError, createInvalidStateError, createNativeAudioDestinationNode, isNativeOfflineAudioContext);
    var createBiquadFilterNodeRenderer = createBiquadFilterNodeRendererFactory(createNativeBiquadFilterNode);
    var biquadFilterNodeConstructor = createBiquadFilterNodeConstructor(createAudioParam, createBiquadFilterNodeRenderer, createInvalidAccessError, createNativeBiquadFilterNode, isNativeOfflineAudioContext, noneAudioDestinationNodeConstructor);
    var createChannelMergerNodeRenderer = createChannelMergerNodeRendererFactory(createNativeChannelMergerNode);
    var channelMergerNodeConstructor = createChannelMergerNodeConstructor(createChannelMergerNodeRenderer, createNativeChannelMergerNode, isNativeOfflineAudioContext, noneAudioDestinationNodeConstructor);
    var createChannelSplitterNodeRenderer = createChannelSplitterNodeRendererFactory(createNativeChannelSplitterNode);
    var channelSplitterNodeConstructor = createChannelSplitterNodeConstructor(createChannelSplitterNodeRenderer, createNativeChannelSplitterNode, isNativeOfflineAudioContext, noneAudioDestinationNodeConstructor);
    var createNativeConstantSourceNodeFaker = createNativeConstantSourceNodeFakerFactory(createNativeAudioBufferSourceNode, createNativeGainNode);
    var createNativeConstantSourceNode = createNativeConstantSourceNodeFactory(createNativeConstantSourceNodeFaker);
    var createConstantSourceNodeRenderer = createConstantSourceNodeRendererFactory(createNativeConstantSourceNode);
    var constantSourceNodeConstructor = createConstantSourceNodeConstructor(createAudioParam, createConstantSourceNodeRenderer, createNativeConstantSourceNode, isNativeOfflineAudioContext, noneAudioDestinationNodeConstructor);
    var createGainNodeRenderer = createGainNodeRendererFactory(createNativeGainNode);
    var gainNodeConstructor = createGainNodeConstructor(createAudioParam, createGainNodeRenderer, createNativeGainNode, isNativeOfflineAudioContext, noneAudioDestinationNodeConstructor);
    var renderNativeOfflineAudioContext = createRenderNativeOfflineAudioContext(createNativeGainNode);
    var createIIRFilterNodeRenderer = createIIRFilterNodeRendererFactory(createNativeAudioBufferSourceNode, nativeOfflineAudioContextConstructor, renderNativeOfflineAudioContext);
    var createNativeIIRFilterNodeFaker = createNativeIIRFilterNodeFakerFactory(createInvalidAccessError, createInvalidStateError, createNotSupportedError);
    var createNativeIIRFilterNode = createNativeIIRFilterNodeFactory(createNativeIIRFilterNodeFaker);
    var iIRFilterNodeConstructor = createIIRFilterNodeConstructor(createNativeIIRFilterNode, createIIRFilterNodeRenderer, isNativeOfflineAudioContext, noneAudioDestinationNodeConstructor);
    var minimalBaseAudioContextConstructor = createMinimalBaseAudioContextConstructor(audioDestinationNodeConstructor);
    var createOscillatorNodeRenderer = createOscillatorNodeRendererFactory(createNativeOscillatorNode);
    var oscillatorNodeConstructor = createOscillatorNodeConstructor(createAudioParam, createInvalidStateError, createNativeOscillatorNode, createOscillatorNodeRenderer, isNativeOfflineAudioContext, noneAudioDestinationNodeConstructor);
    var baseAudioContextConstructor = createBaseAudioContextConstructor(analyserNodeConstructor, audioBufferConstructor, audioBufferSourceNodeConstructor, biquadFilterNodeConstructor, channelMergerNodeConstructor, channelSplitterNodeConstructor, constantSourceNodeConstructor, gainNodeConstructor, iIRFilterNodeConstructor, minimalBaseAudioContextConstructor, oscillatorNodeConstructor);
    var mediaElementAudioSourceNodeConstructor = createMediaElementAudioSourceNodeConstructor(noneAudioDestinationNodeConstructor);
    var mediaStreamAudioSourceNodeConstructor = createMediaStreamAudioSourceNodeConstructor(noneAudioDestinationNodeConstructor);
    var nativeAudioContextConstructor = createNativeAudioContextConstructor(window$1);
    var audioContextConstructor = createAudioContextConstructor(baseAudioContextConstructor, createInvalidStateError, mediaElementAudioSourceNodeConstructor, mediaStreamAudioSourceNodeConstructor, nativeAudioContextConstructor);
    var connectMultipleOutputs = createConnectMultipleOutputs(createIndexSizeError);
    var disconnectMultipleOutputs = createDisconnectMultipleOutputs(createIndexSizeError);
    var nativeAudioWorkletNodeConstructor = createNativeAudioWorkletNodeConstructor(window$1);
    var createAudioWorkletNodeRenderer = createAudioWorkletNodeRendererFactory(connectMultipleOutputs, createNativeAudioBufferSourceNode, createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeConstantSourceNode, createNativeGainNode, disconnectMultipleOutputs, nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor, renderNativeOfflineAudioContext);
    var createNativeAudioWorkletNodeFaker = createNativeAudioWorkletNodeFakerFactory(connectMultipleOutputs, createIndexSizeError, createInvalidStateError, createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeConstantSourceNode, createNativeGainNode, createNotSupportedError, disconnectMultipleOutputs);
    var createNativeAudioWorkletNode = createNativeAudioWorkletNodeFactory(createInvalidStateError, createNativeAudioWorkletNodeFaker, createNotSupportedError);
    var audioWorkletNodeConstructor = createAudioWorkletNodeConstructor(createAudioParam, createAudioWorkletNodeRenderer, createNativeAudioWorkletNode, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor, noneAudioDestinationNodeConstructor);
    var minimalAudioContextConstructor = createMinimalAudioContextConstructor(createInvalidStateError, minimalBaseAudioContextConstructor, nativeAudioContextConstructor);
    var startRendering = createStartRendering(renderNativeOfflineAudioContext);
    var minimalOfflineAudioContextConstructor = createMinimalOfflineAudioContextConstructor(createInvalidStateError, minimalBaseAudioContextConstructor, nativeOfflineAudioContextConstructor, startRendering);
    var offlineAudioContextConstructor = createOfflineAudioContextConstructor(baseAudioContextConstructor, createInvalidStateError, nativeOfflineAudioContextConstructor, startRendering);
    var isSupported = function isSupported() {
      return createIsSupportedPromise(browsernizr, createTestAudioContextCloseMethodSupport(nativeAudioContextConstructor), createTestAudioContextDecodeAudioDataMethodTypeErrorSupport(nativeOfflineAudioContextConstructor), createTestAudioContextOptionsSupport(nativeAudioContextConstructor), createTestChannelMergerNodeSupport(nativeAudioContextConstructor));
    };

    exports.AnalyserNode = analyserNodeConstructor;
    exports.AudioBuffer = audioBufferConstructor;
    exports.AudioBufferSourceNode = audioBufferSourceNodeConstructor;
    exports.AudioContext = audioContextConstructor;
    exports.AudioWorkletNode = audioWorkletNodeConstructor;
    exports.BiquadFilterNode = biquadFilterNodeConstructor;
    exports.ChannelMergerNode = channelMergerNodeConstructor;
    exports.ChannelSplitterNode = channelSplitterNodeConstructor;
    exports.ConstantSourceNode = constantSourceNodeConstructor;
    exports.GainNode = gainNodeConstructor;
    exports.IIRFilterNode = iIRFilterNodeConstructor;
    exports.MediaElementAudioSourceNode = mediaElementAudioSourceNodeConstructor;
    exports.MediaStreamAudioSourceNode = mediaStreamAudioSourceNodeConstructor;
    exports.MinimalAudioContext = minimalAudioContextConstructor;
    exports.MinimalOfflineAudioContext = minimalOfflineAudioContextConstructor;
    exports.OfflineAudioContext = offlineAudioContextConstructor;
    exports.OscillatorNode = oscillatorNodeConstructor;
    exports.isSupported = isSupported;
    exports.addAudioWorkletModule = addAudioWorkletModule;
    exports.decodeAudioData = decodeAudioData;

    Object.defineProperty(exports, '__esModule', { value: true });

})));
